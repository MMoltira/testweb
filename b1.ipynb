{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "b1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4tHlmnjHHxA1",
        "XhGoWt8CHxA3",
        "4CfquesGP-rZ",
        "gIezSP7KHxA5",
        "nbfA8plqHxBA",
        "W_E0EHBiQlIJ",
        "AdgXpLcnREHl",
        "NZUvi2SEREHm",
        "TDetFQwMSKk3"
      ],
      "authorship_tag": "ABX9TyPJc1PjGUk6LNxQFH2LJSvo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MMoltira/Chest-X-Ray-classification/blob/main/b1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### import"
      ],
      "metadata": {
        "id": "Kpnf_sft9x4-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Psng6eJUdzUG"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torchsummary import summary\n",
        "from skimage.io import imread, imsave\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model\n",
        "from imutils import paths\n",
        "import argparse\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import metrics\n",
        "from scipy.stats import zscore\n",
        "\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import savefig\n",
        "\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels"
      ],
      "metadata": {
        "id": "6f-PDKiLl2iC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import joblib"
      ],
      "metadata": {
        "id": "KywT8U_h4Bmb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Load data // KKUmail"
      ],
      "metadata": {
        "id": "udl0zY8hAONG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8834f4b-670e-4cda-971d-d477fd18ae41",
        "id": "CZD0IvKyAONH"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTByVBBEAONI"
      },
      "source": [
        "data_dir = '/content/drive/My Drive/Senior Project/Senior Project/CXR Image3class/Image'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train 3 class"
      ],
      "metadata": {
        "id": "ySK4zn_OAONI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Normal151_dir = os.path.join(data_dir,'Normal151')\n",
        "TB150_dir = os.path.join(data_dir,'TB150')\n",
        "CA150_dir = os.path.join(data_dir,'CA150')\n",
        "\n",
        "All_3class_dir = os.path.join(data_dir,'All_3class')"
      ],
      "metadata": {
        "id": "yWVr9yKtAONI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Load data // Gmail"
      ],
      "metadata": {
        "id": "DVAihFMCTxcI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cf23bd1-a9cc-4a26-b8d0-f693dd8683f5",
        "id": "y1ciXCtjTxcJ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q_4EnTuTxcM"
      },
      "source": [
        "data_dir = '/content/drive/My Drive/Senior Project/Senior Project/CXR Image3class/Image'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train 3 class"
      ],
      "metadata": {
        "id": "M0cxoTbeTxcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Normal151_dir = os.path.join(data_dir,'Normal151')\n",
        "TB150_dir = os.path.join(data_dir,'TB150')\n",
        "CA150_dir = os.path.join(data_dir,'CA150')\n",
        "\n",
        "All_3class_dir = os.path.join(data_dir,'All_3class')"
      ],
      "metadata": {
        "id": "xMhNdbHoTxcN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### train 3 class  \n",
        "ข้อมูลใน All_3class_dir รวมภาพทั้ง 3 คลาส รวม 450 ภาพ TB150, Normal151 (เอามาแค่150) และ CA150 (CA คือ lungcancer)"
      ],
      "metadata": {
        "id": "YFVxlpQZf5pU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Normal151_dir = os.path.join(data_dir,'Normal151')\n",
        "TB150_dir = os.path.join(data_dir,'TB150')\n",
        "CA150_dir = os.path.join(data_dir,'CA150')\n",
        "\n",
        "All_3class_dir = os.path.join(data_dir,'All_3class')"
      ],
      "metadata": {
        "id": "8BHyN8YKpwx9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal = []\n",
        "for i in range(len(os.listdir(Normal151_dir))):\n",
        "    img = os.listdir(Normal151_dir)[i]\n",
        "    normal.append(img)\n",
        "    \n",
        "tnormal = pd.DataFrame({'ImageName':[normal][0],\n",
        "                                       'NameType': \"Normal\" ,\n",
        "                                       'NumberType': 0                      })"
      ],
      "metadata": {
        "id": "mT0QF8IgrfVm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuberculosis = []\n",
        "for i in range(len(os.listdir(TB150_dir))):\n",
        "    img = os.listdir(TB150_dir)[i]\n",
        "    tuberculosis.append(img)\n",
        "\n",
        "ttuberculosis = pd.DataFrame({'ImageName':[tuberculosis][0],\n",
        "                                       'NameType': \"Tuberculosis\" ,\n",
        "                                       'NumberType': 1                        })"
      ],
      "metadata": {
        "id": "VtNPg0jwf5pW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lungcancer = []\n",
        "for i in range(len(os.listdir(CA150_dir))):\n",
        "    img = os.listdir(CA150_dir)[i]\n",
        "    lungcancer.append(img)\n",
        "\n",
        "tlungcancer = pd.DataFrame({'ImageName':[lungcancer][0],\n",
        "                                       'NameType': \"Lungcancer\" ,\n",
        "                                       'NumberType': 2                        })"
      ],
      "metadata": {
        "id": "X5pyCUl5mJGV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train3 = pd.concat([tnormal[:-1], ttuberculosis, tlungcancer])\n",
        "data_train3[-3:]"
      ],
      "metadata": {
        "id": "bgArCw5jnwg2",
        "outputId": "ebe9d532-3a6f-4e56-94e5-3968ddf75a4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    ImageName    NameType  NumberType\n",
              "147  ca88.jpg  Lungcancer           2\n",
              "148  ca85.jpg  Lungcancer           2\n",
              "149  ca94.jpg  Lungcancer           2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24535e19-1f53-45cb-91fb-469a90da793f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageName</th>\n",
              "      <th>NameType</th>\n",
              "      <th>NumberType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>ca88.jpg</td>\n",
              "      <td>Lungcancer</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>ca85.jpg</td>\n",
              "      <td>Lungcancer</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>ca94.jpg</td>\n",
              "      <td>Lungcancer</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24535e19-1f53-45cb-91fb-469a90da793f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-24535e19-1f53-45cb-91fb-469a90da793f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-24535e19-1f53-45cb-91fb-469a90da793f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-fold 0-100\n",
        "แก้เป็น k-fold หมดแล้ว \n",
        "เหลือลองรันว่าจะเจ้งมั้ย\n",
        "- 311 layer\n",
        "-   filepath มี .h5 ทุกอัน"
      ],
      "metadata": {
        "id": "4qDyqEDCHxA0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8 \n"
      ],
      "metadata": {
        "id": "lT_PlZpRHxA0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8  soft pre bi\n"
      ],
      "metadata": {
        "id": "4tHlmnjHHxA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 8\n",
        "filepath = \"Kmodel8_soft_pre_bi.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "id": "EAgEARpiKDL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel8_soft_pre_bi{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "S_Bu_V7SKDDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H_Incep.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7gTdnI-0VqX",
        "outputId": "dc411628-02cf-47c8-d433-a8724802c05e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy', 'lr'])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = H_Incep.history['lr']\n",
        "\n",
        "plt.figure(figsize=(20,15))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(lr, label = \" Learning rate\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZdFZUZc0dEI",
        "outputId": "70e4a54c-1e46-4010-8803-52177759b231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f802cdbdd50>]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x1080 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8 soft pre bi adam  \n"
      ],
      "metadata": {
        "id": "XhGoWt8CHxA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 8\n",
        "filepath = \"Kmodel8_soft_pre_bi_adam.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k5-3GpI6epe",
        "outputId": "96b03506-eddb-4c17-f5fe-976c247895dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:06<00:00, 66.43it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel8_soft_pre_bi_adam{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "qTbqFtDF6cwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8 soft pre bi sgd  \n"
      ],
      "metadata": {
        "id": "4CfquesGP-rZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 8\n",
        "filepath = \"Kmodel8_soft_pre_bi_sgd.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b03506-eddb-4c17-f5fe-976c247895dd",
        "id": "gdxYY4UjP-ra"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:06<00:00, 66.43it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel8_soft_pre_bi_sgd{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "uqOS1R8QP-ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8 soft pre cate \n"
      ],
      "metadata": {
        "id": "gIezSP7KHxA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 8\n",
        "filepath = \"Kmodel8_soft_pre_cate.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "8f62ba84-295e-4d23-a2f7-57bc97196ed3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7LqShb-HxA5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:10<00:00, 41.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel8_soft_pre_cate{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "zInSrqiRHxA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8 soft pre cate adam\n"
      ],
      "metadata": {
        "id": "nbfA8plqHxBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 8\n",
        "filepath = \"Kmodel8_soft_pre_cate_adam.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "4ade8ad3-0a08-4391-b9cc-b535897670e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOXzS-frHxBA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:04<00:00, 92.81it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel8_soft_pre_cate_adam{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "8TXqdL-wHxBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8 soft pre cate sgd\n"
      ],
      "metadata": {
        "id": "W_E0EHBiQlIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 8\n",
        "filepath = \"Kmodel8_soft_pre_cate_sgd.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "e0013bf3-aa3f-458d-9cdf-cfef53cc7f9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHY8s-kPQlIK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:15<00:00, 28.30it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel8_soft_pre_cate_sgd{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "xEFeEAyBQlIK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25b81a39-810d-4ecc-f6f1-58b62eaa5a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold #1\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1543 - accuracy: 0.2917\n",
            "Epoch 1: val_accuracy improved from -inf to 0.32222, saving model to  Kmodel8_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd1.h5 /assets\n",
            "45/45 [==============================] - 82s 2s/step - loss: 1.1543 - accuracy: 0.2917 - val_loss: 1.1798 - val_accuracy: 0.3222 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1319 - accuracy: 0.3028\n",
            "Epoch 2: val_accuracy improved from 0.32222 to 0.35556, saving model to  Kmodel8_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd1.h5 /assets\n",
            "45/45 [==============================] - 54s 1s/step - loss: 1.1319 - accuracy: 0.3028 - val_loss: 1.1130 - val_accuracy: 0.3556 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1151 - accuracy: 0.3333\n",
            "Epoch 3: val_accuracy improved from 0.35556 to 0.37778, saving model to  Kmodel8_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd1.h5 /assets\n",
            "45/45 [==============================] - 54s 1s/step - loss: 1.1151 - accuracy: 0.3333 - val_loss: 1.0920 - val_accuracy: 0.3778 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1220 - accuracy: 0.3333\n",
            "Epoch 4: val_accuracy improved from 0.37778 to 0.46667, saving model to  Kmodel8_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd1.h5 /assets\n",
            "45/45 [==============================] - 55s 1s/step - loss: 1.1220 - accuracy: 0.3333 - val_loss: 1.0792 - val_accuracy: 0.4667 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1142 - accuracy: 0.3444\n",
            "Epoch 5: val_accuracy improved from 0.46667 to 0.47778, saving model to  Kmodel8_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd1.h5 /assets\n",
            "45/45 [==============================] - 55s 1s/step - loss: 1.1142 - accuracy: 0.3444 - val_loss: 1.0563 - val_accuracy: 0.4778 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0856 - accuracy: 0.3722\n",
            "Epoch 6: val_accuracy improved from 0.47778 to 0.52222, saving model to  Kmodel8_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd1.h5 /assets\n",
            "45/45 [==============================] - 54s 1s/step - loss: 1.0856 - accuracy: 0.3722 - val_loss: 1.0415 - val_accuracy: 0.5222 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0808 - accuracy: 0.3889\n",
            "Epoch 7: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 13s 281ms/step - loss: 1.0808 - accuracy: 0.3889 - val_loss: 1.0293 - val_accuracy: 0.5222 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0695 - accuracy: 0.4333\n",
            "Epoch 8: val_accuracy improved from 0.52222 to 0.55556, saving model to  Kmodel8_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd1.h5 /assets\n",
            "45/45 [==============================] - 54s 1s/step - loss: 1.0695 - accuracy: 0.4333 - val_loss: 1.0191 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0579 - accuracy: 0.4361\n",
            "Epoch 9: val_accuracy did not improve from 0.55556\n",
            "45/45 [==============================] - 13s 284ms/step - loss: 1.0579 - accuracy: 0.4361 - val_loss: 1.0123 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0496 - accuracy: 0.4750\n",
            "Epoch 10: val_accuracy improved from 0.55556 to 0.56667, saving model to  Kmodel8_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd1.h5 /assets\n",
            "45/45 [==============================] - 54s 1s/step - loss: 1.0496 - accuracy: 0.4750 - val_loss: 1.0021 - val_accuracy: 0.5667 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0269 - accuracy: 0.5306\n",
            "Epoch 11: val_accuracy did not improve from 0.56667\n",
            "45/45 [==============================] - 13s 281ms/step - loss: 1.0269 - accuracy: 0.5306 - val_loss: 0.9937 - val_accuracy: 0.5667 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0232 - accuracy: 0.4806\n",
            "Epoch 12: val_accuracy improved from 0.56667 to 0.58889, saving model to  Kmodel8_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd1.h5 /assets\n",
            "45/45 [==============================] - 54s 1s/step - loss: 1.0232 - accuracy: 0.4806 - val_loss: 0.9829 - val_accuracy: 0.5889 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0414 - accuracy: 0.4972\n",
            "Epoch 13: val_accuracy improved from 0.58889 to 0.60000, saving model to  Kmodel8_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd1.h5 /assets\n",
            "45/45 [==============================] - 53s 1s/step - loss: 1.0414 - accuracy: 0.4972 - val_loss: 0.9763 - val_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0177 - accuracy: 0.4889\n",
            "Epoch 14: val_accuracy did not improve from 0.60000\n",
            "45/45 [==============================] - 13s 285ms/step - loss: 1.0177 - accuracy: 0.4889 - val_loss: 0.9700 - val_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0089 - accuracy: 0.5278\n",
            "Epoch 15: val_accuracy did not improve from 0.60000\n",
            "45/45 [==============================] - 13s 277ms/step - loss: 1.0089 - accuracy: 0.5278 - val_loss: 0.9603 - val_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0022 - accuracy: 0.5278\n",
            "Epoch 16: val_accuracy did not improve from 0.60000\n",
            "45/45 [==============================] - 13s 277ms/step - loss: 1.0022 - accuracy: 0.5278 - val_loss: 0.9509 - val_accuracy: 0.5889 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9868 - accuracy: 0.5778\n",
            "Epoch 17: val_accuracy improved from 0.60000 to 0.61111, saving model to  Kmodel8_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd1.h5 /assets\n",
            "45/45 [==============================] - 53s 1s/step - loss: 0.9868 - accuracy: 0.5778 - val_loss: 0.9444 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9758 - accuracy: 0.6056\n",
            "Epoch 18: val_accuracy did not improve from 0.61111\n",
            "45/45 [==============================] - 13s 289ms/step - loss: 0.9758 - accuracy: 0.6056 - val_loss: 0.9365 - val_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9879 - accuracy: 0.5444\n",
            "Epoch 19: val_accuracy did not improve from 0.61111\n",
            "45/45 [==============================] - 13s 281ms/step - loss: 0.9879 - accuracy: 0.5444 - val_loss: 0.9298 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9658 - accuracy: 0.6056\n",
            "Epoch 20: val_accuracy did not improve from 0.61111\n",
            "45/45 [==============================] - 13s 282ms/step - loss: 0.9658 - accuracy: 0.6056 - val_loss: 0.9230 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9422 - accuracy: 0.6167\n",
            "Epoch 21: val_accuracy improved from 0.61111 to 0.62222, saving model to  Kmodel8_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd1.h5 /assets\n",
            "45/45 [==============================] - 53s 1s/step - loss: 0.9422 - accuracy: 0.6167 - val_loss: 0.9152 - val_accuracy: 0.6222 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9230 - accuracy: 0.6556\n",
            "Epoch 22: val_accuracy did not improve from 0.62222\n",
            "45/45 [==============================] - 13s 287ms/step - loss: 0.9230 - accuracy: 0.6556 - val_loss: 0.9068 - val_accuracy: 0.6222 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9369 - accuracy: 0.6083\n",
            "Epoch 23: val_accuracy did not improve from 0.62222\n",
            "45/45 [==============================] - 13s 284ms/step - loss: 0.9369 - accuracy: 0.6083 - val_loss: 0.9024 - val_accuracy: 0.6222 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9380 - accuracy: 0.6250\n",
            "Epoch 24: val_accuracy did not improve from 0.62222\n",
            "45/45 [==============================] - 13s 290ms/step - loss: 0.9380 - accuracy: 0.6250 - val_loss: 0.8943 - val_accuracy: 0.6222 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9263 - accuracy: 0.6000\n",
            "Epoch 25: val_accuracy did not improve from 0.62222\n",
            "45/45 [==============================] - 13s 288ms/step - loss: 0.9263 - accuracy: 0.6000 - val_loss: 0.8888 - val_accuracy: 0.6222 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9120 - accuracy: 0.6333\n",
            "Epoch 26: val_accuracy did not improve from 0.62222\n",
            "45/45 [==============================] - 13s 281ms/step - loss: 0.9120 - accuracy: 0.6333 - val_loss: 0.8812 - val_accuracy: 0.6222 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8991 - accuracy: 0.6417\n",
            "Epoch 27: val_accuracy did not improve from 0.62222\n",
            "\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "45/45 [==============================] - 13s 284ms/step - loss: 0.8991 - accuracy: 0.6417 - val_loss: 0.8756 - val_accuracy: 0.6222 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8968 - accuracy: 0.6500\n",
            "Epoch 28: val_accuracy improved from 0.62222 to 0.63333, saving model to  Kmodel8_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd1.h5 /assets\n",
            "45/45 [==============================] - 54s 1s/step - loss: 0.8968 - accuracy: 0.6500 - val_loss: 0.8723 - val_accuracy: 0.6333 - lr: 5.0000e-05\n",
            "Epoch 29/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8989 - accuracy: 0.6167\n",
            "Epoch 29: val_accuracy did not improve from 0.63333\n",
            "45/45 [==============================] - 13s 291ms/step - loss: 0.8989 - accuracy: 0.6167 - val_loss: 0.8687 - val_accuracy: 0.6333 - lr: 5.0000e-05\n",
            "Epoch 30/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8997 - accuracy: 0.6583\n",
            "Epoch 30: val_accuracy improved from 0.63333 to 0.65556, saving model to  Kmodel8_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd1.h5 /assets\n",
            "45/45 [==============================] - 55s 1s/step - loss: 0.8997 - accuracy: 0.6583 - val_loss: 0.8656 - val_accuracy: 0.6556 - lr: 5.0000e-05\n",
            "Epoch 31/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8848 - accuracy: 0.6222\n",
            "Epoch 31: val_accuracy did not improve from 0.65556\n",
            "45/45 [==============================] - 13s 286ms/step - loss: 0.8848 - accuracy: 0.6222 - val_loss: 0.8619 - val_accuracy: 0.6444 - lr: 5.0000e-05\n",
            "Epoch 32/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8765 - accuracy: 0.6778\n",
            "Epoch 32: val_accuracy did not improve from 0.65556\n",
            "45/45 [==============================] - 13s 288ms/step - loss: 0.8765 - accuracy: 0.6778 - val_loss: 0.8584 - val_accuracy: 0.6333 - lr: 5.0000e-05\n",
            "Epoch 33/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8910 - accuracy: 0.6389\n",
            "Epoch 33: val_accuracy did not improve from 0.65556\n",
            "45/45 [==============================] - 13s 285ms/step - loss: 0.8910 - accuracy: 0.6389 - val_loss: 0.8546 - val_accuracy: 0.6556 - lr: 5.0000e-05\n",
            "Epoch 34/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8619 - accuracy: 0.6750\n",
            "Epoch 34: val_accuracy did not improve from 0.65556\n",
            "45/45 [==============================] - 13s 295ms/step - loss: 0.8619 - accuracy: 0.6750 - val_loss: 0.8514 - val_accuracy: 0.6444 - lr: 5.0000e-05\n",
            "Epoch 35/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8695 - accuracy: 0.6694\n",
            "Epoch 35: val_accuracy did not improve from 0.65556\n",
            "45/45 [==============================] - 13s 289ms/step - loss: 0.8695 - accuracy: 0.6694 - val_loss: 0.8487 - val_accuracy: 0.6444 - lr: 5.0000e-05\n",
            "Epoch 36/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8856 - accuracy: 0.6694\n",
            "Epoch 36: val_accuracy did not improve from 0.65556\n",
            "\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "45/45 [==============================] - 13s 293ms/step - loss: 0.8856 - accuracy: 0.6694 - val_loss: 0.8450 - val_accuracy: 0.6556 - lr: 5.0000e-05\n",
            "Epoch 37/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8810 - accuracy: 0.6333\n",
            "Epoch 37: val_accuracy improved from 0.65556 to 0.66667, saving model to  Kmodel8_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd1.h5 /assets\n",
            "45/45 [==============================] - 55s 1s/step - loss: 0.8810 - accuracy: 0.6333 - val_loss: 0.8428 - val_accuracy: 0.6667 - lr: 2.5000e-05\n",
            "Epoch 38/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8564 - accuracy: 0.6583\n",
            "Epoch 38: val_accuracy did not improve from 0.66667\n",
            "45/45 [==============================] - 13s 284ms/step - loss: 0.8564 - accuracy: 0.6583 - val_loss: 0.8407 - val_accuracy: 0.6556 - lr: 2.5000e-05\n",
            "Epoch 39/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8778 - accuracy: 0.6611\n",
            "Epoch 39: val_accuracy did not improve from 0.66667\n",
            "45/45 [==============================] - 13s 289ms/step - loss: 0.8778 - accuracy: 0.6611 - val_loss: 0.8396 - val_accuracy: 0.6556 - lr: 2.5000e-05\n",
            "Epoch 40/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8598 - accuracy: 0.6611\n",
            "Epoch 40: val_accuracy did not improve from 0.66667\n",
            "45/45 [==============================] - 13s 286ms/step - loss: 0.8598 - accuracy: 0.6611 - val_loss: 0.8374 - val_accuracy: 0.6667 - lr: 2.5000e-05\n",
            "Epoch 41/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8737 - accuracy: 0.6417\n",
            "Epoch 41: val_accuracy improved from 0.66667 to 0.67778, saving model to  Kmodel8_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd1.h5 /assets\n",
            "45/45 [==============================] - 55s 1s/step - loss: 0.8737 - accuracy: 0.6417 - val_loss: 0.8367 - val_accuracy: 0.6778 - lr: 2.5000e-05\n",
            "Epoch 42/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8555 - accuracy: 0.6472\n",
            "Epoch 42: val_accuracy did not improve from 0.67778\n",
            "45/45 [==============================] - 13s 287ms/step - loss: 0.8555 - accuracy: 0.6472 - val_loss: 0.8358 - val_accuracy: 0.6667 - lr: 2.5000e-05\n",
            "Epoch 43/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8446 - accuracy: 0.6556\n",
            "Epoch 43: val_accuracy did not improve from 0.67778\n",
            "45/45 [==============================] - 13s 287ms/step - loss: 0.8446 - accuracy: 0.6556 - val_loss: 0.8341 - val_accuracy: 0.6556 - lr: 2.5000e-05\n",
            "Epoch 44/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8375 - accuracy: 0.6639\n",
            "Epoch 44: val_accuracy did not improve from 0.67778\n",
            "45/45 [==============================] - 13s 285ms/step - loss: 0.8375 - accuracy: 0.6639 - val_loss: 0.8330 - val_accuracy: 0.6778 - lr: 2.5000e-05\n",
            "Epoch 45/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8357 - accuracy: 0.7028\n",
            "Epoch 45: val_accuracy did not improve from 0.67778\n",
            "45/45 [==============================] - 13s 289ms/step - loss: 0.8357 - accuracy: 0.7028 - val_loss: 0.8307 - val_accuracy: 0.6778 - lr: 2.5000e-05\n",
            "Epoch 46/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8650 - accuracy: 0.6889\n",
            "Epoch 46: val_accuracy did not improve from 0.67778\n",
            "45/45 [==============================] - 13s 291ms/step - loss: 0.8650 - accuracy: 0.6889 - val_loss: 0.8283 - val_accuracy: 0.6778 - lr: 2.5000e-05\n",
            "Epoch 47/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8610 - accuracy: 0.6278\n",
            "Epoch 47: val_accuracy did not improve from 0.67778\n",
            "\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "45/45 [==============================] - 13s 287ms/step - loss: 0.8610 - accuracy: 0.6278 - val_loss: 0.8269 - val_accuracy: 0.6778 - lr: 2.5000e-05\n",
            "Epoch 48/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8505 - accuracy: 0.6750\n",
            "Epoch 48: val_accuracy improved from 0.67778 to 0.68889, saving model to  Kmodel8_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd1.h5 /assets\n",
            "45/45 [==============================] - 55s 1s/step - loss: 0.8505 - accuracy: 0.6750 - val_loss: 0.8255 - val_accuracy: 0.6889 - lr: 1.2500e-05\n",
            "Epoch 49/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8419 - accuracy: 0.6972\n",
            "Epoch 49: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 289ms/step - loss: 0.8419 - accuracy: 0.6972 - val_loss: 0.8262 - val_accuracy: 0.6667 - lr: 1.2500e-05\n",
            "Epoch 50/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8530 - accuracy: 0.6583\n",
            "Epoch 50: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 287ms/step - loss: 0.8530 - accuracy: 0.6583 - val_loss: 0.8282 - val_accuracy: 0.6667 - lr: 1.2500e-05\n",
            "Epoch 51/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8586 - accuracy: 0.6278\n",
            "Epoch 51: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 286ms/step - loss: 0.8586 - accuracy: 0.6278 - val_loss: 0.8252 - val_accuracy: 0.6667 - lr: 1.2500e-05\n",
            "Epoch 52/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8204 - accuracy: 0.6972\n",
            "Epoch 52: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 290ms/step - loss: 0.8204 - accuracy: 0.6972 - val_loss: 0.8247 - val_accuracy: 0.6667 - lr: 1.2500e-05\n",
            "Epoch 53/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8420 - accuracy: 0.6639\n",
            "Epoch 53: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 290ms/step - loss: 0.8420 - accuracy: 0.6639 - val_loss: 0.8243 - val_accuracy: 0.6889 - lr: 1.2500e-05\n",
            "Epoch 54/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8433 - accuracy: 0.6667\n",
            "Epoch 54: val_accuracy did not improve from 0.68889\n",
            "\n",
            "Epoch 54: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "45/45 [==============================] - 12s 272ms/step - loss: 0.8433 - accuracy: 0.6667 - val_loss: 0.8238 - val_accuracy: 0.6444 - lr: 1.2500e-05\n",
            "Epoch 55/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8523 - accuracy: 0.6639\n",
            "Epoch 55: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 284ms/step - loss: 0.8523 - accuracy: 0.6639 - val_loss: 0.8230 - val_accuracy: 0.6444 - lr: 1.0000e-05\n",
            "Epoch 56/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8332 - accuracy: 0.6722\n",
            "Epoch 56: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 294ms/step - loss: 0.8332 - accuracy: 0.6722 - val_loss: 0.8238 - val_accuracy: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 57/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8458 - accuracy: 0.7000\n",
            "Epoch 57: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 284ms/step - loss: 0.8458 - accuracy: 0.7000 - val_loss: 0.8233 - val_accuracy: 0.6444 - lr: 1.0000e-05\n",
            "Epoch 58/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8429 - accuracy: 0.6361\n",
            "Epoch 58: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 283ms/step - loss: 0.8429 - accuracy: 0.6361 - val_loss: 0.8227 - val_accuracy: 0.6444 - lr: 1.0000e-05\n",
            "Epoch 59/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8521 - accuracy: 0.6917\n",
            "Epoch 59: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 287ms/step - loss: 0.8521 - accuracy: 0.6917 - val_loss: 0.8208 - val_accuracy: 0.6444 - lr: 1.0000e-05\n",
            "Epoch 60/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8288 - accuracy: 0.6833\n",
            "Epoch 60: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 290ms/step - loss: 0.8288 - accuracy: 0.6833 - val_loss: 0.8192 - val_accuracy: 0.6556 - lr: 1.0000e-05\n",
            "Epoch 61/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8542 - accuracy: 0.6583\n",
            "Epoch 61: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 284ms/step - loss: 0.8542 - accuracy: 0.6583 - val_loss: 0.8182 - val_accuracy: 0.6444 - lr: 1.0000e-05\n",
            "Epoch 62/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8456 - accuracy: 0.6778\n",
            "Epoch 62: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 287ms/step - loss: 0.8456 - accuracy: 0.6778 - val_loss: 0.8155 - val_accuracy: 0.6444 - lr: 1.0000e-05\n",
            "Epoch 63/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8536 - accuracy: 0.6556\n",
            "Epoch 63: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 288ms/step - loss: 0.8536 - accuracy: 0.6556 - val_loss: 0.8172 - val_accuracy: 0.6556 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.58      0.50      0.54        28\n",
            "      Normal       0.76      1.00      0.86        31\n",
            "Tuberculosis       0.56      0.45      0.50        31\n",
            "\n",
            "    accuracy                           0.66        90\n",
            "   macro avg       0.63      0.65      0.63        90\n",
            "weighted avg       0.63      0.66      0.64        90\n",
            "\n",
            "Fold #2\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8475 - accuracy: 0.6806\n",
            "Epoch 1: val_accuracy improved from -inf to 0.71111, saving model to  Kmodel8_soft_pre_cate_sgd2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd2.h5 /assets\n",
            "45/45 [==============================] - 53s 1s/step - loss: 0.8475 - accuracy: 0.6806 - val_loss: 0.7793 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8313 - accuracy: 0.6556\n",
            "Epoch 2: val_accuracy did not improve from 0.71111\n",
            "45/45 [==============================] - 13s 285ms/step - loss: 0.8313 - accuracy: 0.6556 - val_loss: 0.7780 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8455 - accuracy: 0.6556\n",
            "Epoch 3: val_accuracy did not improve from 0.71111\n",
            "45/45 [==============================] - 13s 288ms/step - loss: 0.8455 - accuracy: 0.6556 - val_loss: 0.7788 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8325 - accuracy: 0.7056\n",
            "Epoch 4: val_accuracy did not improve from 0.71111\n",
            "45/45 [==============================] - 13s 285ms/step - loss: 0.8325 - accuracy: 0.7056 - val_loss: 0.7750 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8532 - accuracy: 0.6750\n",
            "Epoch 5: val_accuracy did not improve from 0.71111\n",
            "45/45 [==============================] - 13s 290ms/step - loss: 0.8532 - accuracy: 0.6750 - val_loss: 0.7762 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8432 - accuracy: 0.6861\n",
            "Epoch 6: val_accuracy did not improve from 0.71111\n",
            "45/45 [==============================] - 14s 302ms/step - loss: 0.8432 - accuracy: 0.6861 - val_loss: 0.7761 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8321 - accuracy: 0.6944\n",
            "Epoch 7: val_accuracy did not improve from 0.71111\n",
            "45/45 [==============================] - 13s 292ms/step - loss: 0.8321 - accuracy: 0.6944 - val_loss: 0.7760 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8542 - accuracy: 0.6389\n",
            "Epoch 8: val_accuracy did not improve from 0.71111\n",
            "45/45 [==============================] - 13s 287ms/step - loss: 0.8542 - accuracy: 0.6389 - val_loss: 0.7728 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8492 - accuracy: 0.6306\n",
            "Epoch 9: val_accuracy improved from 0.71111 to 0.72222, saving model to  Kmodel8_soft_pre_cate_sgd2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd2.h5 /assets\n",
            "45/45 [==============================] - 55s 1s/step - loss: 0.8492 - accuracy: 0.6306 - val_loss: 0.7739 - val_accuracy: 0.7222 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8480 - accuracy: 0.6278\n",
            "Epoch 10: val_accuracy did not improve from 0.72222\n",
            "45/45 [==============================] - 13s 291ms/step - loss: 0.8480 - accuracy: 0.6278 - val_loss: 0.7737 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8417 - accuracy: 0.6639\n",
            "Epoch 11: val_accuracy did not improve from 0.72222\n",
            "45/45 [==============================] - 13s 285ms/step - loss: 0.8417 - accuracy: 0.6639 - val_loss: 0.7753 - val_accuracy: 0.7000 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8391 - accuracy: 0.6833\n",
            "Epoch 12: val_accuracy did not improve from 0.72222\n",
            "45/45 [==============================] - 13s 292ms/step - loss: 0.8391 - accuracy: 0.6833 - val_loss: 0.7728 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8450 - accuracy: 0.6611\n",
            "Epoch 13: val_accuracy did not improve from 0.72222\n",
            "45/45 [==============================] - 13s 287ms/step - loss: 0.8450 - accuracy: 0.6611 - val_loss: 0.7708 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8372 - accuracy: 0.6750\n",
            "Epoch 14: val_accuracy did not improve from 0.72222\n",
            "45/45 [==============================] - 13s 277ms/step - loss: 0.8372 - accuracy: 0.6750 - val_loss: 0.7706 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8335 - accuracy: 0.7056\n",
            "Epoch 15: val_accuracy did not improve from 0.72222\n",
            "45/45 [==============================] - 13s 286ms/step - loss: 0.8335 - accuracy: 0.7056 - val_loss: 0.7697 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8234 - accuracy: 0.6917\n",
            "Epoch 16: val_accuracy did not improve from 0.72222\n",
            "45/45 [==============================] - 13s 291ms/step - loss: 0.8234 - accuracy: 0.6917 - val_loss: 0.7704 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8344 - accuracy: 0.6694\n",
            "Epoch 17: val_accuracy did not improve from 0.72222\n",
            "45/45 [==============================] - 13s 288ms/step - loss: 0.8344 - accuracy: 0.6694 - val_loss: 0.7698 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8327 - accuracy: 0.6639\n",
            "Epoch 18: val_accuracy did not improve from 0.72222\n",
            "45/45 [==============================] - 13s 279ms/step - loss: 0.8327 - accuracy: 0.6639 - val_loss: 0.7690 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8494 - accuracy: 0.6500\n",
            "Epoch 19: val_accuracy did not improve from 0.72222\n",
            "45/45 [==============================] - 13s 286ms/step - loss: 0.8494 - accuracy: 0.6500 - val_loss: 0.7676 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8303 - accuracy: 0.6944\n",
            "Epoch 20: val_accuracy did not improve from 0.72222\n",
            "45/45 [==============================] - 13s 294ms/step - loss: 0.8303 - accuracy: 0.6944 - val_loss: 0.7667 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8424 - accuracy: 0.6722\n",
            "Epoch 21: val_accuracy did not improve from 0.72222\n",
            "45/45 [==============================] - 13s 279ms/step - loss: 0.8424 - accuracy: 0.6722 - val_loss: 0.7660 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8203 - accuracy: 0.6917\n",
            "Epoch 22: val_accuracy did not improve from 0.72222\n",
            "45/45 [==============================] - 13s 282ms/step - loss: 0.8203 - accuracy: 0.6917 - val_loss: 0.7637 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8357 - accuracy: 0.6806\n",
            "Epoch 23: val_accuracy did not improve from 0.72222\n",
            "45/45 [==============================] - 13s 289ms/step - loss: 0.8357 - accuracy: 0.6806 - val_loss: 0.7650 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8243 - accuracy: 0.6750\n",
            "Epoch 24: val_accuracy did not improve from 0.72222\n",
            "45/45 [==============================] - 13s 285ms/step - loss: 0.8243 - accuracy: 0.6750 - val_loss: 0.7663 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.73      0.65      0.69        34\n",
            "      Normal       0.68      0.93      0.78        27\n",
            "Tuberculosis       0.74      0.59      0.65        29\n",
            "\n",
            "    accuracy                           0.71        90\n",
            "   macro avg       0.72      0.72      0.71        90\n",
            "weighted avg       0.72      0.71      0.70        90\n",
            "\n",
            "Fold #3\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8385 - accuracy: 0.6861\n",
            "Epoch 1: val_accuracy improved from -inf to 0.71111, saving model to  Kmodel8_soft_pre_cate_sgd3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd3.h5 /assets\n",
            "45/45 [==============================] - 53s 1s/step - loss: 0.8385 - accuracy: 0.6861 - val_loss: 0.7485 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8270 - accuracy: 0.6806\n",
            "Epoch 2: val_accuracy improved from 0.71111 to 0.72222, saving model to  Kmodel8_soft_pre_cate_sgd3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd3.h5 /assets\n",
            "45/45 [==============================] - 54s 1s/step - loss: 0.8270 - accuracy: 0.6806 - val_loss: 0.7491 - val_accuracy: 0.7222 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8240 - accuracy: 0.6667\n",
            "Epoch 3: val_accuracy did not improve from 0.72222\n",
            "45/45 [==============================] - 13s 288ms/step - loss: 0.8240 - accuracy: 0.6667 - val_loss: 0.7501 - val_accuracy: 0.7222 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8328 - accuracy: 0.6611\n",
            "Epoch 4: val_accuracy did not improve from 0.72222\n",
            "45/45 [==============================] - 13s 291ms/step - loss: 0.8328 - accuracy: 0.6611 - val_loss: 0.7471 - val_accuracy: 0.7222 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8225 - accuracy: 0.6972\n",
            "Epoch 5: val_accuracy did not improve from 0.72222\n",
            "45/45 [==============================] - 13s 285ms/step - loss: 0.8225 - accuracy: 0.6972 - val_loss: 0.7479 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8409 - accuracy: 0.6750\n",
            "Epoch 6: val_accuracy did not improve from 0.72222\n",
            "45/45 [==============================] - 13s 285ms/step - loss: 0.8409 - accuracy: 0.6750 - val_loss: 0.7476 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8224 - accuracy: 0.6667\n",
            "Epoch 7: val_accuracy did not improve from 0.72222\n",
            "45/45 [==============================] - 13s 284ms/step - loss: 0.8224 - accuracy: 0.6667 - val_loss: 0.7480 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8367 - accuracy: 0.6417\n",
            "Epoch 8: val_accuracy did not improve from 0.72222\n",
            "45/45 [==============================] - 13s 292ms/step - loss: 0.8367 - accuracy: 0.6417 - val_loss: 0.7478 - val_accuracy: 0.7222 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8309 - accuracy: 0.6389\n",
            "Epoch 9: val_accuracy did not improve from 0.72222\n",
            "45/45 [==============================] - 13s 288ms/step - loss: 0.8309 - accuracy: 0.6389 - val_loss: 0.7461 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8061 - accuracy: 0.6750\n",
            "Epoch 10: val_accuracy did not improve from 0.72222\n",
            "45/45 [==============================] - 13s 283ms/step - loss: 0.8061 - accuracy: 0.6750 - val_loss: 0.7439 - val_accuracy: 0.7222 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8195 - accuracy: 0.6528\n",
            "Epoch 11: val_accuracy did not improve from 0.72222\n",
            "45/45 [==============================] - 13s 282ms/step - loss: 0.8195 - accuracy: 0.6528 - val_loss: 0.7427 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8187 - accuracy: 0.6722\n",
            "Epoch 12: val_accuracy improved from 0.72222 to 0.74444, saving model to  Kmodel8_soft_pre_cate_sgd3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd3.h5 /assets\n",
            "45/45 [==============================] - 53s 1s/step - loss: 0.8187 - accuracy: 0.6722 - val_loss: 0.7417 - val_accuracy: 0.7444 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8281 - accuracy: 0.6611\n",
            "Epoch 13: val_accuracy did not improve from 0.74444\n",
            "45/45 [==============================] - 13s 285ms/step - loss: 0.8281 - accuracy: 0.6611 - val_loss: 0.7407 - val_accuracy: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7785 - accuracy: 0.7111\n",
            "Epoch 14: val_accuracy did not improve from 0.74444\n",
            "45/45 [==============================] - 13s 286ms/step - loss: 0.7785 - accuracy: 0.7111 - val_loss: 0.7406 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8258 - accuracy: 0.6639\n",
            "Epoch 15: val_accuracy did not improve from 0.74444\n",
            "45/45 [==============================] - 13s 286ms/step - loss: 0.8258 - accuracy: 0.6639 - val_loss: 0.7404 - val_accuracy: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7912 - accuracy: 0.7083\n",
            "Epoch 16: val_accuracy did not improve from 0.74444\n",
            "45/45 [==============================] - 13s 290ms/step - loss: 0.7912 - accuracy: 0.7083 - val_loss: 0.7401 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8146 - accuracy: 0.6861\n",
            "Epoch 17: val_accuracy did not improve from 0.74444\n",
            "45/45 [==============================] - 13s 287ms/step - loss: 0.8146 - accuracy: 0.6861 - val_loss: 0.7393 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8203 - accuracy: 0.6639\n",
            "Epoch 18: val_accuracy did not improve from 0.74444\n",
            "45/45 [==============================] - 13s 286ms/step - loss: 0.8203 - accuracy: 0.6639 - val_loss: 0.7392 - val_accuracy: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8206 - accuracy: 0.6694\n",
            "Epoch 19: val_accuracy did not improve from 0.74444\n",
            "45/45 [==============================] - 13s 289ms/step - loss: 0.8206 - accuracy: 0.6694 - val_loss: 0.7384 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8109 - accuracy: 0.6861\n",
            "Epoch 20: val_accuracy did not improve from 0.74444\n",
            "45/45 [==============================] - 13s 293ms/step - loss: 0.8109 - accuracy: 0.6861 - val_loss: 0.7389 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8236 - accuracy: 0.7000\n",
            "Epoch 21: val_accuracy did not improve from 0.74444\n",
            "45/45 [==============================] - 13s 287ms/step - loss: 0.8236 - accuracy: 0.7000 - val_loss: 0.7365 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8161 - accuracy: 0.6722\n",
            "Epoch 22: val_accuracy did not improve from 0.74444\n",
            "45/45 [==============================] - 13s 289ms/step - loss: 0.8161 - accuracy: 0.6722 - val_loss: 0.7365 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7963 - accuracy: 0.7194\n",
            "Epoch 23: val_accuracy did not improve from 0.74444\n",
            "45/45 [==============================] - 13s 292ms/step - loss: 0.7963 - accuracy: 0.7194 - val_loss: 0.7374 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8169 - accuracy: 0.6806\n",
            "Epoch 24: val_accuracy did not improve from 0.74444\n",
            "45/45 [==============================] - 13s 290ms/step - loss: 0.8169 - accuracy: 0.6806 - val_loss: 0.7371 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7980 - accuracy: 0.7111\n",
            "Epoch 25: val_accuracy did not improve from 0.74444\n",
            "45/45 [==============================] - 13s 289ms/step - loss: 0.7980 - accuracy: 0.7111 - val_loss: 0.7365 - val_accuracy: 0.7222 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8138 - accuracy: 0.6889\n",
            "Epoch 26: val_accuracy did not improve from 0.74444\n",
            "45/45 [==============================] - 13s 293ms/step - loss: 0.8138 - accuracy: 0.6889 - val_loss: 0.7355 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 27/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8193 - accuracy: 0.6556\n",
            "Epoch 27: val_accuracy did not improve from 0.74444\n",
            "45/45 [==============================] - 13s 291ms/step - loss: 0.8193 - accuracy: 0.6556 - val_loss: 0.7364 - val_accuracy: 0.7222 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.71      0.74      0.73        27\n",
            "      Normal       0.76      0.85      0.80        33\n",
            "Tuberculosis       0.68      0.57      0.62        30\n",
            "\n",
            "    accuracy                           0.72        90\n",
            "   macro avg       0.72      0.72      0.72        90\n",
            "weighted avg       0.72      0.72      0.72        90\n",
            "\n",
            "Fold #4\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8118 - accuracy: 0.6972\n",
            "Epoch 1: val_accuracy improved from -inf to 0.67778, saving model to  Kmodel8_soft_pre_cate_sgd4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd4.h5 /assets\n",
            "45/45 [==============================] - 56s 1s/step - loss: 0.8118 - accuracy: 0.6972 - val_loss: 0.7686 - val_accuracy: 0.6778 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8060 - accuracy: 0.6806\n",
            "Epoch 2: val_accuracy did not improve from 0.67778\n",
            "45/45 [==============================] - 13s 289ms/step - loss: 0.8060 - accuracy: 0.6806 - val_loss: 0.7687 - val_accuracy: 0.6778 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7727 - accuracy: 0.7444\n",
            "Epoch 3: val_accuracy did not improve from 0.67778\n",
            "45/45 [==============================] - 13s 290ms/step - loss: 0.7727 - accuracy: 0.7444 - val_loss: 0.7694 - val_accuracy: 0.6778 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8157 - accuracy: 0.7056\n",
            "Epoch 4: val_accuracy did not improve from 0.67778\n",
            "45/45 [==============================] - 13s 282ms/step - loss: 0.8157 - accuracy: 0.7056 - val_loss: 0.7683 - val_accuracy: 0.6778 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8137 - accuracy: 0.6750\n",
            "Epoch 5: val_accuracy did not improve from 0.67778\n",
            "45/45 [==============================] - 13s 283ms/step - loss: 0.8137 - accuracy: 0.6750 - val_loss: 0.7680 - val_accuracy: 0.6778 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8142 - accuracy: 0.6583\n",
            "Epoch 6: val_accuracy did not improve from 0.67778\n",
            "45/45 [==============================] - 13s 287ms/step - loss: 0.8142 - accuracy: 0.6583 - val_loss: 0.7665 - val_accuracy: 0.6778 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8049 - accuracy: 0.6889\n",
            "Epoch 7: val_accuracy did not improve from 0.67778\n",
            "45/45 [==============================] - 13s 291ms/step - loss: 0.8049 - accuracy: 0.6889 - val_loss: 0.7659 - val_accuracy: 0.6778 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8351 - accuracy: 0.6778\n",
            "Epoch 8: val_accuracy improved from 0.67778 to 0.68889, saving model to  Kmodel8_soft_pre_cate_sgd4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd4.h5 /assets\n",
            "45/45 [==============================] - 55s 1s/step - loss: 0.8351 - accuracy: 0.6778 - val_loss: 0.7660 - val_accuracy: 0.6889 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8301 - accuracy: 0.6583\n",
            "Epoch 9: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 290ms/step - loss: 0.8301 - accuracy: 0.6583 - val_loss: 0.7634 - val_accuracy: 0.6889 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8246 - accuracy: 0.6694\n",
            "Epoch 10: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 292ms/step - loss: 0.8246 - accuracy: 0.6694 - val_loss: 0.7624 - val_accuracy: 0.6778 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8390 - accuracy: 0.6611\n",
            "Epoch 11: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 288ms/step - loss: 0.8390 - accuracy: 0.6611 - val_loss: 0.7623 - val_accuracy: 0.6889 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7963 - accuracy: 0.6833\n",
            "Epoch 12: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 291ms/step - loss: 0.7963 - accuracy: 0.6833 - val_loss: 0.7628 - val_accuracy: 0.6889 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8042 - accuracy: 0.7139\n",
            "Epoch 13: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 294ms/step - loss: 0.8042 - accuracy: 0.7139 - val_loss: 0.7631 - val_accuracy: 0.6889 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8023 - accuracy: 0.6833\n",
            "Epoch 14: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 290ms/step - loss: 0.8023 - accuracy: 0.6833 - val_loss: 0.7638 - val_accuracy: 0.6778 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8014 - accuracy: 0.7000\n",
            "Epoch 15: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 288ms/step - loss: 0.8014 - accuracy: 0.7000 - val_loss: 0.7614 - val_accuracy: 0.6778 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8034 - accuracy: 0.6806\n",
            "Epoch 16: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 293ms/step - loss: 0.8034 - accuracy: 0.6806 - val_loss: 0.7626 - val_accuracy: 0.6778 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8014 - accuracy: 0.7056\n",
            "Epoch 17: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 14s 304ms/step - loss: 0.8014 - accuracy: 0.7056 - val_loss: 0.7612 - val_accuracy: 0.6778 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7799 - accuracy: 0.6806\n",
            "Epoch 18: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 283ms/step - loss: 0.7799 - accuracy: 0.6806 - val_loss: 0.7625 - val_accuracy: 0.6778 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7951 - accuracy: 0.7056\n",
            "Epoch 19: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 285ms/step - loss: 0.7951 - accuracy: 0.7056 - val_loss: 0.7619 - val_accuracy: 0.6778 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8054 - accuracy: 0.7056\n",
            "Epoch 20: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 289ms/step - loss: 0.8054 - accuracy: 0.7056 - val_loss: 0.7605 - val_accuracy: 0.6889 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8112 - accuracy: 0.6861\n",
            "Epoch 21: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 282ms/step - loss: 0.8112 - accuracy: 0.6861 - val_loss: 0.7605 - val_accuracy: 0.6778 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7922 - accuracy: 0.6972\n",
            "Epoch 22: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 13s 286ms/step - loss: 0.7922 - accuracy: 0.6972 - val_loss: 0.7582 - val_accuracy: 0.6889 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8062 - accuracy: 0.6806\n",
            "Epoch 23: val_accuracy did not improve from 0.68889\n",
            "45/45 [==============================] - 14s 298ms/step - loss: 0.8062 - accuracy: 0.6806 - val_loss: 0.7580 - val_accuracy: 0.6778 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.65      0.67      0.66        30\n",
            "      Normal       0.73      0.97      0.83        31\n",
            "Tuberculosis       0.61      0.38      0.47        29\n",
            "\n",
            "    accuracy                           0.68        90\n",
            "   macro avg       0.66      0.67      0.65        90\n",
            "weighted avg       0.66      0.68      0.66        90\n",
            "\n",
            "Fold #5\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8166 - accuracy: 0.6583\n",
            "Epoch 1: val_accuracy improved from -inf to 0.77778, saving model to  Kmodel8_soft_pre_cate_sgd5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd5.h5 /assets\n",
            "45/45 [==============================] - 54s 1s/step - loss: 0.8166 - accuracy: 0.6583 - val_loss: 0.7347 - val_accuracy: 0.7778 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8165 - accuracy: 0.6389\n",
            "Epoch 2: val_accuracy improved from 0.77778 to 0.78889, saving model to  Kmodel8_soft_pre_cate_sgd5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd5.h5 /assets\n",
            "45/45 [==============================] - 54s 1s/step - loss: 0.8165 - accuracy: 0.6389 - val_loss: 0.7330 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8056 - accuracy: 0.6750\n",
            "Epoch 3: val_accuracy did not improve from 0.78889\n",
            "45/45 [==============================] - 13s 281ms/step - loss: 0.8056 - accuracy: 0.6750 - val_loss: 0.7321 - val_accuracy: 0.7778 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8147 - accuracy: 0.6444\n",
            "Epoch 4: val_accuracy did not improve from 0.78889\n",
            "45/45 [==============================] - 13s 287ms/step - loss: 0.8147 - accuracy: 0.6444 - val_loss: 0.7312 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8058 - accuracy: 0.6889\n",
            "Epoch 5: val_accuracy did not improve from 0.78889\n",
            "45/45 [==============================] - 13s 289ms/step - loss: 0.8058 - accuracy: 0.6889 - val_loss: 0.7320 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7739 - accuracy: 0.7194\n",
            "Epoch 6: val_accuracy did not improve from 0.78889\n",
            "45/45 [==============================] - 13s 285ms/step - loss: 0.7739 - accuracy: 0.7194 - val_loss: 0.7326 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8046 - accuracy: 0.6917\n",
            "Epoch 7: val_accuracy did not improve from 0.78889\n",
            "45/45 [==============================] - 13s 286ms/step - loss: 0.8046 - accuracy: 0.6917 - val_loss: 0.7314 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7824 - accuracy: 0.7278\n",
            "Epoch 8: val_accuracy did not improve from 0.78889\n",
            "45/45 [==============================] - 13s 295ms/step - loss: 0.7824 - accuracy: 0.7278 - val_loss: 0.7309 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7968 - accuracy: 0.6972\n",
            "Epoch 9: val_accuracy did not improve from 0.78889\n",
            "45/45 [==============================] - 13s 286ms/step - loss: 0.7968 - accuracy: 0.6972 - val_loss: 0.7303 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8045 - accuracy: 0.6639\n",
            "Epoch 10: val_accuracy improved from 0.78889 to 0.80000, saving model to  Kmodel8_soft_pre_cate_sgd5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd5.h5 /assets\n",
            "45/45 [==============================] - 54s 1s/step - loss: 0.8045 - accuracy: 0.6639 - val_loss: 0.7297 - val_accuracy: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7984 - accuracy: 0.6639\n",
            "Epoch 11: val_accuracy improved from 0.80000 to 0.81111, saving model to  Kmodel8_soft_pre_cate_sgd5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_sgd5.h5 /assets\n",
            "45/45 [==============================] - 55s 1s/step - loss: 0.7984 - accuracy: 0.6639 - val_loss: 0.7291 - val_accuracy: 0.8111 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7930 - accuracy: 0.6944\n",
            "Epoch 12: val_accuracy did not improve from 0.81111\n",
            "45/45 [==============================] - 13s 292ms/step - loss: 0.7930 - accuracy: 0.6944 - val_loss: 0.7273 - val_accuracy: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7864 - accuracy: 0.7111\n",
            "Epoch 13: val_accuracy did not improve from 0.81111\n",
            "45/45 [==============================] - 13s 291ms/step - loss: 0.7864 - accuracy: 0.7111 - val_loss: 0.7284 - val_accuracy: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7986 - accuracy: 0.6639\n",
            "Epoch 14: val_accuracy did not improve from 0.81111\n",
            "45/45 [==============================] - 13s 287ms/step - loss: 0.7986 - accuracy: 0.6639 - val_loss: 0.7278 - val_accuracy: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7924 - accuracy: 0.6750\n",
            "Epoch 15: val_accuracy did not improve from 0.81111\n",
            "45/45 [==============================] - 13s 295ms/step - loss: 0.7924 - accuracy: 0.6750 - val_loss: 0.7257 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8128 - accuracy: 0.6778\n",
            "Epoch 16: val_accuracy did not improve from 0.81111\n",
            "45/45 [==============================] - 14s 298ms/step - loss: 0.8128 - accuracy: 0.6778 - val_loss: 0.7259 - val_accuracy: 0.8111 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7803 - accuracy: 0.6750\n",
            "Epoch 17: val_accuracy did not improve from 0.81111\n",
            "45/45 [==============================] - 13s 295ms/step - loss: 0.7803 - accuracy: 0.6750 - val_loss: 0.7273 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8034 - accuracy: 0.6667\n",
            "Epoch 18: val_accuracy did not improve from 0.81111\n",
            "45/45 [==============================] - 14s 298ms/step - loss: 0.8034 - accuracy: 0.6667 - val_loss: 0.7255 - val_accuracy: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8077 - accuracy: 0.6778\n",
            "Epoch 19: val_accuracy did not improve from 0.81111\n",
            "45/45 [==============================] - 14s 300ms/step - loss: 0.8077 - accuracy: 0.6778 - val_loss: 0.7265 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7806 - accuracy: 0.6889\n",
            "Epoch 20: val_accuracy did not improve from 0.81111\n",
            "45/45 [==============================] - 13s 288ms/step - loss: 0.7806 - accuracy: 0.6889 - val_loss: 0.7268 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8005 - accuracy: 0.6861\n",
            "Epoch 21: val_accuracy did not improve from 0.81111\n",
            "45/45 [==============================] - 13s 293ms/step - loss: 0.8005 - accuracy: 0.6861 - val_loss: 0.7248 - val_accuracy: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7898 - accuracy: 0.7056\n",
            "Epoch 22: val_accuracy did not improve from 0.81111\n",
            "45/45 [==============================] - 13s 295ms/step - loss: 0.7898 - accuracy: 0.7056 - val_loss: 0.7246 - val_accuracy: 0.8111 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7936 - accuracy: 0.6806\n",
            "Epoch 23: val_accuracy did not improve from 0.81111\n",
            "45/45 [==============================] - 13s 294ms/step - loss: 0.7936 - accuracy: 0.6806 - val_loss: 0.7243 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7946 - accuracy: 0.6528\n",
            "Epoch 24: val_accuracy did not improve from 0.81111\n",
            "45/45 [==============================] - 13s 291ms/step - loss: 0.7946 - accuracy: 0.6528 - val_loss: 0.7219 - val_accuracy: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8088 - accuracy: 0.6583\n",
            "Epoch 25: val_accuracy did not improve from 0.81111\n",
            "45/45 [==============================] - 13s 296ms/step - loss: 0.8088 - accuracy: 0.6583 - val_loss: 0.7234 - val_accuracy: 0.8111 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7823 - accuracy: 0.7111\n",
            "Epoch 26: val_accuracy did not improve from 0.81111\n",
            "45/45 [==============================] - 13s 296ms/step - loss: 0.7823 - accuracy: 0.7111 - val_loss: 0.7214 - val_accuracy: 0.8000 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.80      0.77      0.79        31\n",
            "      Normal       0.75      0.96      0.84        28\n",
            "Tuberculosis       0.88      0.68      0.76        31\n",
            "\n",
            "    accuracy                           0.80        90\n",
            "   macro avg       0.81      0.81      0.80        90\n",
            "weighted avg       0.81      0.80      0.80        90\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.70      0.67      0.68       150\n",
            "      Normal       0.73      0.94      0.82       150\n",
            "Tuberculosis       0.70      0.53      0.60       150\n",
            "\n",
            "    accuracy                           0.71       450\n",
            "   macro avg       0.71      0.71      0.70       450\n",
            "weighted avg       0.71      0.71      0.70       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 16\n"
      ],
      "metadata": {
        "id": "AdgXpLcnREHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 16  soft pre bi\n"
      ],
      "metadata": {
        "id": "NZUvi2SEREHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 16\n",
        "filepath = \"Kmodel16_soft_pre_bi.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "id": "L5EfGRXwREHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel16_soft_pre_bi{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "wzmw0gyPREHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 16 soft pre bi adam  \n"
      ],
      "metadata": {
        "id": "2hRe1jTCREHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 16\n",
        "filepath = \"Kmodel16_soft_pre_bi_adam.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b03506-eddb-4c17-f5fe-976c247895dd",
        "id": "UDNgWM_ZREHq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:06<00:00, 66.43it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel16_soft_pre_bi_adam{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "OoraKn4qREHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 16 soft pre bi sgd  \n"
      ],
      "metadata": {
        "id": "oiU4sPwaREHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 16\n",
        "filepath = \"Kmodel16_soft_pre_bi_sgd.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad1ae712-5aa4-4237-f149-1ca441d93f50",
        "id": "Wd75Y7DjREHr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [01:50<00:00,  4.08it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel16_soft_pre_bi_sgd{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "vc536jz1REHs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d58a5b2-96fd-4227-d3be-91c03b1a0e20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "87924736/87910968 [==============================] - 1s 0us/step\n",
            "Fold #1\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.7646 - accuracy: 0.3634\n",
            "Epoch 1: val_accuracy improved from -inf to 0.34444, saving model to  Kmodel16_soft_pre_bi_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_sgd1.h5 /assets\n",
            "22/22 [==============================] - 72s 3s/step - loss: 0.7646 - accuracy: 0.3634 - val_loss: 0.7279 - val_accuracy: 0.3444 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.7555 - accuracy: 0.3372\n",
            "Epoch 2: val_accuracy did not improve from 0.34444\n",
            "22/22 [==============================] - 11s 478ms/step - loss: 0.7555 - accuracy: 0.3372 - val_loss: 0.7234 - val_accuracy: 0.3000 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.7471 - accuracy: 0.3576\n",
            "Epoch 3: val_accuracy did not improve from 0.34444\n",
            "22/22 [==============================] - 11s 471ms/step - loss: 0.7471 - accuracy: 0.3576 - val_loss: 0.7191 - val_accuracy: 0.2667 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.7377 - accuracy: 0.3866\n",
            "Epoch 4: val_accuracy improved from 0.34444 to 0.35556, saving model to  Kmodel16_soft_pre_bi_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_sgd1.h5 /assets\n",
            "22/22 [==============================] - 44s 2s/step - loss: 0.7377 - accuracy: 0.3866 - val_loss: 0.7153 - val_accuracy: 0.3556 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.7327 - accuracy: 0.3750\n",
            "Epoch 5: val_accuracy did not improve from 0.35556\n",
            "22/22 [==============================] - 11s 480ms/step - loss: 0.7327 - accuracy: 0.3750 - val_loss: 0.7131 - val_accuracy: 0.3556 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.7273 - accuracy: 0.3837\n",
            "Epoch 6: val_accuracy did not improve from 0.35556\n",
            "22/22 [==============================] - 11s 472ms/step - loss: 0.7273 - accuracy: 0.3837 - val_loss: 0.7129 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.7185 - accuracy: 0.3517\n",
            "Epoch 7: val_accuracy improved from 0.35556 to 0.37778, saving model to  Kmodel16_soft_pre_bi_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_sgd1.h5 /assets\n",
            "22/22 [==============================] - 44s 2s/step - loss: 0.7185 - accuracy: 0.3517 - val_loss: 0.7131 - val_accuracy: 0.3778 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.7159 - accuracy: 0.3605\n",
            "Epoch 8: val_accuracy did not improve from 0.37778\n",
            "22/22 [==============================] - 11s 473ms/step - loss: 0.7159 - accuracy: 0.3605 - val_loss: 0.7093 - val_accuracy: 0.3778 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.7113 - accuracy: 0.3750\n",
            "Epoch 9: val_accuracy did not improve from 0.37778\n",
            "22/22 [==============================] - 11s 474ms/step - loss: 0.7113 - accuracy: 0.3750 - val_loss: 0.7049 - val_accuracy: 0.3667 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.7064 - accuracy: 0.3692\n",
            "Epoch 10: val_accuracy did not improve from 0.37778\n",
            "22/22 [==============================] - 10s 468ms/step - loss: 0.7064 - accuracy: 0.3692 - val_loss: 0.7016 - val_accuracy: 0.3667 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6957 - accuracy: 0.4070\n",
            "Epoch 11: val_accuracy did not improve from 0.37778\n",
            "22/22 [==============================] - 11s 475ms/step - loss: 0.6957 - accuracy: 0.4070 - val_loss: 0.6975 - val_accuracy: 0.3778 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.3721\n",
            "Epoch 12: val_accuracy did not improve from 0.37778\n",
            "22/22 [==============================] - 11s 474ms/step - loss: 0.6932 - accuracy: 0.3721 - val_loss: 0.6938 - val_accuracy: 0.3667 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6877 - accuracy: 0.4012\n",
            "Epoch 13: val_accuracy improved from 0.37778 to 0.38889, saving model to  Kmodel16_soft_pre_bi_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_sgd1.h5 /assets\n",
            "22/22 [==============================] - 44s 2s/step - loss: 0.6877 - accuracy: 0.4012 - val_loss: 0.6905 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6840 - accuracy: 0.4041\n",
            "Epoch 14: val_accuracy did not improve from 0.38889\n",
            "22/22 [==============================] - 11s 468ms/step - loss: 0.6840 - accuracy: 0.4041 - val_loss: 0.6870 - val_accuracy: 0.3778 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6811 - accuracy: 0.4012\n",
            "Epoch 15: val_accuracy did not improve from 0.38889\n",
            "22/22 [==============================] - 11s 472ms/step - loss: 0.6811 - accuracy: 0.4012 - val_loss: 0.6841 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6780 - accuracy: 0.3924\n",
            "Epoch 16: val_accuracy did not improve from 0.38889\n",
            "22/22 [==============================] - 11s 470ms/step - loss: 0.6780 - accuracy: 0.3924 - val_loss: 0.6801 - val_accuracy: 0.3778 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6688 - accuracy: 0.4273\n",
            "Epoch 17: val_accuracy did not improve from 0.38889\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.6688 - accuracy: 0.4273 - val_loss: 0.6774 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6661 - accuracy: 0.4215\n",
            "Epoch 18: val_accuracy did not improve from 0.38889\n",
            "22/22 [==============================] - 11s 477ms/step - loss: 0.6661 - accuracy: 0.4215 - val_loss: 0.6744 - val_accuracy: 0.3778 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6648 - accuracy: 0.3924\n",
            "Epoch 19: val_accuracy did not improve from 0.38889\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "22/22 [==============================] - 11s 483ms/step - loss: 0.6648 - accuracy: 0.3924 - val_loss: 0.6722 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6599 - accuracy: 0.4347\n",
            "Epoch 20: val_accuracy did not improve from 0.38889\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 0.6599 - accuracy: 0.4347 - val_loss: 0.6714 - val_accuracy: 0.3889 - lr: 5.0000e-05\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6570 - accuracy: 0.4331\n",
            "Epoch 21: val_accuracy did not improve from 0.38889\n",
            "22/22 [==============================] - 10s 469ms/step - loss: 0.6570 - accuracy: 0.4331 - val_loss: 0.6701 - val_accuracy: 0.3889 - lr: 5.0000e-05\n",
            "Epoch 22/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6554 - accuracy: 0.4602\n",
            "Epoch 22: val_accuracy improved from 0.38889 to 0.40000, saving model to  Kmodel16_soft_pre_bi_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_sgd1.h5 /assets\n",
            "22/22 [==============================] - 44s 2s/step - loss: 0.6554 - accuracy: 0.4602 - val_loss: 0.6691 - val_accuracy: 0.4000 - lr: 5.0000e-05\n",
            "Epoch 23/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6632 - accuracy: 0.4215\n",
            "Epoch 23: val_accuracy improved from 0.40000 to 0.41111, saving model to  Kmodel16_soft_pre_bi_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_sgd1.h5 /assets\n",
            "22/22 [==============================] - 44s 2s/step - loss: 0.6632 - accuracy: 0.4215 - val_loss: 0.6679 - val_accuracy: 0.4111 - lr: 5.0000e-05\n",
            "Epoch 24/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6594 - accuracy: 0.4419\n",
            "Epoch 24: val_accuracy did not improve from 0.41111\n",
            "22/22 [==============================] - 11s 467ms/step - loss: 0.6594 - accuracy: 0.4419 - val_loss: 0.6662 - val_accuracy: 0.4000 - lr: 5.0000e-05\n",
            "Epoch 25/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6576 - accuracy: 0.4244\n",
            "Epoch 25: val_accuracy did not improve from 0.41111\n",
            "22/22 [==============================] - 10s 467ms/step - loss: 0.6576 - accuracy: 0.4244 - val_loss: 0.6648 - val_accuracy: 0.4000 - lr: 5.0000e-05\n",
            "Epoch 26/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6547 - accuracy: 0.4128\n",
            "Epoch 26: val_accuracy did not improve from 0.41111\n",
            "22/22 [==============================] - 11s 469ms/step - loss: 0.6547 - accuracy: 0.4128 - val_loss: 0.6638 - val_accuracy: 0.4000 - lr: 5.0000e-05\n",
            "Epoch 27/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6547 - accuracy: 0.4273\n",
            "Epoch 27: val_accuracy did not improve from 0.41111\n",
            "22/22 [==============================] - 11s 480ms/step - loss: 0.6547 - accuracy: 0.4273 - val_loss: 0.6627 - val_accuracy: 0.4000 - lr: 5.0000e-05\n",
            "Epoch 28/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6571 - accuracy: 0.4215\n",
            "Epoch 28: val_accuracy did not improve from 0.41111\n",
            "22/22 [==============================] - 11s 476ms/step - loss: 0.6571 - accuracy: 0.4215 - val_loss: 0.6616 - val_accuracy: 0.3778 - lr: 5.0000e-05\n",
            "Epoch 29/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6503 - accuracy: 0.4622\n",
            "Epoch 29: val_accuracy did not improve from 0.41111\n",
            "\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "22/22 [==============================] - 11s 473ms/step - loss: 0.6503 - accuracy: 0.4622 - val_loss: 0.6600 - val_accuracy: 0.3778 - lr: 5.0000e-05\n",
            "Epoch 30/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6494 - accuracy: 0.4680\n",
            "Epoch 30: val_accuracy did not improve from 0.41111\n",
            "22/22 [==============================] - 11s 483ms/step - loss: 0.6494 - accuracy: 0.4680 - val_loss: 0.6599 - val_accuracy: 0.3778 - lr: 2.5000e-05\n",
            "Epoch 31/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6497 - accuracy: 0.4273\n",
            "Epoch 31: val_accuracy did not improve from 0.41111\n",
            "22/22 [==============================] - 11s 475ms/step - loss: 0.6497 - accuracy: 0.4273 - val_loss: 0.6593 - val_accuracy: 0.3889 - lr: 2.5000e-05\n",
            "Epoch 32/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6397 - accuracy: 0.4680\n",
            "Epoch 32: val_accuracy did not improve from 0.41111\n",
            "22/22 [==============================] - 11s 478ms/step - loss: 0.6397 - accuracy: 0.4680 - val_loss: 0.6584 - val_accuracy: 0.3778 - lr: 2.5000e-05\n",
            "Epoch 33/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6473 - accuracy: 0.4709\n",
            "Epoch 33: val_accuracy did not improve from 0.41111\n",
            "22/22 [==============================] - 11s 477ms/step - loss: 0.6473 - accuracy: 0.4709 - val_loss: 0.6576 - val_accuracy: 0.3778 - lr: 2.5000e-05\n",
            "Epoch 34/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6487 - accuracy: 0.4506\n",
            "Epoch 34: val_accuracy did not improve from 0.41111\n",
            "22/22 [==============================] - 11s 479ms/step - loss: 0.6487 - accuracy: 0.4506 - val_loss: 0.6566 - val_accuracy: 0.3889 - lr: 2.5000e-05\n",
            "Epoch 35/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6449 - accuracy: 0.4709\n",
            "Epoch 35: val_accuracy did not improve from 0.41111\n",
            "\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "22/22 [==============================] - 11s 476ms/step - loss: 0.6449 - accuracy: 0.4709 - val_loss: 0.6560 - val_accuracy: 0.4111 - lr: 2.5000e-05\n",
            "Epoch 36/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6479 - accuracy: 0.4593\n",
            "Epoch 36: val_accuracy improved from 0.41111 to 0.43333, saving model to  Kmodel16_soft_pre_bi_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_sgd1.h5 /assets\n",
            "22/22 [==============================] - 44s 2s/step - loss: 0.6479 - accuracy: 0.4593 - val_loss: 0.6554 - val_accuracy: 0.4333 - lr: 1.2500e-05\n",
            "Epoch 37/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6458 - accuracy: 0.4390\n",
            "Epoch 37: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 479ms/step - loss: 0.6458 - accuracy: 0.4390 - val_loss: 0.6559 - val_accuracy: 0.4000 - lr: 1.2500e-05\n",
            "Epoch 38/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6437 - accuracy: 0.4797\n",
            "Epoch 38: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.6437 - accuracy: 0.4797 - val_loss: 0.6553 - val_accuracy: 0.4111 - lr: 1.2500e-05\n",
            "Epoch 39/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6455 - accuracy: 0.4331\n",
            "Epoch 39: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 479ms/step - loss: 0.6455 - accuracy: 0.4331 - val_loss: 0.6557 - val_accuracy: 0.4111 - lr: 1.2500e-05\n",
            "Epoch 40/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6407 - accuracy: 0.4535\n",
            "Epoch 40: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 476ms/step - loss: 0.6407 - accuracy: 0.4535 - val_loss: 0.6557 - val_accuracy: 0.4111 - lr: 1.2500e-05\n",
            "Epoch 41/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6475 - accuracy: 0.4477\n",
            "Epoch 41: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 479ms/step - loss: 0.6475 - accuracy: 0.4477 - val_loss: 0.6552 - val_accuracy: 0.4333 - lr: 1.2500e-05\n",
            "Epoch 42/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6520 - accuracy: 0.4244\n",
            "Epoch 42: val_accuracy did not improve from 0.43333\n",
            "\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "22/22 [==============================] - 11s 478ms/step - loss: 0.6520 - accuracy: 0.4244 - val_loss: 0.6548 - val_accuracy: 0.4333 - lr: 1.2500e-05\n",
            "Epoch 43/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6436 - accuracy: 0.4390\n",
            "Epoch 43: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 477ms/step - loss: 0.6436 - accuracy: 0.4390 - val_loss: 0.6547 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 44/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6376 - accuracy: 0.4913\n",
            "Epoch 44: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 478ms/step - loss: 0.6376 - accuracy: 0.4913 - val_loss: 0.6549 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 45/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6421 - accuracy: 0.4535\n",
            "Epoch 45: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 478ms/step - loss: 0.6421 - accuracy: 0.4535 - val_loss: 0.6552 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 46/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6490 - accuracy: 0.4489\n",
            "Epoch 46: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.6490 - accuracy: 0.4489 - val_loss: 0.6539 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 47/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6427 - accuracy: 0.4651\n",
            "Epoch 47: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 478ms/step - loss: 0.6427 - accuracy: 0.4651 - val_loss: 0.6539 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 48/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6484 - accuracy: 0.4390\n",
            "Epoch 48: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 477ms/step - loss: 0.6484 - accuracy: 0.4390 - val_loss: 0.6532 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 49/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6440 - accuracy: 0.4448\n",
            "Epoch 49: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 478ms/step - loss: 0.6440 - accuracy: 0.4448 - val_loss: 0.6531 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 50/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6422 - accuracy: 0.4244\n",
            "Epoch 50: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 481ms/step - loss: 0.6422 - accuracy: 0.4244 - val_loss: 0.6536 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 51/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6406 - accuracy: 0.4797\n",
            "Epoch 51: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 476ms/step - loss: 0.6406 - accuracy: 0.4797 - val_loss: 0.6539 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.38      0.64      0.48        28\n",
            "      Normal       0.47      0.29      0.36        31\n",
            "Tuberculosis       0.42      0.32      0.36        31\n",
            "\n",
            "    accuracy                           0.41        90\n",
            "   macro avg       0.42      0.42      0.40        90\n",
            "weighted avg       0.43      0.41      0.40        90\n",
            "\n",
            "Fold #2\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6466 - accuracy: 0.4273\n",
            "Epoch 1: val_accuracy improved from -inf to 0.37778, saving model to  Kmodel16_soft_pre_bi_sgd2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_sgd2.h5 /assets\n",
            "22/22 [==============================] - 44s 2s/step - loss: 0.6466 - accuracy: 0.4273 - val_loss: 0.6455 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6418 - accuracy: 0.4564\n",
            "Epoch 2: val_accuracy did not improve from 0.37778\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.6418 - accuracy: 0.4564 - val_loss: 0.6456 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6378 - accuracy: 0.4797\n",
            "Epoch 3: val_accuracy did not improve from 0.37778\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.6378 - accuracy: 0.4797 - val_loss: 0.6453 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6355 - accuracy: 0.4971\n",
            "Epoch 4: val_accuracy did not improve from 0.37778\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.6355 - accuracy: 0.4971 - val_loss: 0.6446 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6474 - accuracy: 0.4006\n",
            "Epoch 5: val_accuracy did not improve from 0.37778\n",
            "22/22 [==============================] - 11s 489ms/step - loss: 0.6474 - accuracy: 0.4006 - val_loss: 0.6440 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6404 - accuracy: 0.4593\n",
            "Epoch 6: val_accuracy did not improve from 0.37778\n",
            "22/22 [==============================] - 11s 479ms/step - loss: 0.6404 - accuracy: 0.4593 - val_loss: 0.6431 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6421 - accuracy: 0.4535\n",
            "Epoch 7: val_accuracy did not improve from 0.37778\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.6421 - accuracy: 0.4535 - val_loss: 0.6430 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6370 - accuracy: 0.4593\n",
            "Epoch 8: val_accuracy did not improve from 0.37778\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 0.6370 - accuracy: 0.4593 - val_loss: 0.6427 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6397 - accuracy: 0.4535\n",
            "Epoch 9: val_accuracy did not improve from 0.37778\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.6397 - accuracy: 0.4535 - val_loss: 0.6427 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6384 - accuracy: 0.4593\n",
            "Epoch 10: val_accuracy did not improve from 0.37778\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.6384 - accuracy: 0.4593 - val_loss: 0.6431 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6365 - accuracy: 0.4913\n",
            "Epoch 11: val_accuracy did not improve from 0.37778\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.6365 - accuracy: 0.4913 - val_loss: 0.6430 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6380 - accuracy: 0.4593\n",
            "Epoch 12: val_accuracy did not improve from 0.37778\n",
            "22/22 [==============================] - 11s 483ms/step - loss: 0.6380 - accuracy: 0.4593 - val_loss: 0.6427 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6429 - accuracy: 0.4419\n",
            "Epoch 13: val_accuracy did not improve from 0.37778\n",
            "22/22 [==============================] - 11s 481ms/step - loss: 0.6429 - accuracy: 0.4419 - val_loss: 0.6429 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6411 - accuracy: 0.4244\n",
            "Epoch 14: val_accuracy did not improve from 0.37778\n",
            "22/22 [==============================] - 11s 483ms/step - loss: 0.6411 - accuracy: 0.4244 - val_loss: 0.6428 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6436 - accuracy: 0.4448\n",
            "Epoch 15: val_accuracy did not improve from 0.37778\n",
            "22/22 [==============================] - 11s 481ms/step - loss: 0.6436 - accuracy: 0.4448 - val_loss: 0.6422 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6426 - accuracy: 0.4680\n",
            "Epoch 16: val_accuracy did not improve from 0.37778\n",
            "22/22 [==============================] - 11s 480ms/step - loss: 0.6426 - accuracy: 0.4680 - val_loss: 0.6418 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.41      0.62      0.49        34\n",
            "      Normal       0.50      0.30      0.37        27\n",
            "Tuberculosis       0.17      0.14      0.15        29\n",
            "\n",
            "    accuracy                           0.37        90\n",
            "   macro avg       0.36      0.35      0.34        90\n",
            "weighted avg       0.36      0.37      0.35        90\n",
            "\n",
            "Fold #3\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6313 - accuracy: 0.5000\n",
            "Epoch 1: val_accuracy improved from -inf to 0.41111, saving model to  Kmodel16_soft_pre_bi_sgd3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_sgd3.h5 /assets\n",
            "22/22 [==============================] - 45s 2s/step - loss: 0.6313 - accuracy: 0.5000 - val_loss: 0.6573 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6344 - accuracy: 0.4419\n",
            "Epoch 2: val_accuracy did not improve from 0.41111\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.6344 - accuracy: 0.4419 - val_loss: 0.6566 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6375 - accuracy: 0.4448\n",
            "Epoch 3: val_accuracy improved from 0.41111 to 0.43333, saving model to  Kmodel16_soft_pre_bi_sgd3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_sgd3.h5 /assets\n",
            "22/22 [==============================] - 45s 2s/step - loss: 0.6375 - accuracy: 0.4448 - val_loss: 0.6560 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6418 - accuracy: 0.4797\n",
            "Epoch 4: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 480ms/step - loss: 0.6418 - accuracy: 0.4797 - val_loss: 0.6557 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6355 - accuracy: 0.4913\n",
            "Epoch 5: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.6355 - accuracy: 0.4913 - val_loss: 0.6553 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6332 - accuracy: 0.4826\n",
            "Epoch 6: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 480ms/step - loss: 0.6332 - accuracy: 0.4826 - val_loss: 0.6546 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6372 - accuracy: 0.4855\n",
            "Epoch 7: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.6372 - accuracy: 0.4855 - val_loss: 0.6545 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6409 - accuracy: 0.4855\n",
            "Epoch 8: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 496ms/step - loss: 0.6409 - accuracy: 0.4855 - val_loss: 0.6547 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6374 - accuracy: 0.4622\n",
            "Epoch 9: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.6374 - accuracy: 0.4622 - val_loss: 0.6550 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6381 - accuracy: 0.4709\n",
            "Epoch 10: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 492ms/step - loss: 0.6381 - accuracy: 0.4709 - val_loss: 0.6546 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6430 - accuracy: 0.4477\n",
            "Epoch 11: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 499ms/step - loss: 0.6430 - accuracy: 0.4477 - val_loss: 0.6544 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6376 - accuracy: 0.4186\n",
            "Epoch 12: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 495ms/step - loss: 0.6376 - accuracy: 0.4186 - val_loss: 0.6543 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6359 - accuracy: 0.4942\n",
            "Epoch 13: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.6359 - accuracy: 0.4942 - val_loss: 0.6538 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6350 - accuracy: 0.4826\n",
            "Epoch 14: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 489ms/step - loss: 0.6350 - accuracy: 0.4826 - val_loss: 0.6535 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6346 - accuracy: 0.5029\n",
            "Epoch 15: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 491ms/step - loss: 0.6346 - accuracy: 0.5029 - val_loss: 0.6537 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6345 - accuracy: 0.4767\n",
            "Epoch 16: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 494ms/step - loss: 0.6345 - accuracy: 0.4767 - val_loss: 0.6531 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6345 - accuracy: 0.4680\n",
            "Epoch 17: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.6345 - accuracy: 0.4680 - val_loss: 0.6529 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6367 - accuracy: 0.4680\n",
            "Epoch 18: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 491ms/step - loss: 0.6367 - accuracy: 0.4680 - val_loss: 0.6525 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.45      0.67      0.54        27\n",
            "      Normal       0.60      0.27      0.37        33\n",
            "Tuberculosis       0.34      0.40      0.37        30\n",
            "\n",
            "    accuracy                           0.43        90\n",
            "   macro avg       0.46      0.45      0.43        90\n",
            "weighted avg       0.47      0.43      0.42        90\n",
            "\n",
            "Fold #4\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6377 - accuracy: 0.4448\n",
            "Epoch 1: val_accuracy improved from -inf to 0.41111, saving model to  Kmodel16_soft_pre_bi_sgd4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_sgd4.h5 /assets\n",
            "22/22 [==============================] - 45s 2s/step - loss: 0.6377 - accuracy: 0.4448 - val_loss: 0.6416 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6311 - accuracy: 0.5203\n",
            "Epoch 2: val_accuracy did not improve from 0.41111\n",
            "22/22 [==============================] - 11s 483ms/step - loss: 0.6311 - accuracy: 0.5203 - val_loss: 0.6418 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6334 - accuracy: 0.4477\n",
            "Epoch 3: val_accuracy did not improve from 0.41111\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.6334 - accuracy: 0.4477 - val_loss: 0.6409 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6304 - accuracy: 0.5000\n",
            "Epoch 4: val_accuracy did not improve from 0.41111\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.6304 - accuracy: 0.5000 - val_loss: 0.6410 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6320 - accuracy: 0.4915\n",
            "Epoch 5: val_accuracy did not improve from 0.41111\n",
            "22/22 [==============================] - 11s 491ms/step - loss: 0.6320 - accuracy: 0.4915 - val_loss: 0.6412 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6325 - accuracy: 0.5000\n",
            "Epoch 6: val_accuracy did not improve from 0.41111\n",
            "22/22 [==============================] - 11s 491ms/step - loss: 0.6325 - accuracy: 0.5000 - val_loss: 0.6409 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6365 - accuracy: 0.4680\n",
            "Epoch 7: val_accuracy did not improve from 0.41111\n",
            "22/22 [==============================] - 11s 483ms/step - loss: 0.6365 - accuracy: 0.4680 - val_loss: 0.6408 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6338 - accuracy: 0.4884\n",
            "Epoch 8: val_accuracy did not improve from 0.41111\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 0.6338 - accuracy: 0.4884 - val_loss: 0.6403 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6338 - accuracy: 0.4884\n",
            "Epoch 9: val_accuracy improved from 0.41111 to 0.43333, saving model to  Kmodel16_soft_pre_bi_sgd4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_sgd4.h5 /assets\n",
            "22/22 [==============================] - 44s 2s/step - loss: 0.6338 - accuracy: 0.4884 - val_loss: 0.6396 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6301 - accuracy: 0.4709\n",
            "Epoch 10: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 483ms/step - loss: 0.6301 - accuracy: 0.4709 - val_loss: 0.6397 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6342 - accuracy: 0.4738\n",
            "Epoch 11: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.6342 - accuracy: 0.4738 - val_loss: 0.6399 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6289 - accuracy: 0.4477\n",
            "Epoch 12: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.6289 - accuracy: 0.4477 - val_loss: 0.6397 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6236 - accuracy: 0.5256\n",
            "Epoch 13: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 489ms/step - loss: 0.6236 - accuracy: 0.5256 - val_loss: 0.6403 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6283 - accuracy: 0.4913\n",
            "Epoch 14: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.6283 - accuracy: 0.4913 - val_loss: 0.6400 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6349 - accuracy: 0.4360\n",
            "Epoch 15: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.6349 - accuracy: 0.4360 - val_loss: 0.6399 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6365 - accuracy: 0.4535\n",
            "Epoch 16: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 489ms/step - loss: 0.6365 - accuracy: 0.4535 - val_loss: 0.6400 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6277 - accuracy: 0.4971\n",
            "Epoch 17: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.6277 - accuracy: 0.4971 - val_loss: 0.6398 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6333 - accuracy: 0.4855\n",
            "Epoch 18: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 491ms/step - loss: 0.6333 - accuracy: 0.4855 - val_loss: 0.6396 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6273 - accuracy: 0.4738\n",
            "Epoch 19: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 0.6273 - accuracy: 0.4738 - val_loss: 0.6394 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6331 - accuracy: 0.4593\n",
            "Epoch 20: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.6331 - accuracy: 0.4593 - val_loss: 0.6390 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6280 - accuracy: 0.4680\n",
            "Epoch 21: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.6280 - accuracy: 0.4680 - val_loss: 0.6388 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6285 - accuracy: 0.4971\n",
            "Epoch 22: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.6285 - accuracy: 0.4971 - val_loss: 0.6382 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6282 - accuracy: 0.5291\n",
            "Epoch 23: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.6282 - accuracy: 0.5291 - val_loss: 0.6381 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6304 - accuracy: 0.4767\n",
            "Epoch 24: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.6304 - accuracy: 0.4767 - val_loss: 0.6380 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.43      0.60      0.50        30\n",
            "      Normal       0.52      0.42      0.46        31\n",
            "Tuberculosis       0.35      0.28      0.31        29\n",
            "\n",
            "    accuracy                           0.43        90\n",
            "   macro avg       0.43      0.43      0.42        90\n",
            "weighted avg       0.43      0.43      0.43        90\n",
            "\n",
            "Fold #5\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6330 - accuracy: 0.4651\n",
            "Epoch 1: val_accuracy improved from -inf to 0.42222, saving model to  Kmodel16_soft_pre_bi_sgd5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_sgd5.h5 /assets\n",
            "22/22 [==============================] - 45s 2s/step - loss: 0.6330 - accuracy: 0.4651 - val_loss: 0.6363 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6278 - accuracy: 0.4884\n",
            "Epoch 2: val_accuracy did not improve from 0.42222\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 0.6278 - accuracy: 0.4884 - val_loss: 0.6363 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6305 - accuracy: 0.5000\n",
            "Epoch 3: val_accuracy did not improve from 0.42222\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.6305 - accuracy: 0.5000 - val_loss: 0.6354 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6325 - accuracy: 0.4593\n",
            "Epoch 4: val_accuracy improved from 0.42222 to 0.43333, saving model to  Kmodel16_soft_pre_bi_sgd5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_sgd5.h5 /assets\n",
            "22/22 [==============================] - 45s 2s/step - loss: 0.6325 - accuracy: 0.4593 - val_loss: 0.6357 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6376 - accuracy: 0.4517\n",
            "Epoch 5: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 494ms/step - loss: 0.6376 - accuracy: 0.4517 - val_loss: 0.6353 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6298 - accuracy: 0.4738\n",
            "Epoch 6: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.6298 - accuracy: 0.4738 - val_loss: 0.6351 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6283 - accuracy: 0.4971\n",
            "Epoch 7: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 493ms/step - loss: 0.6283 - accuracy: 0.4971 - val_loss: 0.6353 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6320 - accuracy: 0.4767\n",
            "Epoch 8: val_accuracy did not improve from 0.43333\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.6320 - accuracy: 0.4767 - val_loss: 0.6353 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6298 - accuracy: 0.4738\n",
            "Epoch 9: val_accuracy improved from 0.43333 to 0.45556, saving model to  Kmodel16_soft_pre_bi_sgd5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_sgd5.h5 /assets\n",
            "22/22 [==============================] - 45s 2s/step - loss: 0.6298 - accuracy: 0.4738 - val_loss: 0.6347 - val_accuracy: 0.4556 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6330 - accuracy: 0.4564\n",
            "Epoch 10: val_accuracy did not improve from 0.45556\n",
            "22/22 [==============================] - 11s 493ms/step - loss: 0.6330 - accuracy: 0.4564 - val_loss: 0.6350 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6282 - accuracy: 0.4709\n",
            "Epoch 11: val_accuracy did not improve from 0.45556\n",
            "22/22 [==============================] - 11s 498ms/step - loss: 0.6282 - accuracy: 0.4709 - val_loss: 0.6349 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6332 - accuracy: 0.4855\n",
            "Epoch 12: val_accuracy did not improve from 0.45556\n",
            "22/22 [==============================] - 11s 497ms/step - loss: 0.6332 - accuracy: 0.4855 - val_loss: 0.6351 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6305 - accuracy: 0.4506\n",
            "Epoch 13: val_accuracy did not improve from 0.45556\n",
            "22/22 [==============================] - 11s 494ms/step - loss: 0.6305 - accuracy: 0.4506 - val_loss: 0.6351 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6319 - accuracy: 0.4506\n",
            "Epoch 14: val_accuracy did not improve from 0.45556\n",
            "22/22 [==============================] - 11s 497ms/step - loss: 0.6319 - accuracy: 0.4506 - val_loss: 0.6347 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6281 - accuracy: 0.4971\n",
            "Epoch 15: val_accuracy did not improve from 0.45556\n",
            "22/22 [==============================] - 11s 496ms/step - loss: 0.6281 - accuracy: 0.4971 - val_loss: 0.6346 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6369 - accuracy: 0.4302\n",
            "Epoch 16: val_accuracy did not improve from 0.45556\n",
            "22/22 [==============================] - 11s 494ms/step - loss: 0.6369 - accuracy: 0.4302 - val_loss: 0.6342 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6284 - accuracy: 0.4593\n",
            "Epoch 17: val_accuracy did not improve from 0.45556\n",
            "22/22 [==============================] - 11s 495ms/step - loss: 0.6284 - accuracy: 0.4593 - val_loss: 0.6349 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6324 - accuracy: 0.4716\n",
            "Epoch 18: val_accuracy did not improve from 0.45556\n",
            "22/22 [==============================] - 11s 499ms/step - loss: 0.6324 - accuracy: 0.4716 - val_loss: 0.6349 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6282 - accuracy: 0.4767\n",
            "Epoch 19: val_accuracy did not improve from 0.45556\n",
            "22/22 [==============================] - 11s 495ms/step - loss: 0.6282 - accuracy: 0.4767 - val_loss: 0.6343 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6218 - accuracy: 0.5145\n",
            "Epoch 20: val_accuracy did not improve from 0.45556\n",
            "22/22 [==============================] - 11s 500ms/step - loss: 0.6218 - accuracy: 0.5145 - val_loss: 0.6343 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6322 - accuracy: 0.4622\n",
            "Epoch 21: val_accuracy did not improve from 0.45556\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.6322 - accuracy: 0.4622 - val_loss: 0.6342 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6311 - accuracy: 0.4884\n",
            "Epoch 22: val_accuracy did not improve from 0.45556\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 0.6311 - accuracy: 0.4884 - val_loss: 0.6338 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6290 - accuracy: 0.4767\n",
            "Epoch 23: val_accuracy did not improve from 0.45556\n",
            "22/22 [==============================] - 11s 489ms/step - loss: 0.6290 - accuracy: 0.4767 - val_loss: 0.6331 - val_accuracy: 0.4556 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6223 - accuracy: 0.5116\n",
            "Epoch 24: val_accuracy did not improve from 0.45556\n",
            "22/22 [==============================] - 11s 508ms/step - loss: 0.6223 - accuracy: 0.5116 - val_loss: 0.6329 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.49      0.65      0.56        31\n",
            "      Normal       0.50      0.39      0.44        28\n",
            "Tuberculosis       0.33      0.29      0.31        31\n",
            "\n",
            "    accuracy                           0.44        90\n",
            "   macro avg       0.44      0.44      0.44        90\n",
            "weighted avg       0.44      0.44      0.44        90\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.43      0.63      0.51       150\n",
            "      Normal       0.52      0.33      0.40       150\n",
            "Tuberculosis       0.33      0.29      0.30       150\n",
            "\n",
            "    accuracy                           0.42       450\n",
            "   macro avg       0.42      0.42      0.41       450\n",
            "weighted avg       0.42      0.42      0.41       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 16 soft pre cate \n"
      ],
      "metadata": {
        "id": "2nwMmcCSREHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 16\n",
        "filepath = \"Kmodel16_soft_pre_cate.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" )\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "94527d47-5e77-4a89-a55d-fa9b8cb1d8bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hMfVEfpREHt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [01:48<00:00,  4.16it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel16_soft_pre_cate{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "re6ML_NsREHt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ab9553a-b898-4410-9e66-5993a7ca05f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 3s 0us/step\n",
            "87924736/87910968 [==============================] - 3s 0us/step\n",
            "Fold #1\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.7561 - accuracy: 0.6657\n",
            "Epoch 1: val_accuracy improved from -inf to 0.43333, saving model to  Kmodel16_soft_pre_cate1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate1.h5 /assets\n",
            "22/22 [==============================] - 106s 3s/step - loss: 0.7561 - accuracy: 0.6657 - val_loss: 1.4739 - val_accuracy: 0.4333 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.4257 - accuracy: 0.8401\n",
            "Epoch 2: val_accuracy improved from 0.43333 to 0.46667, saving model to  Kmodel16_soft_pre_cate1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate1.h5 /assets\n",
            "22/22 [==============================] - 49s 2s/step - loss: 0.4257 - accuracy: 0.8401 - val_loss: 1.7103 - val_accuracy: 0.4667 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.3984 - accuracy: 0.8488\n",
            "Epoch 3: val_accuracy improved from 0.46667 to 0.53333, saving model to  Kmodel16_soft_pre_cate1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate1.h5 /assets\n",
            "22/22 [==============================] - 49s 2s/step - loss: 0.3984 - accuracy: 0.8488 - val_loss: 1.3309 - val_accuracy: 0.5333 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.2417 - accuracy: 0.9157\n",
            "Epoch 4: val_accuracy improved from 0.53333 to 0.56667, saving model to  Kmodel16_soft_pre_cate1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate1.h5 /assets\n",
            "22/22 [==============================] - 49s 2s/step - loss: 0.2417 - accuracy: 0.9157 - val_loss: 1.4029 - val_accuracy: 0.5667 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.2288 - accuracy: 0.9157\n",
            "Epoch 5: val_accuracy did not improve from 0.56667\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.2288 - accuracy: 0.9157 - val_loss: 2.5153 - val_accuracy: 0.4889 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1719 - accuracy: 0.9448\n",
            "Epoch 6: val_accuracy improved from 0.56667 to 0.67778, saving model to  Kmodel16_soft_pre_cate1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate1.h5 /assets\n",
            "22/22 [==============================] - 49s 2s/step - loss: 0.1719 - accuracy: 0.9448 - val_loss: 1.4475 - val_accuracy: 0.6778 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1913 - accuracy: 0.9331\n",
            "Epoch 7: val_accuracy did not improve from 0.67778\n",
            "22/22 [==============================] - 11s 489ms/step - loss: 0.1913 - accuracy: 0.9331 - val_loss: 1.2905 - val_accuracy: 0.6556 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1470 - accuracy: 0.9419\n",
            "Epoch 8: val_accuracy did not improve from 0.67778\n",
            "22/22 [==============================] - 11s 493ms/step - loss: 0.1470 - accuracy: 0.9419 - val_loss: 1.7687 - val_accuracy: 0.6556 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1321 - accuracy: 0.9535\n",
            "Epoch 9: val_accuracy improved from 0.67778 to 0.85556, saving model to  Kmodel16_soft_pre_cate1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate1.h5 /assets\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.1321 - accuracy: 0.9535 - val_loss: 0.5216 - val_accuracy: 0.8556 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.9651\n",
            "Epoch 10: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 11s 505ms/step - loss: 0.0969 - accuracy: 0.9651 - val_loss: 1.0050 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 0.9884\n",
            "Epoch 11: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 11s 492ms/step - loss: 0.0443 - accuracy: 0.9884 - val_loss: 1.3956 - val_accuracy: 0.7556 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1377 - accuracy: 0.9506\n",
            "Epoch 12: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.1377 - accuracy: 0.9506 - val_loss: 1.0064 - val_accuracy: 0.7889 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0643 - accuracy: 0.9738\n",
            "Epoch 13: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 11s 495ms/step - loss: 0.0643 - accuracy: 0.9738 - val_loss: 1.3178 - val_accuracy: 0.7444 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 0.9738\n",
            "Epoch 14: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 11s 493ms/step - loss: 0.0712 - accuracy: 0.9738 - val_loss: 1.1190 - val_accuracy: 0.7556 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1270 - accuracy: 0.9622\n",
            "Epoch 15: val_accuracy did not improve from 0.85556\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.1270 - accuracy: 0.9622 - val_loss: 2.7417 - val_accuracy: 0.5111 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1084 - accuracy: 0.9680\n",
            "Epoch 16: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.1084 - accuracy: 0.9680 - val_loss: 1.8220 - val_accuracy: 0.6333 - lr: 5.0000e-05\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9773\n",
            "Epoch 17: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 11s 494ms/step - loss: 0.0537 - accuracy: 0.9773 - val_loss: 1.1262 - val_accuracy: 0.7333 - lr: 5.0000e-05\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 0.9913\n",
            "Epoch 18: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 11s 492ms/step - loss: 0.0287 - accuracy: 0.9913 - val_loss: 1.1991 - val_accuracy: 0.7889 - lr: 5.0000e-05\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9971\n",
            "Epoch 19: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 12s 521ms/step - loss: 0.0180 - accuracy: 0.9971 - val_loss: 1.2194 - val_accuracy: 0.8000 - lr: 5.0000e-05\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 0.9913\n",
            "Epoch 20: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 12s 529ms/step - loss: 0.0286 - accuracy: 0.9913 - val_loss: 0.9912 - val_accuracy: 0.8000 - lr: 5.0000e-05\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9884\n",
            "Epoch 21: val_accuracy did not improve from 0.85556\n",
            "\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "22/22 [==============================] - 12s 520ms/step - loss: 0.0328 - accuracy: 0.9884 - val_loss: 2.9070 - val_accuracy: 0.5556 - lr: 5.0000e-05\n",
            "Epoch 22/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9913\n",
            "Epoch 22: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 12s 518ms/step - loss: 0.0164 - accuracy: 0.9913 - val_loss: 1.9828 - val_accuracy: 0.6889 - lr: 2.5000e-05\n",
            "Epoch 23/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9884\n",
            "Epoch 23: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 12s 521ms/step - loss: 0.0250 - accuracy: 0.9884 - val_loss: 1.2511 - val_accuracy: 0.7667 - lr: 2.5000e-05\n",
            "Epoch 24/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9913\n",
            "Epoch 24: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 11s 510ms/step - loss: 0.0311 - accuracy: 0.9913 - val_loss: 1.4698 - val_accuracy: 0.7556 - lr: 2.5000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.36      0.53        28\n",
            "      Normal       0.96      0.87      0.92        31\n",
            "Tuberculosis       0.60      1.00      0.75        31\n",
            "\n",
            "    accuracy                           0.76        90\n",
            "   macro avg       0.85      0.74      0.73        90\n",
            "weighted avg       0.85      0.76      0.74        90\n",
            "\n",
            "Fold #2\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1164 - accuracy: 0.9622\n",
            "Epoch 1: val_accuracy improved from -inf to 0.97778, saving model to  Kmodel16_soft_pre_cate2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate2.h5 /assets\n",
            "22/22 [==============================] - 51s 2s/step - loss: 0.1164 - accuracy: 0.9622 - val_loss: 0.0916 - val_accuracy: 0.9778 - lr: 2.5000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1359 - accuracy: 0.9506\n",
            "Epoch 2: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 506ms/step - loss: 0.1359 - accuracy: 0.9506 - val_loss: 0.1102 - val_accuracy: 0.9778 - lr: 2.5000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 0.9797\n",
            "Epoch 3: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 497ms/step - loss: 0.0455 - accuracy: 0.9797 - val_loss: 0.0737 - val_accuracy: 0.9778 - lr: 2.5000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9680\n",
            "Epoch 4: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 497ms/step - loss: 0.0692 - accuracy: 0.9680 - val_loss: 0.0760 - val_accuracy: 0.9667 - lr: 2.5000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0558 - accuracy: 0.9855\n",
            "Epoch 5: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 493ms/step - loss: 0.0558 - accuracy: 0.9855 - val_loss: 0.1202 - val_accuracy: 0.9667 - lr: 2.5000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 0.9826\n",
            "Epoch 6: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 495ms/step - loss: 0.0355 - accuracy: 0.9826 - val_loss: 0.1976 - val_accuracy: 0.9667 - lr: 2.5000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9855\n",
            "Epoch 7: val_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "22/22 [==============================] - 11s 495ms/step - loss: 0.0518 - accuracy: 0.9855 - val_loss: 0.2213 - val_accuracy: 0.9667 - lr: 2.5000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 0.9855\n",
            "Epoch 8: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 506ms/step - loss: 0.0517 - accuracy: 0.9855 - val_loss: 0.1599 - val_accuracy: 0.9667 - lr: 1.2500e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 0.9855\n",
            "Epoch 9: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 497ms/step - loss: 0.0403 - accuracy: 0.9855 - val_loss: 0.1067 - val_accuracy: 0.9667 - lr: 1.2500e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9913\n",
            "Epoch 10: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 497ms/step - loss: 0.0238 - accuracy: 0.9913 - val_loss: 0.1369 - val_accuracy: 0.9667 - lr: 1.2500e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9884\n",
            "Epoch 11: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 498ms/step - loss: 0.0333 - accuracy: 0.9884 - val_loss: 0.0972 - val_accuracy: 0.9667 - lr: 1.2500e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 0.9913\n",
            "Epoch 12: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 494ms/step - loss: 0.0300 - accuracy: 0.9913 - val_loss: 0.0891 - val_accuracy: 0.9667 - lr: 1.2500e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9884\n",
            "Epoch 13: val_accuracy did not improve from 0.97778\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "22/22 [==============================] - 11s 497ms/step - loss: 0.0249 - accuracy: 0.9884 - val_loss: 0.0904 - val_accuracy: 0.9667 - lr: 1.2500e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 499ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.9972\n",
            "Epoch 15: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 500ms/step - loss: 0.0231 - accuracy: 0.9972 - val_loss: 0.1185 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 496ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1423 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.88      0.94        34\n",
            "      Normal       1.00      1.00      1.00        27\n",
            "Tuberculosis       0.88      1.00      0.94        29\n",
            "\n",
            "    accuracy                           0.96        90\n",
            "   macro avg       0.96      0.96      0.96        90\n",
            "weighted avg       0.96      0.96      0.96        90\n",
            "\n",
            "Fold #3\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9855\n",
            "Epoch 1: val_accuracy improved from -inf to 0.94444, saving model to  Kmodel16_soft_pre_cate3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate3.h5 /assets\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.0587 - accuracy: 0.9855 - val_loss: 0.1645 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9971\n",
            "Epoch 2: val_accuracy did not improve from 0.94444\n",
            "22/22 [==============================] - 11s 493ms/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 0.1473 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9972\n",
            "Epoch 3: val_accuracy improved from 0.94444 to 0.95556, saving model to  Kmodel16_soft_pre_cate3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate3.h5 /assets\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.0162 - accuracy: 0.9972 - val_loss: 0.1187 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 0.9855\n",
            "Epoch 4: val_accuracy did not improve from 0.95556\n",
            "22/22 [==============================] - 11s 495ms/step - loss: 0.0293 - accuracy: 0.9855 - val_loss: 0.2666 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9855\n",
            "Epoch 5: val_accuracy did not improve from 0.95556\n",
            "22/22 [==============================] - 11s 492ms/step - loss: 0.0269 - accuracy: 0.9855 - val_loss: 0.1384 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 0.9942\n",
            "Epoch 6: val_accuracy improved from 0.95556 to 0.97778, saving model to  Kmodel16_soft_pre_cate3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate3.h5 /assets\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.0224 - accuracy: 0.9942 - val_loss: 0.1048 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 493ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9971\n",
            "Epoch 8: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 493ms/step - loss: 0.0208 - accuracy: 0.9971 - val_loss: 0.0788 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 494ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.1148 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9884\n",
            "Epoch 10: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 498ms/step - loss: 0.0341 - accuracy: 0.9884 - val_loss: 0.0777 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9971\n",
            "Epoch 11: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 492ms/step - loss: 0.0152 - accuracy: 0.9971 - val_loss: 0.0720 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 0.9884\n",
            "Epoch 12: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 492ms/step - loss: 0.0271 - accuracy: 0.9884 - val_loss: 0.0744 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9971\n",
            "Epoch 13: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 492ms/step - loss: 0.0120 - accuracy: 0.9971 - val_loss: 0.0373 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9942\n",
            "Epoch 14: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 496ms/step - loss: 0.0266 - accuracy: 0.9942 - val_loss: 0.0523 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 0.9884\n",
            "Epoch 15: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 493ms/step - loss: 0.0283 - accuracy: 0.9884 - val_loss: 0.0468 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 0.9884\n",
            "Epoch 16: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 491ms/step - loss: 0.0252 - accuracy: 0.9884 - val_loss: 0.0424 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9971\n",
            "Epoch 17: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 496ms/step - loss: 0.0110 - accuracy: 0.9971 - val_loss: 0.0628 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9942\n",
            "Epoch 18: val_accuracy improved from 0.97778 to 0.98889, saving model to  Kmodel16_soft_pre_cate3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate3.h5 /assets\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.0129 - accuracy: 0.9942 - val_loss: 0.0359 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9855\n",
            "Epoch 19: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 492ms/step - loss: 0.0353 - accuracy: 0.9855 - val_loss: 0.0551 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 493ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 495ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 492ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9971\n",
            "Epoch 23: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 493ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.0135 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9942\n",
            "Epoch 24: val_accuracy improved from 0.98889 to 1.00000, saving model to  Kmodel16_soft_pre_cate3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate3.h5 /assets\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.0093 - accuracy: 0.9942 - val_loss: 0.0070 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9913\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 495ms/step - loss: 0.0314 - accuracy: 0.9913 - val_loss: 0.0183 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 496ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 27/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9971\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 492ms/step - loss: 0.0126 - accuracy: 0.9971 - val_loss: 0.0387 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 28/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 495ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 29/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9971\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 506ms/step - loss: 0.0109 - accuracy: 0.9971 - val_loss: 0.0490 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 30/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9971\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 494ms/step - loss: 0.0050 - accuracy: 0.9971 - val_loss: 0.0353 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 31/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 499ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 32/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9971\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 495ms/step - loss: 0.0069 - accuracy: 0.9971 - val_loss: 0.0637 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 33/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 496ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0608 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 34/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 500ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0744 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 35/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9971\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 491ms/step - loss: 0.0106 - accuracy: 0.9971 - val_loss: 0.0217 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 36/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 496ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 37/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9971\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 494ms/step - loss: 0.0126 - accuracy: 0.9971 - val_loss: 0.0252 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 38/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9884\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 492ms/step - loss: 0.0152 - accuracy: 0.9884 - val_loss: 0.0553 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 39/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 492ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0600 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.93      0.96        27\n",
            "      Normal       1.00      1.00      1.00        33\n",
            "Tuberculosis       0.94      1.00      0.97        30\n",
            "\n",
            "    accuracy                           0.98        90\n",
            "   macro avg       0.98      0.98      0.98        90\n",
            "weighted avg       0.98      0.98      0.98        90\n",
            "\n",
            "Fold #4\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 1: val_accuracy improved from -inf to 0.97778, saving model to  Kmodel16_soft_pre_cate4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate4.h5 /assets\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0340 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9942\n",
            "Epoch 2: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 493ms/step - loss: 0.0148 - accuracy: 0.9942 - val_loss: 0.0625 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9884\n",
            "Epoch 3: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 497ms/step - loss: 0.0482 - accuracy: 0.9884 - val_loss: 0.0488 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 1.0000\n",
            "Epoch 4: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 498ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 5: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 502ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy improved from 0.97778 to 0.98889, saving model to  Kmodel16_soft_pre_cate4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate4.h5 /assets\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9971\n",
            "Epoch 7: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 496ms/step - loss: 0.0067 - accuracy: 0.9971 - val_loss: 0.0414 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 497ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0566 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 498ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.1020 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9971\n",
            "Epoch 10: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 491ms/step - loss: 0.0030 - accuracy: 0.9971 - val_loss: 0.0470 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9971\n",
            "Epoch 11: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 494ms/step - loss: 0.0079 - accuracy: 0.9971 - val_loss: 0.0789 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9971\n",
            "Epoch 12: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 498ms/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 0.0924 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 499ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0575 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9971\n",
            "Epoch 14: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 499ms/step - loss: 0.0062 - accuracy: 0.9971 - val_loss: 0.0478 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9971\n",
            "Epoch 15: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 500ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.0473 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 12s 519ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9942\n",
            "Epoch 17: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 12s 522ms/step - loss: 0.0096 - accuracy: 0.9942 - val_loss: 0.0640 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 12s 524ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0656 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 12s 540ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0571 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 12s 527ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 12s 540ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0633 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.97      0.98        30\n",
            "      Normal       1.00      1.00      1.00        31\n",
            "Tuberculosis       0.97      1.00      0.98        29\n",
            "\n",
            "    accuracy                           0.99        90\n",
            "   macro avg       0.99      0.99      0.99        90\n",
            "weighted avg       0.99      0.99      0.99        90\n",
            "\n",
            "Fold #5\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 1: val_accuracy improved from -inf to 1.00000, saving model to  Kmodel16_soft_pre_cate5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate5.h5 /assets\n",
            "22/22 [==============================] - 50s 2s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9942\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 501ms/step - loss: 0.0112 - accuracy: 0.9942 - val_loss: 0.0188 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9971\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 12s 514ms/step - loss: 0.0036 - accuracy: 0.9971 - val_loss: 0.0132 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 12s 518ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 512ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 509ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9942\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 513ms/step - loss: 0.0131 - accuracy: 0.9942 - val_loss: 0.0018 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9972\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 12s 518ms/step - loss: 0.0134 - accuracy: 0.9972 - val_loss: 4.1423e-04 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 509ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 9.6711e-04 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 513ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 12s 512ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9971\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 514ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 0.0148 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000    \n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 512ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 12s 512ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 509ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 12s 514ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      1.00      1.00        31\n",
            "      Normal       1.00      1.00      1.00        28\n",
            "Tuberculosis       1.00      1.00      1.00        31\n",
            "\n",
            "    accuracy                           1.00        90\n",
            "   macro avg       1.00      1.00      1.00        90\n",
            "weighted avg       1.00      1.00      1.00        90\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.83      0.91       150\n",
            "      Normal       0.99      0.97      0.98       150\n",
            "Tuberculosis       0.84      1.00      0.91       150\n",
            "\n",
            "    accuracy                           0.94       450\n",
            "   macro avg       0.95      0.94      0.94       450\n",
            "weighted avg       0.95      0.94      0.94       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####16 soft pre cate adam\n"
      ],
      "metadata": {
        "id": "V1-B4YN5REHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 16                                                       ##\n",
        "filepath = \"Kmodel16_soft_pre_cate_adam.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "d800ef57-9b21-4c4e-848f-13e4d562a1db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkxTvAKFREHu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:11<00:00, 38.62it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel16_soft_pre_cate_adam{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "bRGqY3paREHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84b89a0f-3038-4318-b944-18067b0e1f6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold #1\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.7811 - accuracy: 0.6512\n",
            "Epoch 1: val_accuracy improved from -inf to 0.41111, saving model to  Kmodel16_soft_pre_cate_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_adam1.h5 /assets\n",
            "22/22 [==============================] - 71s 3s/step - loss: 0.7811 - accuracy: 0.6512 - val_loss: 1.4843 - val_accuracy: 0.4111 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.4689 - accuracy: 0.8227\n",
            "Epoch 2: val_accuracy improved from 0.41111 to 0.60000, saving model to  Kmodel16_soft_pre_cate_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_adam1.h5 /assets\n",
            "22/22 [==============================] - 50s 2s/step - loss: 0.4689 - accuracy: 0.8227 - val_loss: 0.9592 - val_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.3591 - accuracy: 0.8605\n",
            "Epoch 3: val_accuracy improved from 0.60000 to 0.61111, saving model to  Kmodel16_soft_pre_cate_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_adam1.h5 /assets\n",
            "22/22 [==============================] - 50s 2s/step - loss: 0.3591 - accuracy: 0.8605 - val_loss: 0.9721 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.2789 - accuracy: 0.8895\n",
            "Epoch 4: val_accuracy improved from 0.61111 to 0.64444, saving model to  Kmodel16_soft_pre_cate_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_adam1.h5 /assets\n",
            "22/22 [==============================] - 50s 2s/step - loss: 0.2789 - accuracy: 0.8895 - val_loss: 1.2683 - val_accuracy: 0.6444 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.2217 - accuracy: 0.9186\n",
            "Epoch 5: val_accuracy did not improve from 0.64444\n",
            "22/22 [==============================] - 12s 514ms/step - loss: 0.2217 - accuracy: 0.9186 - val_loss: 1.3714 - val_accuracy: 0.5333 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1560 - accuracy: 0.9331\n",
            "Epoch 6: val_accuracy improved from 0.64444 to 0.67778, saving model to  Kmodel16_soft_pre_cate_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_adam1.h5 /assets\n",
            "22/22 [==============================] - 50s 2s/step - loss: 0.1560 - accuracy: 0.9331 - val_loss: 0.9898 - val_accuracy: 0.6778 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1676 - accuracy: 0.9477\n",
            "Epoch 7: val_accuracy did not improve from 0.67778\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.1676 - accuracy: 0.9477 - val_loss: 1.2178 - val_accuracy: 0.6556 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1397 - accuracy: 0.9419\n",
            "Epoch 8: val_accuracy improved from 0.67778 to 0.70000, saving model to  Kmodel16_soft_pre_cate_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_adam1.h5 /assets\n",
            "22/22 [==============================] - 50s 2s/step - loss: 0.1397 - accuracy: 0.9419 - val_loss: 0.9874 - val_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1274 - accuracy: 0.9535\n",
            "Epoch 9: val_accuracy did not improve from 0.70000\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.1274 - accuracy: 0.9535 - val_loss: 1.2315 - val_accuracy: 0.6889 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.9651\n",
            "Epoch 10: val_accuracy improved from 0.70000 to 0.75556, saving model to  Kmodel16_soft_pre_cate_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_adam1.h5 /assets\n",
            "22/22 [==============================] - 50s 2s/step - loss: 0.0832 - accuracy: 0.9651 - val_loss: 0.8810 - val_accuracy: 0.7556 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0734 - accuracy: 0.9716\n",
            "Epoch 11: val_accuracy improved from 0.75556 to 0.77778, saving model to  Kmodel16_soft_pre_cate_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_adam1.h5 /assets\n",
            "22/22 [==============================] - 50s 2s/step - loss: 0.0734 - accuracy: 0.9716 - val_loss: 0.8198 - val_accuracy: 0.7778 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0824 - accuracy: 0.9738\n",
            "Epoch 12: val_accuracy improved from 0.77778 to 0.83333, saving model to  Kmodel16_soft_pre_cate_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_adam1.h5 /assets\n",
            "22/22 [==============================] - 50s 2s/step - loss: 0.0824 - accuracy: 0.9738 - val_loss: 0.7043 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0775 - accuracy: 0.9738\n",
            "Epoch 13: val_accuracy did not improve from 0.83333\n",
            "22/22 [==============================] - 11s 483ms/step - loss: 0.0775 - accuracy: 0.9738 - val_loss: 0.7656 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1166 - accuracy: 0.9651\n",
            "Epoch 14: val_accuracy did not improve from 0.83333\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.1166 - accuracy: 0.9651 - val_loss: 0.6639 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0806 - accuracy: 0.9767\n",
            "Epoch 15: val_accuracy did not improve from 0.83333\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.0806 - accuracy: 0.9767 - val_loss: 1.3096 - val_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 0.9767\n",
            "Epoch 16: val_accuracy did not improve from 0.83333\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.0655 - accuracy: 0.9767 - val_loss: 1.7818 - val_accuracy: 0.6222 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 0.9738\n",
            "Epoch 17: val_accuracy did not improve from 0.83333\n",
            "22/22 [==============================] - 11s 489ms/step - loss: 0.0548 - accuracy: 0.9738 - val_loss: 1.3886 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0749 - accuracy: 0.9709\n",
            "Epoch 18: val_accuracy did not improve from 0.83333\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.0749 - accuracy: 0.9709 - val_loss: 1.2575 - val_accuracy: 0.7111 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9913\n",
            "Epoch 19: val_accuracy did not improve from 0.83333\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.0294 - accuracy: 0.9913 - val_loss: 1.4082 - val_accuracy: 0.6889 - lr: 5.0000e-05\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9942\n",
            "Epoch 20: val_accuracy did not improve from 0.83333\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 1.5306 - val_accuracy: 0.6556 - lr: 5.0000e-05\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9942\n",
            "Epoch 21: val_accuracy did not improve from 0.83333\n",
            "22/22 [==============================] - 11s 489ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 1.5741 - val_accuracy: 0.6778 - lr: 5.0000e-05\n",
            "Epoch 22/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.9884\n",
            "Epoch 22: val_accuracy did not improve from 0.83333\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.0534 - accuracy: 0.9884 - val_loss: 1.2533 - val_accuracy: 0.7111 - lr: 5.0000e-05\n",
            "Epoch 23/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.9913\n",
            "Epoch 23: val_accuracy did not improve from 0.83333\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.0215 - accuracy: 0.9913 - val_loss: 1.1194 - val_accuracy: 0.7444 - lr: 5.0000e-05\n",
            "Epoch 24/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9942\n",
            "Epoch 24: val_accuracy did not improve from 0.83333\n",
            "\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.0186 - accuracy: 0.9942 - val_loss: 1.1401 - val_accuracy: 0.7333 - lr: 5.0000e-05\n",
            "Epoch 25/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0405 - accuracy: 0.9942\n",
            "Epoch 25: val_accuracy did not improve from 0.83333\n",
            "22/22 [==============================] - 11s 489ms/step - loss: 0.0405 - accuracy: 0.9942 - val_loss: 1.1804 - val_accuracy: 0.7444 - lr: 2.5000e-05\n",
            "Epoch 26/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 0.9884\n",
            "Epoch 26: val_accuracy did not improve from 0.83333\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.0427 - accuracy: 0.9884 - val_loss: 1.1918 - val_accuracy: 0.7333 - lr: 2.5000e-05\n",
            "Epoch 27/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 0.83333\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.1428 - val_accuracy: 0.7667 - lr: 2.5000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.54      0.70        28\n",
            "      Normal       1.00      0.74      0.85        31\n",
            "Tuberculosis       0.60      1.00      0.75        31\n",
            "\n",
            "    accuracy                           0.77        90\n",
            "   macro avg       0.87      0.76      0.77        90\n",
            "weighted avg       0.86      0.77      0.77        90\n",
            "\n",
            "Fold #2\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1792 - accuracy: 0.9535\n",
            "Epoch 1: val_accuracy improved from -inf to 0.98889, saving model to  Kmodel16_soft_pre_cate_adam2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_adam2.h5 /assets\n",
            "22/22 [==============================] - 51s 2s/step - loss: 0.1792 - accuracy: 0.9535 - val_loss: 0.0249 - val_accuracy: 0.9889 - lr: 2.5000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0920 - accuracy: 0.9622\n",
            "Epoch 2: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.0920 - accuracy: 0.9622 - val_loss: 0.0194 - val_accuracy: 0.9889 - lr: 2.5000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9797\n",
            "Epoch 3: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.0577 - accuracy: 0.9797 - val_loss: 0.0336 - val_accuracy: 0.9889 - lr: 2.5000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0582 - accuracy: 0.9797\n",
            "Epoch 4: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.0582 - accuracy: 0.9797 - val_loss: 0.0368 - val_accuracy: 0.9889 - lr: 2.5000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.9826\n",
            "Epoch 5: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.0468 - accuracy: 0.9826 - val_loss: 0.0487 - val_accuracy: 0.9889 - lr: 2.5000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.9826\n",
            "Epoch 6: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.0523 - accuracy: 0.9826 - val_loss: 0.0591 - val_accuracy: 0.9778 - lr: 2.5000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9855\n",
            "Epoch 7: val_accuracy did not improve from 0.98889\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.0363 - accuracy: 0.9855 - val_loss: 0.0865 - val_accuracy: 0.9667 - lr: 2.5000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0560 - accuracy: 0.9826\n",
            "Epoch 8: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 489ms/step - loss: 0.0560 - accuracy: 0.9826 - val_loss: 0.0896 - val_accuracy: 0.9667 - lr: 1.2500e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 0.9942\n",
            "Epoch 9: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 511ms/step - loss: 0.0287 - accuracy: 0.9942 - val_loss: 0.1011 - val_accuracy: 0.9556 - lr: 1.2500e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 0.9913\n",
            "Epoch 10: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 511ms/step - loss: 0.0315 - accuracy: 0.9913 - val_loss: 0.1084 - val_accuracy: 0.9556 - lr: 1.2500e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9855\n",
            "Epoch 11: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 12s 518ms/step - loss: 0.0298 - accuracy: 0.9855 - val_loss: 0.1039 - val_accuracy: 0.9556 - lr: 1.2500e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 0.9913\n",
            "Epoch 12: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 513ms/step - loss: 0.0360 - accuracy: 0.9913 - val_loss: 0.0825 - val_accuracy: 0.9667 - lr: 1.2500e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9855\n",
            "Epoch 13: val_accuracy did not improve from 0.98889\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "22/22 [==============================] - 11s 526ms/step - loss: 0.0392 - accuracy: 0.9855 - val_loss: 0.0681 - val_accuracy: 0.9667 - lr: 1.2500e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9826\n",
            "Epoch 14: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 503ms/step - loss: 0.0467 - accuracy: 0.9826 - val_loss: 0.0614 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.9826\n",
            "Epoch 15: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 12s 518ms/step - loss: 0.0614 - accuracy: 0.9826 - val_loss: 0.0731 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9826\n",
            "Epoch 16: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 12s 518ms/step - loss: 0.0510 - accuracy: 0.9826 - val_loss: 0.0988 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.91      0.95        34\n",
            "      Normal       1.00      0.93      0.96        27\n",
            "Tuberculosis       0.85      1.00      0.92        29\n",
            "\n",
            "    accuracy                           0.94        90\n",
            "   macro avg       0.95      0.95      0.95        90\n",
            "weighted avg       0.95      0.94      0.95        90\n",
            "\n",
            "Fold #3\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.9884\n",
            "Epoch 1: val_accuracy improved from -inf to 0.97778, saving model to  Kmodel16_soft_pre_cate_adam3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_adam3.h5 /assets\n",
            "22/22 [==============================] - 52s 2s/step - loss: 0.0500 - accuracy: 0.9884 - val_loss: 0.0672 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 1.0000\n",
            "Epoch 2: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 492ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0622 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9913\n",
            "Epoch 3: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.0199 - accuracy: 0.9913 - val_loss: 0.0641 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0396 - accuracy: 0.9855\n",
            "Epoch 4: val_accuracy improved from 0.97778 to 0.98889, saving model to  Kmodel16_soft_pre_cate_adam3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_adam3.h5 /assets\n",
            "22/22 [==============================] - 50s 2s/step - loss: 0.0396 - accuracy: 0.9855 - val_loss: 0.0633 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 1.0000\n",
            "Epoch 5: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 489ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0575 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9942\n",
            "Epoch 6: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.0525 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 0.9913\n",
            "Epoch 7: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.0252 - accuracy: 0.9913 - val_loss: 0.0449 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9971\n",
            "Epoch 8: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.0202 - accuracy: 0.9971 - val_loss: 0.0363 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9913\n",
            "Epoch 9: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 489ms/step - loss: 0.0164 - accuracy: 0.9913 - val_loss: 0.0427 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9942\n",
            "Epoch 10: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.0264 - accuracy: 0.9942 - val_loss: 0.0416 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9971\n",
            "Epoch 11: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 489ms/step - loss: 0.0148 - accuracy: 0.9971 - val_loss: 0.0482 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9971\n",
            "Epoch 12: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.0173 - accuracy: 0.9971 - val_loss: 0.0534 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9972\n",
            "Epoch 13: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 495ms/step - loss: 0.0210 - accuracy: 0.9972 - val_loss: 0.0530 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9971\n",
            "Epoch 14: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.0632 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9971\n",
            "Epoch 15: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.0598 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9971\n",
            "Epoch 16: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.0118 - accuracy: 0.9971 - val_loss: 0.0581 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9971\n",
            "Epoch 17: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.0126 - accuracy: 0.9971 - val_loss: 0.0640 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0674 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9971\n",
            "Epoch 19: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.0140 - accuracy: 0.9971 - val_loss: 0.0677 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.93      0.96        27\n",
            "      Normal       1.00      1.00      1.00        33\n",
            "Tuberculosis       0.94      1.00      0.97        30\n",
            "\n",
            "    accuracy                           0.98        90\n",
            "   macro avg       0.98      0.98      0.98        90\n",
            "weighted avg       0.98      0.98      0.98        90\n",
            "\n",
            "Fold #4\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9942\n",
            "Epoch 1: val_accuracy improved from -inf to 0.94444, saving model to  Kmodel16_soft_pre_cate_adam4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_adam4.h5 /assets\n",
            "22/22 [==============================] - 51s 2s/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 0.0994 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 1.0000\n",
            "Epoch 2: val_accuracy improved from 0.94444 to 0.96667, saving model to  Kmodel16_soft_pre_cate_adam4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_adam4.h5 /assets\n",
            "22/22 [==============================] - 50s 2s/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9942\n",
            "Epoch 3: val_accuracy did not improve from 0.96667\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.0228 - accuracy: 0.9942 - val_loss: 0.1342 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9913\n",
            "Epoch 4: val_accuracy did not improve from 0.96667\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.0340 - accuracy: 0.9913 - val_loss: 0.1080 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 0.9913\n",
            "Epoch 5: val_accuracy did not improve from 0.96667\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.0205 - accuracy: 0.9913 - val_loss: 0.0795 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9942\n",
            "Epoch 6: val_accuracy did not improve from 0.96667\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.0828 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9971\n",
            "Epoch 7: val_accuracy did not improve from 0.96667\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.0107 - accuracy: 0.9971 - val_loss: 0.0884 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 0.9855\n",
            "Epoch 8: val_accuracy did not improve from 0.96667\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.0315 - accuracy: 0.9855 - val_loss: 0.0840 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 0.96667\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 1.0000\n",
            "Epoch 10: val_accuracy did not improve from 0.96667\n",
            "22/22 [==============================] - 11s 489ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0666 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9971\n",
            "Epoch 11: val_accuracy did not improve from 0.96667\n",
            "22/22 [==============================] - 11s 494ms/step - loss: 0.0115 - accuracy: 0.9971 - val_loss: 0.0518 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy improved from 0.96667 to 0.98889, saving model to  Kmodel16_soft_pre_cate_adam4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_adam4.h5 /assets\n",
            "22/22 [==============================] - 50s 2s/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0363 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9913\n",
            "Epoch 14: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 489ms/step - loss: 0.0170 - accuracy: 0.9913 - val_loss: 0.0359 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9942\n",
            "Epoch 15: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.0225 - accuracy: 0.9942 - val_loss: 0.0283 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9913\n",
            "Epoch 16: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 0.0338 - accuracy: 0.9913 - val_loss: 0.0327 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9942\n",
            "Epoch 17: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.0136 - accuracy: 0.9942 - val_loss: 0.0364 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9942\n",
            "Epoch 18: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.0144 - accuracy: 0.9942 - val_loss: 0.0745 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9942\n",
            "Epoch 19: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.0196 - accuracy: 0.9942 - val_loss: 0.0537 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.9943\n",
            "Epoch 20: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 497ms/step - loss: 0.0130 - accuracy: 0.9943 - val_loss: 0.0515 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 489ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9913\n",
            "Epoch 22: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.0200 - accuracy: 0.9913 - val_loss: 0.0554 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9971\n",
            "Epoch 23: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.0557 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0599 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9942\n",
            "Epoch 25: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.0148 - accuracy: 0.9942 - val_loss: 0.0595 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.9971\n",
            "Epoch 26: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 491ms/step - loss: 0.0132 - accuracy: 0.9971 - val_loss: 0.0644 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 27/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 489ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0611 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.90      0.95        30\n",
            "      Normal       1.00      1.00      1.00        31\n",
            "Tuberculosis       0.91      1.00      0.95        29\n",
            "\n",
            "    accuracy                           0.97        90\n",
            "   macro avg       0.97      0.97      0.97        90\n",
            "weighted avg       0.97      0.97      0.97        90\n",
            "\n",
            "Fold #5\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9971\n",
            "Epoch 1: val_accuracy improved from -inf to 0.98889, saving model to  Kmodel16_soft_pre_cate_adam5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_adam5.h5 /assets\n",
            "22/22 [==============================] - 50s 2s/step - loss: 0.0106 - accuracy: 0.9971 - val_loss: 0.0329 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9971\n",
            "Epoch 2: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.0351 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 3: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9971\n",
            "Epoch 4: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.0145 - accuracy: 0.9971 - val_loss: 0.0420 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9942\n",
            "Epoch 5: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 491ms/step - loss: 0.0100 - accuracy: 0.9942 - val_loss: 0.0480 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9971\n",
            "Epoch 7: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 491ms/step - loss: 0.0122 - accuracy: 0.9971 - val_loss: 0.0439 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9942\n",
            "Epoch 9: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 491ms/step - loss: 0.0200 - accuracy: 0.9942 - val_loss: 0.0517 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9971\n",
            "Epoch 10: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 505ms/step - loss: 0.0076 - accuracy: 0.9971 - val_loss: 0.0591 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9855\n",
            "Epoch 11: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.0465 - accuracy: 0.9855 - val_loss: 0.0447 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0572 - accuracy: 0.9767\n",
            "Epoch 12: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 489ms/step - loss: 0.0572 - accuracy: 0.9767 - val_loss: 0.0438 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9971\n",
            "Epoch 13: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 483ms/step - loss: 0.0114 - accuracy: 0.9971 - val_loss: 0.0348 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.9913\n",
            "Epoch 15: val_accuracy improved from 0.98889 to 1.00000, saving model to  Kmodel16_soft_pre_cate_adam5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_adam5.h5 /assets\n",
            "22/22 [==============================] - 50s 2s/step - loss: 0.0265 - accuracy: 0.9913 - val_loss: 0.0392 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9884\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.0302 - accuracy: 0.9884 - val_loss: 0.0439 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9971\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 492ms/step - loss: 0.0072 - accuracy: 0.9971 - val_loss: 0.0435 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 500ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9971\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 492ms/step - loss: 0.0106 - accuracy: 0.9971 - val_loss: 0.0321 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9971\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.0126 - accuracy: 0.9971 - val_loss: 0.0197 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9971\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 12s 516ms/step - loss: 0.0103 - accuracy: 0.9971 - val_loss: 0.0196 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 12s 521ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9855\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 12s 518ms/step - loss: 0.0247 - accuracy: 0.9855 - val_loss: 0.0308 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9913\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 503ms/step - loss: 0.0244 - accuracy: 0.9913 - val_loss: 0.0489 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 12s 522ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9913\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 12s 533ms/step - loss: 0.0185 - accuracy: 0.9913 - val_loss: 0.0302 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 27/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 12s 525ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 28/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 12s 523ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0300 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 29/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 494ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 30/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 492ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.97      0.98        31\n",
            "      Normal       1.00      1.00      1.00        28\n",
            "Tuberculosis       0.97      1.00      0.98        31\n",
            "\n",
            "    accuracy                           0.99        90\n",
            "   macro avg       0.99      0.99      0.99        90\n",
            "weighted avg       0.99      0.99      0.99        90\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.85      0.92       150\n",
            "      Normal       1.00      0.93      0.97       150\n",
            "Tuberculosis       0.82      1.00      0.90       150\n",
            "\n",
            "    accuracy                           0.93       450\n",
            "   macro avg       0.94      0.93      0.93       450\n",
            "weighted avg       0.94      0.93      0.93       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 16 soft pre cate sgd\n"
      ],
      "metadata": {
        "id": "b3TXk6OsREHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 16                                                       ##\n",
        "filepath = \"Kmodel16_soft_pre_cate_sgd.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" )\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "cc0fee0d-343b-448e-edf0-cbbf8be674d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFF_2ASxREHv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:11<00:00, 38.52it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel16_soft_pre_cate_sgd{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "elc3h1RWREHv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4672b9ec-436e-4c7e-d64e-5997dd467328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold #1\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.1706 - accuracy: 0.3140\n",
            "Epoch 1: val_accuracy improved from -inf to 0.35556, saving model to  Kmodel16_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd1.h5 /assets\n",
            "22/22 [==============================] - 57s 2s/step - loss: 1.1706 - accuracy: 0.3140 - val_loss: 1.1708 - val_accuracy: 0.3556 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.1396 - accuracy: 0.3663\n",
            "Epoch 2: val_accuracy did not improve from 0.35556\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 1.1396 - accuracy: 0.3663 - val_loss: 1.1458 - val_accuracy: 0.2889 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.1336 - accuracy: 0.3285\n",
            "Epoch 3: val_accuracy did not improve from 0.35556\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 1.1336 - accuracy: 0.3285 - val_loss: 1.1415 - val_accuracy: 0.3444 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.1216 - accuracy: 0.3198\n",
            "Epoch 4: val_accuracy did not improve from 0.35556\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 1.1216 - accuracy: 0.3198 - val_loss: 1.1365 - val_accuracy: 0.3444 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.1201 - accuracy: 0.3517\n",
            "Epoch 5: val_accuracy did not improve from 0.35556\n",
            "22/22 [==============================] - 11s 507ms/step - loss: 1.1201 - accuracy: 0.3517 - val_loss: 1.1245 - val_accuracy: 0.3444 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.1055 - accuracy: 0.3866\n",
            "Epoch 6: val_accuracy did not improve from 0.35556\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 1.1055 - accuracy: 0.3866 - val_loss: 1.1214 - val_accuracy: 0.3222 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.1167 - accuracy: 0.3256\n",
            "Epoch 7: val_accuracy improved from 0.35556 to 0.36667, saving model to  Kmodel16_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd1.h5 /assets\n",
            "22/22 [==============================] - 48s 2s/step - loss: 1.1167 - accuracy: 0.3256 - val_loss: 1.1154 - val_accuracy: 0.3667 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.0892 - accuracy: 0.3983\n",
            "Epoch 8: val_accuracy did not improve from 0.36667\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 1.0892 - accuracy: 0.3983 - val_loss: 1.1089 - val_accuracy: 0.3556 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.0578 - accuracy: 0.4432\n",
            "Epoch 9: val_accuracy improved from 0.36667 to 0.38889, saving model to  Kmodel16_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd1.h5 /assets\n",
            "22/22 [==============================] - 49s 2s/step - loss: 1.0578 - accuracy: 0.4432 - val_loss: 1.1025 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.0918 - accuracy: 0.3924\n",
            "Epoch 10: val_accuracy improved from 0.38889 to 0.41111, saving model to  Kmodel16_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd1.h5 /assets\n",
            "22/22 [==============================] - 48s 2s/step - loss: 1.0918 - accuracy: 0.3924 - val_loss: 1.0962 - val_accuracy: 0.4111 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.0607 - accuracy: 0.4448\n",
            "Epoch 11: val_accuracy improved from 0.41111 to 0.42222, saving model to  Kmodel16_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd1.h5 /assets\n",
            "22/22 [==============================] - 48s 2s/step - loss: 1.0607 - accuracy: 0.4448 - val_loss: 1.0898 - val_accuracy: 0.4222 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.0528 - accuracy: 0.4432\n",
            "Epoch 12: val_accuracy did not improve from 0.42222\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 1.0528 - accuracy: 0.4432 - val_loss: 1.0809 - val_accuracy: 0.4111 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.0441 - accuracy: 0.4448\n",
            "Epoch 13: val_accuracy did not improve from 0.42222\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 1.0441 - accuracy: 0.4448 - val_loss: 1.0742 - val_accuracy: 0.4222 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.0466 - accuracy: 0.4128\n",
            "Epoch 14: val_accuracy did not improve from 0.42222\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 1.0466 - accuracy: 0.4128 - val_loss: 1.0693 - val_accuracy: 0.4111 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.0466 - accuracy: 0.4273\n",
            "Epoch 15: val_accuracy improved from 0.42222 to 0.45556, saving model to  Kmodel16_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd1.h5 /assets\n",
            "22/22 [==============================] - 48s 2s/step - loss: 1.0466 - accuracy: 0.4273 - val_loss: 1.0647 - val_accuracy: 0.4556 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.0414 - accuracy: 0.4477\n",
            "Epoch 16: val_accuracy did not improve from 0.45556\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 1.0414 - accuracy: 0.4477 - val_loss: 1.0594 - val_accuracy: 0.4556 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.0309 - accuracy: 0.4593\n",
            "Epoch 17: val_accuracy did not improve from 0.45556\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 1.0309 - accuracy: 0.4593 - val_loss: 1.0547 - val_accuracy: 0.4556 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.0469 - accuracy: 0.4651\n",
            "Epoch 18: val_accuracy improved from 0.45556 to 0.47778, saving model to  Kmodel16_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd1.h5 /assets\n",
            "22/22 [==============================] - 49s 2s/step - loss: 1.0469 - accuracy: 0.4651 - val_loss: 1.0500 - val_accuracy: 0.4778 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.0228 - accuracy: 0.5087\n",
            "Epoch 19: val_accuracy did not improve from 0.47778\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 1.0228 - accuracy: 0.5087 - val_loss: 1.0445 - val_accuracy: 0.4778 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.0043 - accuracy: 0.5523\n",
            "Epoch 20: val_accuracy did not improve from 0.47778\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 1.0043 - accuracy: 0.5523 - val_loss: 1.0403 - val_accuracy: 0.4778 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9997 - accuracy: 0.5116\n",
            "Epoch 21: val_accuracy did not improve from 0.47778\n",
            "22/22 [==============================] - 11s 506ms/step - loss: 0.9997 - accuracy: 0.5116 - val_loss: 1.0355 - val_accuracy: 0.4667 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.0063 - accuracy: 0.5233\n",
            "Epoch 22: val_accuracy did not improve from 0.47778\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 1.0063 - accuracy: 0.5233 - val_loss: 1.0305 - val_accuracy: 0.4667 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.0001 - accuracy: 0.5291\n",
            "Epoch 23: val_accuracy did not improve from 0.47778\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 1.0001 - accuracy: 0.5291 - val_loss: 1.0258 - val_accuracy: 0.4667 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9912 - accuracy: 0.5465\n",
            "Epoch 24: val_accuracy improved from 0.47778 to 0.48889, saving model to  Kmodel16_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd1.h5 /assets\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.9912 - accuracy: 0.5465 - val_loss: 1.0238 - val_accuracy: 0.4889 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9952 - accuracy: 0.5581\n",
            "Epoch 25: val_accuracy improved from 0.48889 to 0.50000, saving model to  Kmodel16_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd1.h5 /assets\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.9952 - accuracy: 0.5581 - val_loss: 1.0199 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9902 - accuracy: 0.5640\n",
            "Epoch 26: val_accuracy improved from 0.50000 to 0.51111, saving model to  Kmodel16_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd1.h5 /assets\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.9902 - accuracy: 0.5640 - val_loss: 1.0160 - val_accuracy: 0.5111 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9900 - accuracy: 0.5320\n",
            "Epoch 27: val_accuracy did not improve from 0.51111\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.9900 - accuracy: 0.5320 - val_loss: 1.0123 - val_accuracy: 0.5111 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9798 - accuracy: 0.5378\n",
            "Epoch 28: val_accuracy improved from 0.51111 to 0.52222, saving model to  Kmodel16_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd1.h5 /assets\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.9798 - accuracy: 0.5378 - val_loss: 1.0078 - val_accuracy: 0.5222 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9500 - accuracy: 0.6221\n",
            "Epoch 29: val_accuracy did not improve from 0.52222\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.9500 - accuracy: 0.6221 - val_loss: 1.0042 - val_accuracy: 0.5222 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9671 - accuracy: 0.5756\n",
            "Epoch 30: val_accuracy did not improve from 0.52222\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.9671 - accuracy: 0.5756 - val_loss: 1.0005 - val_accuracy: 0.5111 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9694 - accuracy: 0.5610\n",
            "Epoch 31: val_accuracy did not improve from 0.52222\n",
            "22/22 [==============================] - 12s 516ms/step - loss: 0.9694 - accuracy: 0.5610 - val_loss: 0.9967 - val_accuracy: 0.5222 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9698 - accuracy: 0.5552\n",
            "Epoch 32: val_accuracy did not improve from 0.52222\n",
            "22/22 [==============================] - 11s 514ms/step - loss: 0.9698 - accuracy: 0.5552 - val_loss: 0.9931 - val_accuracy: 0.5222 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9598 - accuracy: 0.5233\n",
            "Epoch 33: val_accuracy improved from 0.52222 to 0.53333, saving model to  Kmodel16_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd1.h5 /assets\n",
            "22/22 [==============================] - 50s 2s/step - loss: 0.9598 - accuracy: 0.5233 - val_loss: 0.9884 - val_accuracy: 0.5333 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9632 - accuracy: 0.5959\n",
            "Epoch 34: val_accuracy improved from 0.53333 to 0.56667, saving model to  Kmodel16_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd1.h5 /assets\n",
            "22/22 [==============================] - 49s 2s/step - loss: 0.9632 - accuracy: 0.5959 - val_loss: 0.9845 - val_accuracy: 0.5667 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9568 - accuracy: 0.5988\n",
            "Epoch 35: val_accuracy did not improve from 0.56667\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.9568 - accuracy: 0.5988 - val_loss: 0.9807 - val_accuracy: 0.5667 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9491 - accuracy: 0.5523\n",
            "Epoch 36: val_accuracy did not improve from 0.56667\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.9491 - accuracy: 0.5523 - val_loss: 0.9775 - val_accuracy: 0.5667 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9395 - accuracy: 0.5843\n",
            "Epoch 37: val_accuracy did not improve from 0.56667\n",
            "22/22 [==============================] - 11s 500ms/step - loss: 0.9395 - accuracy: 0.5843 - val_loss: 0.9740 - val_accuracy: 0.5667 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9308 - accuracy: 0.6192\n",
            "Epoch 38: val_accuracy improved from 0.56667 to 0.57778, saving model to  Kmodel16_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd1.h5 /assets\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.9308 - accuracy: 0.6192 - val_loss: 0.9721 - val_accuracy: 0.5778 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9438 - accuracy: 0.6047\n",
            "Epoch 39: val_accuracy did not improve from 0.57778\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.9438 - accuracy: 0.6047 - val_loss: 0.9678 - val_accuracy: 0.5778 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9252 - accuracy: 0.5959\n",
            "Epoch 40: val_accuracy did not improve from 0.57778\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.9252 - accuracy: 0.5959 - val_loss: 0.9641 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9195 - accuracy: 0.6192\n",
            "Epoch 41: val_accuracy did not improve from 0.57778\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.9195 - accuracy: 0.6192 - val_loss: 0.9604 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9110 - accuracy: 0.6134\n",
            "Epoch 42: val_accuracy did not improve from 0.57778\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.9110 - accuracy: 0.6134 - val_loss: 0.9567 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9126 - accuracy: 0.6105\n",
            "Epoch 43: val_accuracy did not improve from 0.57778\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.9126 - accuracy: 0.6105 - val_loss: 0.9536 - val_accuracy: 0.5667 - lr: 1.0000e-04\n",
            "Epoch 44/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9047 - accuracy: 0.6134\n",
            "Epoch 44: val_accuracy did not improve from 0.57778\n",
            "\n",
            "Epoch 44: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.9047 - accuracy: 0.6134 - val_loss: 0.9490 - val_accuracy: 0.5778 - lr: 1.0000e-04\n",
            "Epoch 45/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8928 - accuracy: 0.6250\n",
            "Epoch 45: val_accuracy improved from 0.57778 to 0.58889, saving model to  Kmodel16_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd1.h5 /assets\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.8928 - accuracy: 0.6250 - val_loss: 0.9474 - val_accuracy: 0.5889 - lr: 5.0000e-05\n",
            "Epoch 46/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9062 - accuracy: 0.6453\n",
            "Epoch 46: val_accuracy improved from 0.58889 to 0.60000, saving model to  Kmodel16_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd1.h5 /assets\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.9062 - accuracy: 0.6453 - val_loss: 0.9454 - val_accuracy: 0.6000 - lr: 5.0000e-05\n",
            "Epoch 47/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9043 - accuracy: 0.6221\n",
            "Epoch 47: val_accuracy did not improve from 0.60000\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.9043 - accuracy: 0.6221 - val_loss: 0.9433 - val_accuracy: 0.5889 - lr: 5.0000e-05\n",
            "Epoch 48/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8975 - accuracy: 0.6250\n",
            "Epoch 48: val_accuracy did not improve from 0.60000\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 0.8975 - accuracy: 0.6250 - val_loss: 0.9432 - val_accuracy: 0.5778 - lr: 5.0000e-05\n",
            "Epoch 49/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9054 - accuracy: 0.6279\n",
            "Epoch 49: val_accuracy did not improve from 0.60000\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.9054 - accuracy: 0.6279 - val_loss: 0.9413 - val_accuracy: 0.5778 - lr: 5.0000e-05\n",
            "Epoch 50/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9175 - accuracy: 0.6192\n",
            "Epoch 50: val_accuracy did not improve from 0.60000\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.9175 - accuracy: 0.6192 - val_loss: 0.9391 - val_accuracy: 0.5889 - lr: 5.0000e-05\n",
            "Epoch 51/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8857 - accuracy: 0.6628\n",
            "Epoch 51: val_accuracy did not improve from 0.60000\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 0.8857 - accuracy: 0.6628 - val_loss: 0.9385 - val_accuracy: 0.6000 - lr: 5.0000e-05\n",
            "Epoch 52/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8882 - accuracy: 0.6657\n",
            "Epoch 52: val_accuracy did not improve from 0.60000\n",
            "\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.8882 - accuracy: 0.6657 - val_loss: 0.9353 - val_accuracy: 0.5889 - lr: 5.0000e-05\n",
            "Epoch 53/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8799 - accuracy: 0.6715\n",
            "Epoch 53: val_accuracy did not improve from 0.60000\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.8799 - accuracy: 0.6715 - val_loss: 0.9344 - val_accuracy: 0.5889 - lr: 2.5000e-05\n",
            "Epoch 54/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9022 - accuracy: 0.6017\n",
            "Epoch 54: val_accuracy did not improve from 0.60000\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.9022 - accuracy: 0.6017 - val_loss: 0.9341 - val_accuracy: 0.5667 - lr: 2.5000e-05\n",
            "Epoch 55/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8703 - accuracy: 0.6570\n",
            "Epoch 55: val_accuracy did not improve from 0.60000\n",
            "22/22 [==============================] - 11s 489ms/step - loss: 0.8703 - accuracy: 0.6570 - val_loss: 0.9338 - val_accuracy: 0.5778 - lr: 2.5000e-05\n",
            "Epoch 56/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8894 - accuracy: 0.6221\n",
            "Epoch 56: val_accuracy did not improve from 0.60000\n",
            "22/22 [==============================] - 11s 492ms/step - loss: 0.8894 - accuracy: 0.6221 - val_loss: 0.9327 - val_accuracy: 0.5778 - lr: 2.5000e-05\n",
            "Epoch 57/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8844 - accuracy: 0.6628\n",
            "Epoch 57: val_accuracy did not improve from 0.60000\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.8844 - accuracy: 0.6628 - val_loss: 0.9323 - val_accuracy: 0.5778 - lr: 2.5000e-05\n",
            "Epoch 58/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8864 - accuracy: 0.6453\n",
            "Epoch 58: val_accuracy did not improve from 0.60000\n",
            "\n",
            "Epoch 58: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "22/22 [==============================] - 11s 483ms/step - loss: 0.8864 - accuracy: 0.6453 - val_loss: 0.9309 - val_accuracy: 0.5778 - lr: 2.5000e-05\n",
            "Epoch 59/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8900 - accuracy: 0.6453\n",
            "Epoch 59: val_accuracy did not improve from 0.60000\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.8900 - accuracy: 0.6453 - val_loss: 0.9310 - val_accuracy: 0.5778 - lr: 1.2500e-05\n",
            "Epoch 60/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8722 - accuracy: 0.6744\n",
            "Epoch 60: val_accuracy did not improve from 0.60000\n",
            "22/22 [==============================] - 11s 476ms/step - loss: 0.8722 - accuracy: 0.6744 - val_loss: 0.9295 - val_accuracy: 0.5778 - lr: 1.2500e-05\n",
            "Epoch 61/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9004 - accuracy: 0.5959\n",
            "Epoch 61: val_accuracy did not improve from 0.60000\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.9004 - accuracy: 0.5959 - val_loss: 0.9291 - val_accuracy: 0.5778 - lr: 1.2500e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.54      0.46      0.50        28\n",
            "      Normal       0.74      0.84      0.79        31\n",
            "Tuberculosis       0.42      0.42      0.42        31\n",
            "\n",
            "    accuracy                           0.58        90\n",
            "   macro avg       0.57      0.57      0.57        90\n",
            "weighted avg       0.57      0.58      0.57        90\n",
            "\n",
            "Fold #2\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8910 - accuracy: 0.6424\n",
            "Epoch 1: val_accuracy improved from -inf to 0.63333, saving model to  Kmodel16_soft_pre_cate_sgd2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd2.h5 /assets\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.8910 - accuracy: 0.6424 - val_loss: 0.9065 - val_accuracy: 0.6333 - lr: 1.2500e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8909 - accuracy: 0.5988\n",
            "Epoch 2: val_accuracy improved from 0.63333 to 0.64444, saving model to  Kmodel16_soft_pre_cate_sgd2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd2.h5 /assets\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.8909 - accuracy: 0.5988 - val_loss: 0.9064 - val_accuracy: 0.6444 - lr: 1.2500e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8789 - accuracy: 0.6483\n",
            "Epoch 3: val_accuracy did not improve from 0.64444\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.8789 - accuracy: 0.6483 - val_loss: 0.9056 - val_accuracy: 0.6444 - lr: 1.2500e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9132 - accuracy: 0.5785\n",
            "Epoch 4: val_accuracy did not improve from 0.64444\n",
            "22/22 [==============================] - 11s 478ms/step - loss: 0.9132 - accuracy: 0.5785 - val_loss: 0.9045 - val_accuracy: 0.6444 - lr: 1.2500e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8882 - accuracy: 0.6395\n",
            "Epoch 5: val_accuracy did not improve from 0.64444\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.8882 - accuracy: 0.6395 - val_loss: 0.9040 - val_accuracy: 0.6444 - lr: 1.2500e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9174 - accuracy: 0.5872\n",
            "Epoch 6: val_accuracy did not improve from 0.64444\n",
            "22/22 [==============================] - 11s 480ms/step - loss: 0.9174 - accuracy: 0.5872 - val_loss: 0.9029 - val_accuracy: 0.6444 - lr: 1.2500e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9032 - accuracy: 0.5959\n",
            "Epoch 7: val_accuracy did not improve from 0.64444\n",
            "22/22 [==============================] - 11s 476ms/step - loss: 0.9032 - accuracy: 0.5959 - val_loss: 0.9033 - val_accuracy: 0.6444 - lr: 1.2500e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8964 - accuracy: 0.5959\n",
            "Epoch 8: val_accuracy improved from 0.64444 to 0.65556, saving model to  Kmodel16_soft_pre_cate_sgd2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd2.h5 /assets\n",
            "22/22 [==============================] - 47s 2s/step - loss: 0.8964 - accuracy: 0.5959 - val_loss: 0.9032 - val_accuracy: 0.6556 - lr: 1.2500e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8732 - accuracy: 0.6773\n",
            "Epoch 9: val_accuracy did not improve from 0.65556\n",
            "22/22 [==============================] - 11s 479ms/step - loss: 0.8732 - accuracy: 0.6773 - val_loss: 0.9023 - val_accuracy: 0.6556 - lr: 1.2500e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8945 - accuracy: 0.6453\n",
            "Epoch 10: val_accuracy did not improve from 0.65556\n",
            "22/22 [==============================] - 11s 480ms/step - loss: 0.8945 - accuracy: 0.6453 - val_loss: 0.9003 - val_accuracy: 0.6556 - lr: 1.2500e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8776 - accuracy: 0.6453\n",
            "Epoch 11: val_accuracy did not improve from 0.65556\n",
            "22/22 [==============================] - 11s 483ms/step - loss: 0.8776 - accuracy: 0.6453 - val_loss: 0.9003 - val_accuracy: 0.6556 - lr: 1.2500e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8926 - accuracy: 0.6686\n",
            "Epoch 12: val_accuracy did not improve from 0.65556\n",
            "22/22 [==============================] - 11s 478ms/step - loss: 0.8926 - accuracy: 0.6686 - val_loss: 0.8996 - val_accuracy: 0.6556 - lr: 1.2500e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8857 - accuracy: 0.6424\n",
            "Epoch 13: val_accuracy did not improve from 0.65556\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.8857 - accuracy: 0.6424 - val_loss: 0.8996 - val_accuracy: 0.6556 - lr: 1.2500e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8784 - accuracy: 0.6570\n",
            "Epoch 14: val_accuracy improved from 0.65556 to 0.66667, saving model to  Kmodel16_soft_pre_cate_sgd2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd2.h5 /assets\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.8784 - accuracy: 0.6570 - val_loss: 0.8998 - val_accuracy: 0.6667 - lr: 1.2500e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8833 - accuracy: 0.6541\n",
            "Epoch 15: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.8833 - accuracy: 0.6541 - val_loss: 0.9003 - val_accuracy: 0.6556 - lr: 1.2500e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8645 - accuracy: 0.6715\n",
            "Epoch 16: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 478ms/step - loss: 0.8645 - accuracy: 0.6715 - val_loss: 0.8997 - val_accuracy: 0.6556 - lr: 1.2500e-05\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8784 - accuracy: 0.6395\n",
            "Epoch 17: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.8784 - accuracy: 0.6395 - val_loss: 0.8990 - val_accuracy: 0.6667 - lr: 1.2500e-05\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8885 - accuracy: 0.5785\n",
            "Epoch 18: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 483ms/step - loss: 0.8885 - accuracy: 0.5785 - val_loss: 0.8996 - val_accuracy: 0.6667 - lr: 1.2500e-05\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8697 - accuracy: 0.6628\n",
            "Epoch 19: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.8697 - accuracy: 0.6628 - val_loss: 0.8989 - val_accuracy: 0.6667 - lr: 1.2500e-05\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8749 - accuracy: 0.6562\n",
            "Epoch 20: val_accuracy did not improve from 0.66667\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "22/22 [==============================] - 11s 493ms/step - loss: 0.8749 - accuracy: 0.6562 - val_loss: 0.8989 - val_accuracy: 0.6667 - lr: 1.2500e-05\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8809 - accuracy: 0.6308\n",
            "Epoch 21: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.8809 - accuracy: 0.6308 - val_loss: 0.8987 - val_accuracy: 0.6556 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.9007 - accuracy: 0.6163\n",
            "Epoch 22: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 480ms/step - loss: 0.9007 - accuracy: 0.6163 - val_loss: 0.8983 - val_accuracy: 0.6556 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8857 - accuracy: 0.6337\n",
            "Epoch 23: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 481ms/step - loss: 0.8857 - accuracy: 0.6337 - val_loss: 0.8980 - val_accuracy: 0.6556 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8908 - accuracy: 0.5988\n",
            "Epoch 24: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 483ms/step - loss: 0.8908 - accuracy: 0.5988 - val_loss: 0.8982 - val_accuracy: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8659 - accuracy: 0.6192\n",
            "Epoch 25: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.8659 - accuracy: 0.6192 - val_loss: 0.8984 - val_accuracy: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8575 - accuracy: 0.6512\n",
            "Epoch 26: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 483ms/step - loss: 0.8575 - accuracy: 0.6512 - val_loss: 0.8977 - val_accuracy: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 27/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8603 - accuracy: 0.6773\n",
            "Epoch 27: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.8603 - accuracy: 0.6773 - val_loss: 0.8958 - val_accuracy: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 28/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8850 - accuracy: 0.6134\n",
            "Epoch 28: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 483ms/step - loss: 0.8850 - accuracy: 0.6134 - val_loss: 0.8958 - val_accuracy: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 29/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8812 - accuracy: 0.6366\n",
            "Epoch 29: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 483ms/step - loss: 0.8812 - accuracy: 0.6366 - val_loss: 0.8960 - val_accuracy: 0.6667 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.66      0.62      0.64        34\n",
            "      Normal       0.71      0.89      0.79        27\n",
            "Tuberculosis       0.62      0.52      0.57        29\n",
            "\n",
            "    accuracy                           0.67        90\n",
            "   macro avg       0.66      0.67      0.66        90\n",
            "weighted avg       0.66      0.67      0.66        90\n",
            "\n",
            "Fold #3\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8906 - accuracy: 0.6192\n",
            "Epoch 1: val_accuracy improved from -inf to 0.60000, saving model to  Kmodel16_soft_pre_cate_sgd3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd3.h5 /assets\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.8906 - accuracy: 0.6192 - val_loss: 0.9209 - val_accuracy: 0.6000 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8883 - accuracy: 0.5901\n",
            "Epoch 2: val_accuracy did not improve from 0.60000\n",
            "22/22 [==============================] - 11s 479ms/step - loss: 0.8883 - accuracy: 0.5901 - val_loss: 0.9213 - val_accuracy: 0.6000 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8677 - accuracy: 0.6570\n",
            "Epoch 3: val_accuracy improved from 0.60000 to 0.62222, saving model to  Kmodel16_soft_pre_cate_sgd3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd3.h5 /assets\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.8677 - accuracy: 0.6570 - val_loss: 0.9208 - val_accuracy: 0.6222 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8583 - accuracy: 0.6802\n",
            "Epoch 4: val_accuracy did not improve from 0.62222\n",
            "22/22 [==============================] - 11s 481ms/step - loss: 0.8583 - accuracy: 0.6802 - val_loss: 0.9209 - val_accuracy: 0.6222 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8649 - accuracy: 0.6599\n",
            "Epoch 5: val_accuracy did not improve from 0.62222\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.8649 - accuracy: 0.6599 - val_loss: 0.9208 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8536 - accuracy: 0.6657\n",
            "Epoch 6: val_accuracy did not improve from 0.62222\n",
            "22/22 [==============================] - 11s 481ms/step - loss: 0.8536 - accuracy: 0.6657 - val_loss: 0.9219 - val_accuracy: 0.6000 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8591 - accuracy: 0.6483\n",
            "Epoch 7: val_accuracy did not improve from 0.62222\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.8591 - accuracy: 0.6483 - val_loss: 0.9202 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8568 - accuracy: 0.6599\n",
            "Epoch 8: val_accuracy did not improve from 0.62222\n",
            "22/22 [==============================] - 11s 486ms/step - loss: 0.8568 - accuracy: 0.6599 - val_loss: 0.9193 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8652 - accuracy: 0.6628\n",
            "Epoch 9: val_accuracy did not improve from 0.62222\n",
            "22/22 [==============================] - 11s 507ms/step - loss: 0.8652 - accuracy: 0.6628 - val_loss: 0.9189 - val_accuracy: 0.5889 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8679 - accuracy: 0.6744\n",
            "Epoch 10: val_accuracy did not improve from 0.62222\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.8679 - accuracy: 0.6744 - val_loss: 0.9176 - val_accuracy: 0.6222 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8694 - accuracy: 0.6424\n",
            "Epoch 11: val_accuracy did not improve from 0.62222\n",
            "22/22 [==============================] - 11s 498ms/step - loss: 0.8694 - accuracy: 0.6424 - val_loss: 0.9179 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8682 - accuracy: 0.6337\n",
            "Epoch 12: val_accuracy did not improve from 0.62222\n",
            "22/22 [==============================] - 11s 507ms/step - loss: 0.8682 - accuracy: 0.6337 - val_loss: 0.9162 - val_accuracy: 0.6222 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8749 - accuracy: 0.6395\n",
            "Epoch 13: val_accuracy did not improve from 0.62222\n",
            "22/22 [==============================] - 11s 513ms/step - loss: 0.8749 - accuracy: 0.6395 - val_loss: 0.9163 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8938 - accuracy: 0.6105\n",
            "Epoch 14: val_accuracy did not improve from 0.62222\n",
            "22/22 [==============================] - 11s 508ms/step - loss: 0.8938 - accuracy: 0.6105 - val_loss: 0.9157 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8574 - accuracy: 0.6453\n",
            "Epoch 15: val_accuracy did not improve from 0.62222\n",
            "22/22 [==============================] - 11s 503ms/step - loss: 0.8574 - accuracy: 0.6453 - val_loss: 0.9165 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8720 - accuracy: 0.6570\n",
            "Epoch 16: val_accuracy did not improve from 0.62222\n",
            "22/22 [==============================] - 11s 514ms/step - loss: 0.8720 - accuracy: 0.6570 - val_loss: 0.9158 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8670 - accuracy: 0.6512\n",
            "Epoch 17: val_accuracy did not improve from 0.62222\n",
            "22/22 [==============================] - 11s 501ms/step - loss: 0.8670 - accuracy: 0.6512 - val_loss: 0.9159 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8705 - accuracy: 0.6512\n",
            "Epoch 18: val_accuracy did not improve from 0.62222\n",
            "22/22 [==============================] - 11s 507ms/step - loss: 0.8705 - accuracy: 0.6512 - val_loss: 0.9150 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.65      0.56      0.60        27\n",
            "      Normal       0.66      0.70      0.68        33\n",
            "Tuberculosis       0.53      0.57      0.55        30\n",
            "\n",
            "    accuracy                           0.61        90\n",
            "   macro avg       0.61      0.61      0.61        90\n",
            "weighted avg       0.61      0.61      0.61        90\n",
            "\n",
            "Fold #4\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8725 - accuracy: 0.6392\n",
            "Epoch 1: val_accuracy improved from -inf to 0.66667, saving model to  Kmodel16_soft_pre_cate_sgd4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd4.h5 /assets\n",
            "22/22 [==============================] - 51s 2s/step - loss: 0.8725 - accuracy: 0.6392 - val_loss: 0.8758 - val_accuracy: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8976 - accuracy: 0.5959\n",
            "Epoch 2: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 0.8976 - accuracy: 0.5959 - val_loss: 0.8771 - val_accuracy: 0.6444 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8566 - accuracy: 0.6831\n",
            "Epoch 3: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 0.8566 - accuracy: 0.6831 - val_loss: 0.8773 - val_accuracy: 0.6444 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8823 - accuracy: 0.6279\n",
            "Epoch 4: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 489ms/step - loss: 0.8823 - accuracy: 0.6279 - val_loss: 0.8772 - val_accuracy: 0.6556 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8679 - accuracy: 0.6628\n",
            "Epoch 5: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.8679 - accuracy: 0.6628 - val_loss: 0.8759 - val_accuracy: 0.6556 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8575 - accuracy: 0.6860\n",
            "Epoch 6: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 0.8575 - accuracy: 0.6860 - val_loss: 0.8753 - val_accuracy: 0.6556 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8504 - accuracy: 0.6648\n",
            "Epoch 7: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 495ms/step - loss: 0.8504 - accuracy: 0.6648 - val_loss: 0.8757 - val_accuracy: 0.6444 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8858 - accuracy: 0.6424\n",
            "Epoch 8: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 487ms/step - loss: 0.8858 - accuracy: 0.6424 - val_loss: 0.8756 - val_accuracy: 0.6444 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8571 - accuracy: 0.6860\n",
            "Epoch 9: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.8571 - accuracy: 0.6860 - val_loss: 0.8747 - val_accuracy: 0.6333 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8772 - accuracy: 0.6512\n",
            "Epoch 10: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 514ms/step - loss: 0.8772 - accuracy: 0.6512 - val_loss: 0.8755 - val_accuracy: 0.6444 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8638 - accuracy: 0.6570\n",
            "Epoch 11: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 502ms/step - loss: 0.8638 - accuracy: 0.6570 - val_loss: 0.8751 - val_accuracy: 0.6444 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8624 - accuracy: 0.6599\n",
            "Epoch 12: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 12s 540ms/step - loss: 0.8624 - accuracy: 0.6599 - val_loss: 0.8761 - val_accuracy: 0.6556 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8695 - accuracy: 0.6308\n",
            "Epoch 13: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 504ms/step - loss: 0.8695 - accuracy: 0.6308 - val_loss: 0.8756 - val_accuracy: 0.6556 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8666 - accuracy: 0.6657\n",
            "Epoch 14: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 12s 517ms/step - loss: 0.8666 - accuracy: 0.6657 - val_loss: 0.8758 - val_accuracy: 0.6556 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8628 - accuracy: 0.6512\n",
            "Epoch 15: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 511ms/step - loss: 0.8628 - accuracy: 0.6512 - val_loss: 0.8751 - val_accuracy: 0.6556 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8557 - accuracy: 0.6977\n",
            "Epoch 16: val_accuracy did not improve from 0.66667\n",
            "22/22 [==============================] - 11s 510ms/step - loss: 0.8557 - accuracy: 0.6977 - val_loss: 0.8731 - val_accuracy: 0.6444 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.70      0.53      0.60        30\n",
            "      Normal       0.69      0.94      0.79        31\n",
            "Tuberculosis       0.52      0.45      0.48        29\n",
            "\n",
            "    accuracy                           0.64        90\n",
            "   macro avg       0.64      0.64      0.63        90\n",
            "weighted avg       0.64      0.64      0.63        90\n",
            "\n",
            "Fold #5\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8753 - accuracy: 0.6221\n",
            "Epoch 1: val_accuracy improved from -inf to 0.57778, saving model to  Kmodel16_soft_pre_cate_sgd5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd5.h5 /assets\n",
            "22/22 [==============================] - 49s 2s/step - loss: 0.8753 - accuracy: 0.6221 - val_loss: 0.8789 - val_accuracy: 0.5778 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8689 - accuracy: 0.6657\n",
            "Epoch 2: val_accuracy did not improve from 0.57778\n",
            "22/22 [==============================] - 11s 496ms/step - loss: 0.8689 - accuracy: 0.6657 - val_loss: 0.8791 - val_accuracy: 0.5778 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8687 - accuracy: 0.6570\n",
            "Epoch 3: val_accuracy did not improve from 0.57778\n",
            "22/22 [==============================] - 12s 518ms/step - loss: 0.8687 - accuracy: 0.6570 - val_loss: 0.8783 - val_accuracy: 0.5778 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8576 - accuracy: 0.6802\n",
            "Epoch 4: val_accuracy improved from 0.57778 to 0.60000, saving model to  Kmodel16_soft_pre_cate_sgd5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd5.h5 /assets\n",
            "22/22 [==============================] - 50s 2s/step - loss: 0.8576 - accuracy: 0.6802 - val_loss: 0.8764 - val_accuracy: 0.6000 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8630 - accuracy: 0.6570\n",
            "Epoch 5: val_accuracy did not improve from 0.60000\n",
            "22/22 [==============================] - 12s 524ms/step - loss: 0.8630 - accuracy: 0.6570 - val_loss: 0.8771 - val_accuracy: 0.5889 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8761 - accuracy: 0.6686\n",
            "Epoch 6: val_accuracy did not improve from 0.60000\n",
            "22/22 [==============================] - 12s 520ms/step - loss: 0.8761 - accuracy: 0.6686 - val_loss: 0.8771 - val_accuracy: 0.5889 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8736 - accuracy: 0.6105\n",
            "Epoch 7: val_accuracy did not improve from 0.60000\n",
            "22/22 [==============================] - 12s 528ms/step - loss: 0.8736 - accuracy: 0.6105 - val_loss: 0.8766 - val_accuracy: 0.5889 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8664 - accuracy: 0.6705\n",
            "Epoch 8: val_accuracy did not improve from 0.60000\n",
            "22/22 [==============================] - 12s 536ms/step - loss: 0.8664 - accuracy: 0.6705 - val_loss: 0.8752 - val_accuracy: 0.5778 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8608 - accuracy: 0.6686\n",
            "Epoch 9: val_accuracy did not improve from 0.60000\n",
            "22/22 [==============================] - 12s 520ms/step - loss: 0.8608 - accuracy: 0.6686 - val_loss: 0.8745 - val_accuracy: 0.5889 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8753 - accuracy: 0.6512\n",
            "Epoch 10: val_accuracy did not improve from 0.60000\n",
            "22/22 [==============================] - 12s 518ms/step - loss: 0.8753 - accuracy: 0.6512 - val_loss: 0.8748 - val_accuracy: 0.5778 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8686 - accuracy: 0.6250\n",
            "Epoch 11: val_accuracy did not improve from 0.60000\n",
            "22/22 [==============================] - 12s 531ms/step - loss: 0.8686 - accuracy: 0.6250 - val_loss: 0.8746 - val_accuracy: 0.5889 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8678 - accuracy: 0.6570\n",
            "Epoch 12: val_accuracy did not improve from 0.60000\n",
            "22/22 [==============================] - 12s 521ms/step - loss: 0.8678 - accuracy: 0.6570 - val_loss: 0.8751 - val_accuracy: 0.6000 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8604 - accuracy: 0.6395\n",
            "Epoch 13: val_accuracy did not improve from 0.60000\n",
            "22/22 [==============================] - 12s 516ms/step - loss: 0.8604 - accuracy: 0.6395 - val_loss: 0.8734 - val_accuracy: 0.6000 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8553 - accuracy: 0.6395\n",
            "Epoch 14: val_accuracy improved from 0.60000 to 0.61111, saving model to  Kmodel16_soft_pre_cate_sgd5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_cate_sgd5.h5 /assets\n",
            "22/22 [==============================] - 51s 2s/step - loss: 0.8553 - accuracy: 0.6395 - val_loss: 0.8716 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8501 - accuracy: 0.6483\n",
            "Epoch 15: val_accuracy did not improve from 0.61111\n",
            "22/22 [==============================] - 12s 514ms/step - loss: 0.8501 - accuracy: 0.6483 - val_loss: 0.8716 - val_accuracy: 0.5889 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8478 - accuracy: 0.6744\n",
            "Epoch 16: val_accuracy did not improve from 0.61111\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.8478 - accuracy: 0.6744 - val_loss: 0.8716 - val_accuracy: 0.6000 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8713 - accuracy: 0.6541\n",
            "Epoch 17: val_accuracy did not improve from 0.61111\n",
            "22/22 [==============================] - 11s 506ms/step - loss: 0.8713 - accuracy: 0.6541 - val_loss: 0.8714 - val_accuracy: 0.6000 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8564 - accuracy: 0.6366\n",
            "Epoch 18: val_accuracy did not improve from 0.61111\n",
            "22/22 [==============================] - 11s 508ms/step - loss: 0.8564 - accuracy: 0.6366 - val_loss: 0.8696 - val_accuracy: 0.6000 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8560 - accuracy: 0.6628\n",
            "Epoch 19: val_accuracy did not improve from 0.61111\n",
            "22/22 [==============================] - 12s 528ms/step - loss: 0.8560 - accuracy: 0.6628 - val_loss: 0.8682 - val_accuracy: 0.6000 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8525 - accuracy: 0.6628\n",
            "Epoch 20: val_accuracy did not improve from 0.61111\n",
            "22/22 [==============================] - 12s 527ms/step - loss: 0.8525 - accuracy: 0.6628 - val_loss: 0.8687 - val_accuracy: 0.5889 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8680 - accuracy: 0.6395\n",
            "Epoch 21: val_accuracy did not improve from 0.61111\n",
            "22/22 [==============================] - 12s 525ms/step - loss: 0.8680 - accuracy: 0.6395 - val_loss: 0.8695 - val_accuracy: 0.5889 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8574 - accuracy: 0.6657\n",
            "Epoch 22: val_accuracy did not improve from 0.61111\n",
            "22/22 [==============================] - 12s 519ms/step - loss: 0.8574 - accuracy: 0.6657 - val_loss: 0.8700 - val_accuracy: 0.5889 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8458 - accuracy: 0.6570\n",
            "Epoch 23: val_accuracy did not improve from 0.61111\n",
            "22/22 [==============================] - 12s 522ms/step - loss: 0.8458 - accuracy: 0.6570 - val_loss: 0.8696 - val_accuracy: 0.5889 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8614 - accuracy: 0.6453\n",
            "Epoch 24: val_accuracy did not improve from 0.61111\n",
            "22/22 [==============================] - 12s 524ms/step - loss: 0.8614 - accuracy: 0.6453 - val_loss: 0.8690 - val_accuracy: 0.6000 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8581 - accuracy: 0.6250\n",
            "Epoch 25: val_accuracy did not improve from 0.61111\n",
            "22/22 [==============================] - 12s 519ms/step - loss: 0.8581 - accuracy: 0.6250 - val_loss: 0.8691 - val_accuracy: 0.6000 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8484 - accuracy: 0.6802\n",
            "Epoch 26: val_accuracy did not improve from 0.61111\n",
            "22/22 [==============================] - 12s 524ms/step - loss: 0.8484 - accuracy: 0.6802 - val_loss: 0.8686 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
            "Epoch 27/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8739 - accuracy: 0.6483\n",
            "Epoch 27: val_accuracy did not improve from 0.61111\n",
            "22/22 [==============================] - 12s 526ms/step - loss: 0.8739 - accuracy: 0.6483 - val_loss: 0.8681 - val_accuracy: 0.6000 - lr: 1.0000e-05\n",
            "Epoch 28/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8810 - accuracy: 0.6453\n",
            "Epoch 28: val_accuracy did not improve from 0.61111\n",
            "22/22 [==============================] - 11s 508ms/step - loss: 0.8810 - accuracy: 0.6453 - val_loss: 0.8666 - val_accuracy: 0.5889 - lr: 1.0000e-05\n",
            "Epoch 29/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.8446 - accuracy: 0.6802\n",
            "Epoch 29: val_accuracy did not improve from 0.61111\n",
            "22/22 [==============================] - 12s 517ms/step - loss: 0.8446 - accuracy: 0.6802 - val_loss: 0.8665 - val_accuracy: 0.5889 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.54      0.48      0.51        31\n",
            "      Normal       0.71      0.89      0.79        28\n",
            "Tuberculosis       0.48      0.42      0.45        31\n",
            "\n",
            "    accuracy                           0.59        90\n",
            "   macro avg       0.58      0.60      0.58        90\n",
            "weighted avg       0.57      0.59      0.58        90\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.62      0.53      0.57       150\n",
            "      Normal       0.70      0.85      0.77       150\n",
            "Tuberculosis       0.51      0.47      0.49       150\n",
            "\n",
            "    accuracy                           0.62       450\n",
            "   macro avg       0.61      0.62      0.61       450\n",
            "weighted avg       0.61      0.62      0.61       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 32"
      ],
      "metadata": {
        "id": "TDetFQwMSKk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 32  soft pre bi\n"
      ],
      "metadata": {
        "id": "tUqsoIt5SKk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 32\n",
        "filepath = \"Kmodel32_soft_pre_bi.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "id": "dGYBzI9tSKk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel32_soft_pre_bi{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "shIE2WLlSKk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 32 soft pre bi adam  \n"
      ],
      "metadata": {
        "id": "17rbmbkJSKk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 32\n",
        "filepath = \"Kmodel32_soft_pre_bi_adam.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b03506-eddb-4c17-f5fe-976c247895dd",
        "id": "0Rc1AYwDSKk6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:06<00:00, 66.43it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel32_soft_pre_bi_adam{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "Z1tVkD0KSKk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 32 soft pre bi sgd  \n"
      ],
      "metadata": {
        "id": "52QbOgEXSKk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 32\n",
        "filepath = \"Kmodel32_soft_pre_bi_sgd.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b03506-eddb-4c17-f5fe-976c247895dd",
        "id": "p3cQUFuaSKk7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:06<00:00, 66.43it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel32_soft_pre_bi_sgd{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "IQLrE14OSKk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 32 soft pre cate \n"
      ],
      "metadata": {
        "id": "YmWai2hhSKk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 32\n",
        "filepath = \"Kmodel32_soft_pre_cate.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "8f62ba84-295e-4d23-a2f7-57bc97196ed3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9iMBwwkSKk9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:10<00:00, 41.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel32_soft_pre_cate{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "OU3Vt4nBSKk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 32 soft pre cate adam\n"
      ],
      "metadata": {
        "id": "Zrg0ZciqSKk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 32\n",
        "filepath = \"Kmodel32_soft_pre_cate_adam.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "4ade8ad3-0a08-4391-b9cc-b535897670e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6IwQDaZSKk-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:04<00:00, 92.81it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel32_soft_pre_cate_adam{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "SNUh7FzdSKk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 32 soft pre cate sgd\n"
      ],
      "metadata": {
        "id": "PInBxnIXSKk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 32\n",
        "filepath = \"Kmodel32_soft_pre_cate_sgd.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "4ade8ad3-0a08-4391-b9cc-b535897670e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zakBZsBzSKk_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:04<00:00, 92.81it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel32_soft_pre_cate_sgd{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "H9ZZNa8dSKk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 \n"
      ],
      "metadata": {
        "id": "GEk-rt9_StVQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1  soft pre bi\n"
      ],
      "metadata": {
        "id": "QDaLgRIyStVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 1\n",
        "filepath = \"Kmodel1_soft_pre_bi.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "id": "GGUJhDI9StVR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8dae654-0556-4873-90ed-b0216ab08156"
      },
      "execution_count": 15,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 450/450 [01:49<00:00,  4.11it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel1_soft_pre_bi{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "6Vd84ZFgStVS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47f4c29c-9ad6-41b8-c711-6a3cdad7316e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 3s 0us/step\n",
            "87924736/87910968 [==============================] - 3s 0us/step\n",
            "Fold #1\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6104 - accuracy: 0.4528\n",
            "Epoch 1: val_accuracy improved from -inf to 0.30000, saving model to  Kmodel1_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi1.h5 /assets\n",
            "360/360 [==============================] - 122s 214ms/step - loss: 0.6104 - accuracy: 0.4528 - val_loss: 0.7491 - val_accuracy: 0.3000 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.4744 - accuracy: 0.5972\n",
            "Epoch 2: val_accuracy improved from 0.30000 to 0.38889, saving model to  Kmodel1_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi1.h5 /assets\n",
            "360/360 [==============================] - 68s 189ms/step - loss: 0.4744 - accuracy: 0.5972 - val_loss: 0.8039 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.4354 - accuracy: 0.6556\n",
            "Epoch 3: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 32s 90ms/step - loss: 0.4354 - accuracy: 0.6556 - val_loss: 0.7825 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.7111\n",
            "Epoch 4: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.3863 - accuracy: 0.7111 - val_loss: 1.3070 - val_accuracy: 0.3444 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.3588 - accuracy: 0.7417\n",
            "Epoch 5: val_accuracy improved from 0.38889 to 0.48889, saving model to  Kmodel1_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi1.h5 /assets\n",
            "360/360 [==============================] - 67s 187ms/step - loss: 0.3588 - accuracy: 0.7417 - val_loss: 0.6785 - val_accuracy: 0.4889 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.3210 - accuracy: 0.8139\n",
            "Epoch 6: val_accuracy did not improve from 0.48889\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 0.3210 - accuracy: 0.8139 - val_loss: 1.7783 - val_accuracy: 0.4222 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.2973 - accuracy: 0.8194\n",
            "Epoch 7: val_accuracy improved from 0.48889 to 0.52222, saving model to  Kmodel1_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi1.h5 /assets\n",
            "360/360 [==============================] - 67s 187ms/step - loss: 0.2973 - accuracy: 0.8194 - val_loss: 0.6978 - val_accuracy: 0.5222 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.2834 - accuracy: 0.8333\n",
            "Epoch 8: val_accuracy improved from 0.52222 to 0.62222, saving model to  Kmodel1_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi1.h5 /assets\n",
            "360/360 [==============================] - 68s 188ms/step - loss: 0.2834 - accuracy: 0.8333 - val_loss: 0.4558 - val_accuracy: 0.6222 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.2067 - accuracy: 0.8861\n",
            "Epoch 9: val_accuracy improved from 0.62222 to 0.65556, saving model to  Kmodel1_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi1.h5 /assets\n",
            "360/360 [==============================] - 67s 186ms/step - loss: 0.2067 - accuracy: 0.8861 - val_loss: 0.4873 - val_accuracy: 0.6556 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.2263 - accuracy: 0.8778\n",
            "Epoch 10: val_accuracy did not improve from 0.65556\n",
            "360/360 [==============================] - 32s 90ms/step - loss: 0.2263 - accuracy: 0.8778 - val_loss: 2.2142 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.1849 - accuracy: 0.9111\n",
            "Epoch 11: val_accuracy improved from 0.65556 to 0.71111, saving model to  Kmodel1_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi1.h5 /assets\n",
            "360/360 [==============================] - 69s 191ms/step - loss: 0.1849 - accuracy: 0.9111 - val_loss: 0.5318 - val_accuracy: 0.7111 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.1769 - accuracy: 0.9111\n",
            "Epoch 12: val_accuracy did not improve from 0.71111\n",
            "360/360 [==============================] - 33s 90ms/step - loss: 0.1769 - accuracy: 0.9111 - val_loss: 3.7378 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.1269 - accuracy: 0.9278\n",
            "Epoch 13: val_accuracy did not improve from 0.71111\n",
            "360/360 [==============================] - 32s 90ms/step - loss: 0.1269 - accuracy: 0.9278 - val_loss: 2.7232 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.1377 - accuracy: 0.9389\n",
            "Epoch 14: val_accuracy did not improve from 0.71111\n",
            "360/360 [==============================] - 32s 90ms/step - loss: 0.1377 - accuracy: 0.9389 - val_loss: 1.9220 - val_accuracy: 0.4889 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.1205 - accuracy: 0.9500\n",
            "Epoch 15: val_accuracy did not improve from 0.71111\n",
            "360/360 [==============================] - 33s 90ms/step - loss: 0.1205 - accuracy: 0.9500 - val_loss: 1.7591 - val_accuracy: 0.4778 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.1319 - accuracy: 0.9417\n",
            "Epoch 16: val_accuracy did not improve from 0.71111\n",
            "360/360 [==============================] - 33s 90ms/step - loss: 0.1319 - accuracy: 0.9417 - val_loss: 1.0898 - val_accuracy: 0.5333 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0993 - accuracy: 0.9667\n",
            "Epoch 17: val_accuracy did not improve from 0.71111\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0993 - accuracy: 0.9667 - val_loss: 4.3407 - val_accuracy: 0.4778 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0653 - accuracy: 0.9667\n",
            "Epoch 18: val_accuracy did not improve from 0.71111\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0653 - accuracy: 0.9667 - val_loss: 1.1952 - val_accuracy: 0.5000 - lr: 5.0000e-05\n",
            "Epoch 19/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9917\n",
            "Epoch 19: val_accuracy did not improve from 0.71111\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 1.4661 - val_accuracy: 0.4444 - lr: 5.0000e-05\n",
            "Epoch 20/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9917\n",
            "Epoch 20: val_accuracy did not improve from 0.71111\n",
            "360/360 [==============================] - 33s 90ms/step - loss: 0.0268 - accuracy: 0.9917 - val_loss: 1.1305 - val_accuracy: 0.5111 - lr: 5.0000e-05\n",
            "Epoch 21/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9889\n",
            "Epoch 21: val_accuracy did not improve from 0.71111\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0284 - accuracy: 0.9889 - val_loss: 1.1326 - val_accuracy: 0.5000 - lr: 5.0000e-05\n",
            "Epoch 22/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9917\n",
            "Epoch 22: val_accuracy did not improve from 0.71111\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0322 - accuracy: 0.9917 - val_loss: 2.2040 - val_accuracy: 0.4889 - lr: 5.0000e-05\n",
            "Epoch 23/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9833\n",
            "Epoch 23: val_accuracy did not improve from 0.71111\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "360/360 [==============================] - 33s 90ms/step - loss: 0.0631 - accuracy: 0.9833 - val_loss: 2.4797 - val_accuracy: 0.4444 - lr: 5.0000e-05\n",
            "Epoch 24/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.9889\n",
            "Epoch 24: val_accuracy did not improve from 0.71111\n",
            "360/360 [==============================] - 32s 90ms/step - loss: 0.0385 - accuracy: 0.9889 - val_loss: 2.2686 - val_accuracy: 0.4222 - lr: 2.5000e-05\n",
            "Epoch 25/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9972\n",
            "Epoch 25: val_accuracy did not improve from 0.71111\n",
            "360/360 [==============================] - 33s 90ms/step - loss: 0.0123 - accuracy: 0.9972 - val_loss: 2.0418 - val_accuracy: 0.4556 - lr: 2.5000e-05\n",
            "Epoch 26/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9944\n",
            "Epoch 26: val_accuracy did not improve from 0.71111\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0284 - accuracy: 0.9944 - val_loss: 1.3860 - val_accuracy: 0.5111 - lr: 2.5000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.68      0.46      0.55        28\n",
            "      Normal       0.79      0.35      0.49        31\n",
            "Tuberculosis       0.39      0.71      0.50        31\n",
            "\n",
            "    accuracy                           0.51        90\n",
            "   macro avg       0.62      0.51      0.51        90\n",
            "weighted avg       0.62      0.51      0.51        90\n",
            "\n",
            "Fold #2\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.2869 - accuracy: 0.9333\n",
            "Epoch 1: val_accuracy improved from -inf to 0.77778, saving model to  Kmodel1_soft_pre_bi2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi2.h5 /assets\n",
            "360/360 [==============================] - 67s 186ms/step - loss: 0.2869 - accuracy: 0.9333 - val_loss: 0.4258 - val_accuracy: 0.7778 - lr: 2.5000e-05\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.1861 - accuracy: 0.9528\n",
            "Epoch 2: val_accuracy improved from 0.77778 to 0.80000, saving model to  Kmodel1_soft_pre_bi2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi2.h5 /assets\n",
            "360/360 [==============================] - 67s 186ms/step - loss: 0.1861 - accuracy: 0.9528 - val_loss: 0.3389 - val_accuracy: 0.8000 - lr: 2.5000e-05\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.1101 - accuracy: 0.9667\n",
            "Epoch 3: val_accuracy improved from 0.80000 to 0.81111, saving model to  Kmodel1_soft_pre_bi2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi2.h5 /assets\n",
            "360/360 [==============================] - 68s 188ms/step - loss: 0.1101 - accuracy: 0.9667 - val_loss: 0.4340 - val_accuracy: 0.8111 - lr: 2.5000e-05\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.1210 - accuracy: 0.9667\n",
            "Epoch 4: val_accuracy improved from 0.81111 to 0.84444, saving model to  Kmodel1_soft_pre_bi2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi2.h5 /assets\n",
            "360/360 [==============================] - 68s 188ms/step - loss: 0.1210 - accuracy: 0.9667 - val_loss: 0.3915 - val_accuracy: 0.8444 - lr: 2.5000e-05\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.1000 - accuracy: 0.9750\n",
            "Epoch 5: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.1000 - accuracy: 0.9750 - val_loss: 0.4747 - val_accuracy: 0.8111 - lr: 2.5000e-05\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0716 - accuracy: 0.9694\n",
            "Epoch 6: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0716 - accuracy: 0.9694 - val_loss: 0.4174 - val_accuracy: 0.8000 - lr: 2.5000e-05\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.9861\n",
            "Epoch 7: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 33s 90ms/step - loss: 0.0536 - accuracy: 0.9861 - val_loss: 0.4350 - val_accuracy: 0.8444 - lr: 2.5000e-05\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0620 - accuracy: 0.9861\n",
            "Epoch 8: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 32s 90ms/step - loss: 0.0620 - accuracy: 0.9861 - val_loss: 0.6366 - val_accuracy: 0.7444 - lr: 2.5000e-05\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9861\n",
            "Epoch 9: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 33s 90ms/step - loss: 0.0369 - accuracy: 0.9861 - val_loss: 0.6720 - val_accuracy: 0.7444 - lr: 2.5000e-05\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.9833\n",
            "Epoch 10: val_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0597 - accuracy: 0.9833 - val_loss: 0.7623 - val_accuracy: 0.7444 - lr: 2.5000e-05\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 0.9917\n",
            "Epoch 11: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 32s 90ms/step - loss: 0.0242 - accuracy: 0.9917 - val_loss: 0.6754 - val_accuracy: 0.7667 - lr: 1.2500e-05\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.9944\n",
            "Epoch 12: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 33s 90ms/step - loss: 0.0231 - accuracy: 0.9944 - val_loss: 0.6033 - val_accuracy: 0.7778 - lr: 1.2500e-05\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9917\n",
            "Epoch 13: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 33s 90ms/step - loss: 0.0290 - accuracy: 0.9917 - val_loss: 0.6913 - val_accuracy: 0.7556 - lr: 1.2500e-05\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0261 - accuracy: 0.9917\n",
            "Epoch 14: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 32s 90ms/step - loss: 0.0261 - accuracy: 0.9917 - val_loss: 0.7434 - val_accuracy: 0.7667 - lr: 1.2500e-05\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9972\n",
            "Epoch 15: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0163 - accuracy: 0.9972 - val_loss: 0.7392 - val_accuracy: 0.7444 - lr: 1.2500e-05\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9972\n",
            "Epoch 16: val_accuracy did not improve from 0.84444\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 0.0061 - accuracy: 0.9972 - val_loss: 0.8146 - val_accuracy: 0.7444 - lr: 1.2500e-05\n",
            "Epoch 17/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9944\n",
            "Epoch 17: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0268 - accuracy: 0.9944 - val_loss: 0.6632 - val_accuracy: 0.7667 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9972\n",
            "Epoch 18: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 32s 90ms/step - loss: 0.0134 - accuracy: 0.9972 - val_loss: 0.7827 - val_accuracy: 0.7444 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9944\n",
            "Epoch 19: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0035 - accuracy: 0.9944 - val_loss: 0.9493 - val_accuracy: 0.7222 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.62      0.76        34\n",
            "      Normal       0.89      0.63      0.74        27\n",
            "Tuberculosis       0.54      0.93      0.68        29\n",
            "\n",
            "    accuracy                           0.72        90\n",
            "   macro avg       0.81      0.73      0.73        90\n",
            "weighted avg       0.82      0.72      0.73        90\n",
            "\n",
            "Fold #3\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9917\n",
            "Epoch 1: val_accuracy improved from -inf to 0.81111, saving model to  Kmodel1_soft_pre_bi3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi3.h5 /assets\n",
            "360/360 [==============================] - 67s 187ms/step - loss: 0.0409 - accuracy: 0.9917 - val_loss: 0.5426 - val_accuracy: 0.8111 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.1204e-05 - accuracy: 1.0000\n",
            "Epoch 2: val_accuracy did not improve from 0.81111\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 1.1204e-05 - accuracy: 1.0000 - val_loss: 0.4743 - val_accuracy: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9972\n",
            "Epoch 3: val_accuracy did not improve from 0.81111\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 0.0068 - accuracy: 0.9972 - val_loss: 0.4268 - val_accuracy: 0.7667 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9972\n",
            "Epoch 4: val_accuracy did not improve from 0.81111\n",
            "360/360 [==============================] - 33s 90ms/step - loss: 0.0101 - accuracy: 0.9972 - val_loss: 0.5468 - val_accuracy: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9917\n",
            "Epoch 5: val_accuracy did not improve from 0.81111\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0482 - accuracy: 0.9917 - val_loss: 0.3779 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy did not improve from 0.81111\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5936 - val_accuracy: 0.7556 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9972\n",
            "Epoch 7: val_accuracy did not improve from 0.81111\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0165 - accuracy: 0.9972 - val_loss: 0.5273 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9944\n",
            "Epoch 8: val_accuracy did not improve from 0.81111\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0251 - accuracy: 0.9944 - val_loss: 0.4978 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9972\n",
            "Epoch 9: val_accuracy did not improve from 0.81111\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0026 - accuracy: 0.9972 - val_loss: 0.4420 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9944\n",
            "Epoch 10: val_accuracy did not improve from 0.81111\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0268 - accuracy: 0.9944 - val_loss: 0.5916 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 0.81111\n",
            "360/360 [==============================] - 33s 90ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5669 - val_accuracy: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 8.5725e-04 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.81111\n",
            "360/360 [==============================] - 33s 90ms/step - loss: 8.5725e-04 - accuracy: 1.0000 - val_loss: 0.5735 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 4.0042e-06 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.81111\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 4.0042e-06 - accuracy: 1.0000 - val_loss: 0.6644 - val_accuracy: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 2.1306e-06 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 0.81111\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 2.1306e-06 - accuracy: 1.0000 - val_loss: 0.6387 - val_accuracy: 0.7444 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 4.2720e-05 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.81111\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 4.2720e-05 - accuracy: 1.0000 - val_loss: 0.5662 - val_accuracy: 0.7778 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 5.6939e-06 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.81111\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 5.6939e-06 - accuracy: 1.0000 - val_loss: 0.8577 - val_accuracy: 0.7444 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.96      0.81      0.88        27\n",
            "      Normal       0.94      0.48      0.64        33\n",
            "Tuberculosis       0.58      0.97      0.72        30\n",
            "\n",
            "    accuracy                           0.74        90\n",
            "   macro avg       0.83      0.76      0.75        90\n",
            "weighted avg       0.83      0.74      0.74        90\n",
            "\n",
            "Fold #4\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 3.2500e-05 - accuracy: 1.0000\n",
            "Epoch 1: val_accuracy improved from -inf to 0.70000, saving model to  Kmodel1_soft_pre_bi4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi4.h5 /assets\n",
            "360/360 [==============================] - 67s 186ms/step - loss: 3.2500e-05 - accuracy: 1.0000 - val_loss: 0.7958 - val_accuracy: 0.7000 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9972\n",
            "Epoch 2: val_accuracy did not improve from 0.70000\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0238 - accuracy: 0.9972 - val_loss: 0.7987 - val_accuracy: 0.7000 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 2.9791e-04 - accuracy: 1.0000\n",
            "Epoch 3: val_accuracy improved from 0.70000 to 0.71111, saving model to  Kmodel1_soft_pre_bi4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi4.h5 /assets\n",
            "360/360 [==============================] - 67s 186ms/step - loss: 2.9791e-04 - accuracy: 1.0000 - val_loss: 0.6914 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9972\n",
            "Epoch 4: val_accuracy did not improve from 0.71111\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 0.0044 - accuracy: 0.9972 - val_loss: 0.7407 - val_accuracy: 0.7000 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 6.6739e-04 - accuracy: 1.0000\n",
            "Epoch 5: val_accuracy did not improve from 0.71111\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 6.6739e-04 - accuracy: 1.0000 - val_loss: 0.6861 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 7.7277e-05 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy improved from 0.71111 to 0.75556, saving model to  Kmodel1_soft_pre_bi4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi4.h5 /assets\n",
            "360/360 [==============================] - 67s 186ms/step - loss: 7.7277e-05 - accuracy: 1.0000 - val_loss: 0.6300 - val_accuracy: 0.7556 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 2.3128e-04 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy improved from 0.75556 to 0.76667, saving model to  Kmodel1_soft_pre_bi4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi4.h5 /assets\n",
            "360/360 [==============================] - 67s 185ms/step - loss: 2.3128e-04 - accuracy: 1.0000 - val_loss: 0.5175 - val_accuracy: 0.7667 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 9.1423e-07 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 9.1423e-07 - accuracy: 1.0000 - val_loss: 0.4832 - val_accuracy: 0.7667 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9972\n",
            "Epoch 9: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.6499 - val_accuracy: 0.7000 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 7.7855e-07 - accuracy: 1.0000\n",
            "Epoch 10: val_accuracy improved from 0.76667 to 0.80000, saving model to  Kmodel1_soft_pre_bi4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi4.h5 /assets\n",
            "360/360 [==============================] - 69s 192ms/step - loss: 7.7855e-07 - accuracy: 1.0000 - val_loss: 0.4336 - val_accuracy: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9972\n",
            "Epoch 11: val_accuracy did not improve from 0.80000\n",
            "360/360 [==============================] - 33s 93ms/step - loss: 0.0223 - accuracy: 0.9972 - val_loss: 0.6327 - val_accuracy: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 4.5295e-07 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.80000\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 4.5295e-07 - accuracy: 1.0000 - val_loss: 0.5179 - val_accuracy: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9972\n",
            "Epoch 13: val_accuracy did not improve from 0.80000\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0165 - accuracy: 0.9972 - val_loss: 0.6892 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 3.4584e-07 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 0.80000\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 3.4584e-07 - accuracy: 1.0000 - val_loss: 0.7607 - val_accuracy: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9972\n",
            "Epoch 15: val_accuracy did not improve from 0.80000\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0169 - accuracy: 0.9972 - val_loss: 0.4962 - val_accuracy: 0.7444 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 2.7933e-07 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.80000\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 2.7933e-07 - accuracy: 1.0000 - val_loss: 0.5765 - val_accuracy: 0.7444 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.2158e-04 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 0.80000\n",
            "360/360 [==============================] - 33s 93ms/step - loss: 1.2158e-04 - accuracy: 1.0000 - val_loss: 0.6854 - val_accuracy: 0.6889 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9972\n",
            "Epoch 18: val_accuracy did not improve from 0.80000\n",
            "360/360 [==============================] - 33s 93ms/step - loss: 0.0183 - accuracy: 0.9972 - val_loss: 0.7110 - val_accuracy: 0.6889 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.8534e-06 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 0.80000\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 1.8534e-06 - accuracy: 1.0000 - val_loss: 0.7869 - val_accuracy: 0.6889 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 2.3856e-07 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.80000\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 2.3856e-07 - accuracy: 1.0000 - val_loss: 0.6333 - val_accuracy: 0.7000 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9972\n",
            "Epoch 21: val_accuracy did not improve from 0.80000\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0193 - accuracy: 0.9972 - val_loss: 0.6716 - val_accuracy: 0.7222 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 2.2494e-07 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 0.80000\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 2.2494e-07 - accuracy: 1.0000 - val_loss: 0.5654 - val_accuracy: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 2.2330e-07 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.80000\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 2.2330e-07 - accuracy: 1.0000 - val_loss: 0.5516 - val_accuracy: 0.7444 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 2.0526e-07 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.80000\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 2.0526e-07 - accuracy: 1.0000 - val_loss: 0.7557 - val_accuracy: 0.6778 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.9190e-07 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 0.80000\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 1.9190e-07 - accuracy: 1.0000 - val_loss: 0.6314 - val_accuracy: 0.7000 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.87      0.93        30\n",
            "      Normal       0.79      0.35      0.49        31\n",
            "Tuberculosis       0.52      0.90      0.66        29\n",
            "\n",
            "    accuracy                           0.70        90\n",
            "   macro avg       0.77      0.71      0.69        90\n",
            "weighted avg       0.77      0.70      0.69        90\n",
            "\n",
            "Fold #5\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.6796e-07 - accuracy: 1.0000\n",
            "Epoch 1: val_accuracy improved from -inf to 0.80000, saving model to  Kmodel1_soft_pre_bi5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi5.h5 /assets\n",
            "360/360 [==============================] - 67s 186ms/step - loss: 1.6796e-07 - accuracy: 1.0000 - val_loss: 0.5721 - val_accuracy: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.6020e-07 - accuracy: 1.0000\n",
            "Epoch 2: val_accuracy improved from 0.80000 to 0.83333, saving model to  Kmodel1_soft_pre_bi5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi5.h5 /assets\n",
            "360/360 [==============================] - 67s 187ms/step - loss: 1.6020e-07 - accuracy: 1.0000 - val_loss: 0.5644 - val_accuracy: 0.8333 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 6.7913e-05 - accuracy: 1.0000\n",
            "Epoch 3: val_accuracy did not improve from 0.83333\n",
            "360/360 [==============================] - 33s 93ms/step - loss: 6.7913e-05 - accuracy: 1.0000 - val_loss: 0.6281 - val_accuracy: 0.8222 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.4972e-07 - accuracy: 1.0000\n",
            "Epoch 4: val_accuracy did not improve from 0.83333\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 1.4972e-07 - accuracy: 1.0000 - val_loss: 0.5582 - val_accuracy: 0.8333 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.6054e-07 - accuracy: 1.0000\n",
            "Epoch 5: val_accuracy improved from 0.83333 to 0.84444, saving model to  Kmodel1_soft_pre_bi5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi5.h5 /assets\n",
            "360/360 [==============================] - 67s 186ms/step - loss: 1.6054e-07 - accuracy: 1.0000 - val_loss: 0.5154 - val_accuracy: 0.8444 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.4787e-07 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 1.4787e-07 - accuracy: 1.0000 - val_loss: 0.5679 - val_accuracy: 0.8111 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.2661e-07 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 1.2661e-07 - accuracy: 1.0000 - val_loss: 0.5645 - val_accuracy: 0.8333 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 2.6227e-05 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 33s 90ms/step - loss: 2.6227e-05 - accuracy: 1.0000 - val_loss: 0.5429 - val_accuracy: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.3129e-07 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 1.3129e-07 - accuracy: 1.0000 - val_loss: 0.6327 - val_accuracy: 0.8111 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9972\n",
            "Epoch 10: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 0.0248 - accuracy: 0.9972 - val_loss: 0.7424 - val_accuracy: 0.7556 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0541e-07 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 1.0541e-07 - accuracy: 1.0000 - val_loss: 0.6548 - val_accuracy: 0.7667 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9944\n",
            "Epoch 12: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0118 - accuracy: 0.9944 - val_loss: 0.5941 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.1234e-07 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 1.1234e-07 - accuracy: 1.0000 - val_loss: 0.6215 - val_accuracy: 0.7778 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 9.2938e-04 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 9.2938e-04 - accuracy: 1.0000 - val_loss: 0.4975 - val_accuracy: 0.8333 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 2.2986e-07 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 2.2986e-07 - accuracy: 1.0000 - val_loss: 0.6125 - val_accuracy: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 3.6188e-07 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 3.6188e-07 - accuracy: 1.0000 - val_loss: 0.5576 - val_accuracy: 0.8444 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0279e-07 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 1.0279e-07 - accuracy: 1.0000 - val_loss: 0.5833 - val_accuracy: 0.8111 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 9.7846e-08 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 9.7846e-08 - accuracy: 1.0000 - val_loss: 0.6985 - val_accuracy: 0.7667 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 9.3490e-08 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 9.3490e-08 - accuracy: 1.0000 - val_loss: 0.6542 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 9.6087e-08 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 9.6087e-08 - accuracy: 1.0000 - val_loss: 0.5973 - val_accuracy: 0.8000 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.95      0.68      0.79        31\n",
            "      Normal       1.00      0.75      0.86        28\n",
            "Tuberculosis       0.64      0.97      0.77        31\n",
            "\n",
            "    accuracy                           0.80        90\n",
            "   macro avg       0.86      0.80      0.81        90\n",
            "weighted avg       0.86      0.80      0.80        90\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.93      0.69      0.79       150\n",
            "      Normal       0.89      0.51      0.65       150\n",
            "Tuberculosis       0.53      0.89      0.66       150\n",
            "\n",
            "    accuracy                           0.70       450\n",
            "   macro avg       0.78      0.70      0.70       450\n",
            "weighted avg       0.78      0.70      0.70       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1 soft pre bi adam  \n"
      ],
      "metadata": {
        "id": "OlSZVkmtStVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 1\n",
        "filepath = \"Kmodel1_soft_pre_bi_adam.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8716e8ca-881d-47a3-8cb2-c12fcecc656b",
        "id": "g1Xl88J7StVT"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [01:45<00:00,  4.26it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel1_soft_pre_bi_adam{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "eRLREz42StVT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc99505c-0912-4b0d-c3b6-ba001cb1c9da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "87924736/87910968 [==============================] - 1s 0us/step\n",
            "Fold #1\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6112 - accuracy: 0.4361\n",
            "Epoch 1: val_accuracy improved from -inf to 0.56667, saving model to  Kmodel1_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi_adam1.h5 /assets\n",
            "360/360 [==============================] - 292s 791ms/step - loss: 0.6112 - accuracy: 0.4361 - val_loss: 0.4687 - val_accuracy: 0.5667 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.5024 - accuracy: 0.5833\n",
            "Epoch 2: val_accuracy improved from 0.56667 to 0.63333, saving model to  Kmodel1_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi_adam1.h5 /assets\n",
            "360/360 [==============================] - 303s 842ms/step - loss: 0.5024 - accuracy: 0.5833 - val_loss: 0.5502 - val_accuracy: 0.6333 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.4547 - accuracy: 0.5944\n",
            "Epoch 3: val_accuracy did not improve from 0.63333\n",
            "360/360 [==============================] - 309s 857ms/step - loss: 0.4547 - accuracy: 0.5944 - val_loss: 0.4641 - val_accuracy: 0.5889 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.4132 - accuracy: 0.6500\n",
            "Epoch 4: val_accuracy did not improve from 0.63333\n",
            "360/360 [==============================] - 304s 843ms/step - loss: 0.4132 - accuracy: 0.6500 - val_loss: 1.3510 - val_accuracy: 0.4667 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "108/360 [========>.....................] - ETA: 3:19 - loss: 0.3690 - accuracy: 0.6944"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1 soft pre bi sgd  \n"
      ],
      "metadata": {
        "id": "VUeDos-7StVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 1\n",
        "filepath = \"Kmodel1_soft_pre_bi_sgd.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" )\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "id": "RL_Q1Si5StVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel1_soft_pre_bi_sgd{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "4mZ0oZ-MStVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1 soft pre cate \n"
      ],
      "metadata": {
        "id": "fc3oQRkOStVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 1\n",
        "filepath = \"Kmodel1_soft_pre_cate.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "8f62ba84-295e-4d23-a2f7-57bc97196ed3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoTbrNJKStVU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:10<00:00, 41.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel1_soft_pre_cate{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "7_-gdbBGStVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1 soft pre cate adam\n"
      ],
      "metadata": {
        "id": "6ptGRCe5StVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 1\n",
        "filepath = \"Kmodel1_soft_pre_cate_adam.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "4ade8ad3-0a08-4391-b9cc-b535897670e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1s9MzgGStVV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:04<00:00, 92.81it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel1_soft_pre_cate_adam{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "55Vty_AUStVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1 soft pre cate sgd\n"
      ],
      "metadata": {
        "id": "DKND6UpAStVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 1\n",
        "filepath = \"Kmodel1_soft_pre_cate_sgd.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "4ade8ad3-0a08-4391-b9cc-b535897670e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6PaOOyHStVW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:04<00:00, 92.81it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel1_soft_pre_cate_sgd{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "6HcHnNkAStVW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}