{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "b1(ต่อ).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lT_PlZpRHxA0",
        "AdgXpLcnREHl",
        "TDetFQwMSKk3",
        "QDaLgRIyStVR",
        "OlSZVkmtStVT",
        "VUeDos-7StVT"
      ],
      "authorship_tag": "ABX9TyPQDtp1OANa4k54RRYrh0NC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MMoltira/Chest-X-Ray-classification/blob/main/b1(%E0%B8%95%E0%B9%88%E0%B8%AD).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### import"
      ],
      "metadata": {
        "id": "Kpnf_sft9x4-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Psng6eJUdzUG"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torchsummary import summary\n",
        "from skimage.io import imread, imsave\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model\n",
        "from imutils import paths\n",
        "import argparse\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import metrics\n",
        "from scipy.stats import zscore\n",
        "\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import savefig\n",
        "\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels"
      ],
      "metadata": {
        "id": "6f-PDKiLl2iC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import joblib"
      ],
      "metadata": {
        "id": "KywT8U_h4Bmb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Load data // KKUmail"
      ],
      "metadata": {
        "id": "udl0zY8hAONG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "651fe84f-c2c5-424e-a3a7-4e27ecabba15",
        "id": "CZD0IvKyAONH"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTByVBBEAONI"
      },
      "source": [
        "data_dir = '/content/drive/My Drive/Senior Project/CXR Image3class/Image'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train 3 class"
      ],
      "metadata": {
        "id": "ySK4zn_OAONI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Normal151_dir = os.path.join(data_dir,'Normal151')\n",
        "TB150_dir = os.path.join(data_dir,'TB150')\n",
        "CA150_dir = os.path.join(data_dir,'CA150')\n",
        "\n",
        "All_3class_dir = os.path.join(data_dir,'All_3class')"
      ],
      "metadata": {
        "id": "yWVr9yKtAONI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Load data // Gmail"
      ],
      "metadata": {
        "id": "DVAihFMCTxcI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "274dd748-99e0-4a19-f334-5d3c99f8e1f4",
        "id": "y1ciXCtjTxcJ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q_4EnTuTxcM"
      },
      "source": [
        "data_dir = '/content/drive/My Drive/Senior Project/CXR Image3class/Image'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train 3 class"
      ],
      "metadata": {
        "id": "M0cxoTbeTxcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Normal151_dir = os.path.join(data_dir,'Normal151')\n",
        "TB150_dir = os.path.join(data_dir,'TB150')\n",
        "CA150_dir = os.path.join(data_dir,'CA150')\n",
        "\n",
        "All_3class_dir = os.path.join(data_dir,'All_3class')"
      ],
      "metadata": {
        "id": "xMhNdbHoTxcN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### train 3 class  \n",
        "ข้อมูลใน All_3class_dir รวมภาพทั้ง 3 คลาส รวม 450 ภาพ TB150, Normal151 (เอามาแค่150) และ CA150 (CA คือ lungcancer)"
      ],
      "metadata": {
        "id": "YFVxlpQZf5pU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Normal151_dir = os.path.join(data_dir,'Normal151')\n",
        "TB150_dir = os.path.join(data_dir,'TB150')\n",
        "CA150_dir = os.path.join(data_dir,'CA150')\n",
        "\n",
        "All_3class_dir = os.path.join(data_dir,'All_3class')"
      ],
      "metadata": {
        "id": "8BHyN8YKpwx9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal = []\n",
        "for i in range(len(os.listdir(Normal151_dir))):\n",
        "    img = os.listdir(Normal151_dir)[i]\n",
        "    normal.append(img)\n",
        "    \n",
        "tnormal = pd.DataFrame({'ImageName':[normal][0],\n",
        "                                       'NameType': \"Normal\" ,\n",
        "                                       'NumberType': 0                      })"
      ],
      "metadata": {
        "id": "mT0QF8IgrfVm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuberculosis = []\n",
        "for i in range(len(os.listdir(TB150_dir))):\n",
        "    img = os.listdir(TB150_dir)[i]\n",
        "    tuberculosis.append(img)\n",
        "\n",
        "ttuberculosis = pd.DataFrame({'ImageName':[tuberculosis][0],\n",
        "                                       'NameType': \"Tuberculosis\" ,\n",
        "                                       'NumberType': 1                        })"
      ],
      "metadata": {
        "id": "VtNPg0jwf5pW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lungcancer = []\n",
        "for i in range(len(os.listdir(CA150_dir))):\n",
        "    img = os.listdir(CA150_dir)[i]\n",
        "    lungcancer.append(img)\n",
        "\n",
        "tlungcancer = pd.DataFrame({'ImageName':[lungcancer][0],\n",
        "                                       'NameType': \"Lungcancer\" ,\n",
        "                                       'NumberType': 2                        })"
      ],
      "metadata": {
        "id": "X5pyCUl5mJGV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train3 = pd.concat([tnormal[:-1], ttuberculosis, tlungcancer])\n",
        "data_train3[-3:]"
      ],
      "metadata": {
        "id": "bgArCw5jnwg2",
        "outputId": "6ceace13-5090-4bcb-bf7d-98a5a6009770",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     ImageName    NameType  NumberType\n",
              "147   ca96.jpg  Lungcancer           2\n",
              "148  ca108.jpg  Lungcancer           2\n",
              "149   ca74.jpg  Lungcancer           2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9bcdd105-ee9b-48b8-8450-9920311c1a9b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageName</th>\n",
              "      <th>NameType</th>\n",
              "      <th>NumberType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>ca96.jpg</td>\n",
              "      <td>Lungcancer</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>ca108.jpg</td>\n",
              "      <td>Lungcancer</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>ca74.jpg</td>\n",
              "      <td>Lungcancer</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bcdd105-ee9b-48b8-8450-9920311c1a9b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9bcdd105-ee9b-48b8-8450-9920311c1a9b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9bcdd105-ee9b-48b8-8450-9920311c1a9b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-fold 0-100\n",
        "แก้เป็น k-fold หมดแล้ว \n",
        "เหลือลองรันว่าจะเจ้งมั้ย\n",
        "- 311 layer\n",
        "-   filepath มี .h5 ทุกอัน"
      ],
      "metadata": {
        "id": "4qDyqEDCHxA0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8 \n"
      ],
      "metadata": {
        "id": "lT_PlZpRHxA0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8  soft pre bi\n"
      ],
      "metadata": {
        "id": "4tHlmnjHHxA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 8\n",
        "filepath = \"Kmodel8_soft_pre_bi.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "id": "EAgEARpiKDL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1afaa227-0f17-4a25-99af-04525d8cb0c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:09<00:00, 49.89it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel8_soft_pre_bi{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "S_Bu_V7SKDDf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30a9ecc4-5488-4250-ccd1-60118f83f13f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold #1\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.4859 - accuracy: 0.6361\n",
            "Epoch 1: val_accuracy improved from -inf to 0.55556, saving model to  Kmodel8_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi1.h5 /assets\n",
            "45/45 [==============================] - 99s 2s/step - loss: 0.4859 - accuracy: 0.6361 - val_loss: 0.5577 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.3325 - accuracy: 0.7972\n",
            "Epoch 2: val_accuracy did not improve from 0.55556\n",
            "45/45 [==============================] - 13s 284ms/step - loss: 0.3325 - accuracy: 0.7972 - val_loss: 0.6807 - val_accuracy: 0.5444 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2386 - accuracy: 0.8639\n",
            "Epoch 3: val_accuracy improved from 0.55556 to 0.63333, saving model to  Kmodel8_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi1.h5 /assets\n",
            "45/45 [==============================] - 49s 1s/step - loss: 0.2386 - accuracy: 0.8639 - val_loss: 0.8253 - val_accuracy: 0.6333 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2486 - accuracy: 0.8472\n",
            "Epoch 4: val_accuracy improved from 0.63333 to 0.67778, saving model to  Kmodel8_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi1.h5 /assets\n",
            "45/45 [==============================] - 50s 1s/step - loss: 0.2486 - accuracy: 0.8472 - val_loss: 0.7728 - val_accuracy: 0.6778 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1996 - accuracy: 0.8861\n",
            "Epoch 5: val_accuracy improved from 0.67778 to 0.74444, saving model to  Kmodel8_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi1.h5 /assets\n",
            "45/45 [==============================] - 49s 1s/step - loss: 0.1996 - accuracy: 0.8861 - val_loss: 0.7053 - val_accuracy: 0.7444 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1664 - accuracy: 0.9000\n",
            "Epoch 6: val_accuracy improved from 0.74444 to 0.76667, saving model to  Kmodel8_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi1.h5 /assets\n",
            "45/45 [==============================] - 49s 1s/step - loss: 0.1664 - accuracy: 0.9000 - val_loss: 0.7265 - val_accuracy: 0.7667 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1329 - accuracy: 0.9250\n",
            "Epoch 7: val_accuracy improved from 0.76667 to 0.83333, saving model to  Kmodel8_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi1.h5 /assets\n",
            "45/45 [==============================] - 49s 1s/step - loss: 0.1329 - accuracy: 0.9250 - val_loss: 0.5359 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 0.9583\n",
            "Epoch 8: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.1159 - accuracy: 0.9583 - val_loss: 0.6339 - val_accuracy: 0.7778 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9278\n",
            "Epoch 9: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.1303 - accuracy: 0.9278 - val_loss: 0.9281 - val_accuracy: 0.7889 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1256 - accuracy: 0.9361\n",
            "Epoch 10: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 13s 279ms/step - loss: 0.1256 - accuracy: 0.9361 - val_loss: 0.8530 - val_accuracy: 0.7444 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1014 - accuracy: 0.9500\n",
            "Epoch 11: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 13s 280ms/step - loss: 0.1014 - accuracy: 0.9500 - val_loss: 1.9834 - val_accuracy: 0.4667 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.9556\n",
            "Epoch 12: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 12s 273ms/step - loss: 0.1097 - accuracy: 0.9556 - val_loss: 0.7823 - val_accuracy: 0.8111 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9583\n",
            "Epoch 13: val_accuracy did not improve from 0.83333\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "45/45 [==============================] - 13s 288ms/step - loss: 0.0860 - accuracy: 0.9583 - val_loss: 1.7207 - val_accuracy: 0.6889 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0734 - accuracy: 0.9722\n",
            "Epoch 14: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 13s 289ms/step - loss: 0.0734 - accuracy: 0.9722 - val_loss: 1.4784 - val_accuracy: 0.7000 - lr: 5.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.9500\n",
            "Epoch 15: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 13s 280ms/step - loss: 0.0796 - accuracy: 0.9500 - val_loss: 1.2922 - val_accuracy: 0.6667 - lr: 5.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9833\n",
            "Epoch 16: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 13s 278ms/step - loss: 0.0540 - accuracy: 0.9833 - val_loss: 0.9621 - val_accuracy: 0.6889 - lr: 5.0000e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9833\n",
            "Epoch 17: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 12s 274ms/step - loss: 0.0346 - accuracy: 0.9833 - val_loss: 1.2088 - val_accuracy: 0.6111 - lr: 5.0000e-05\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.9694\n",
            "Epoch 18: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 12s 272ms/step - loss: 0.0808 - accuracy: 0.9694 - val_loss: 1.0151 - val_accuracy: 0.6556 - lr: 5.0000e-05\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9861\n",
            "Epoch 19: val_accuracy did not improve from 0.83333\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "45/45 [==============================] - 13s 276ms/step - loss: 0.0359 - accuracy: 0.9861 - val_loss: 0.8619 - val_accuracy: 0.7333 - lr: 5.0000e-05\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.9861\n",
            "Epoch 20: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 13s 278ms/step - loss: 0.0354 - accuracy: 0.9861 - val_loss: 0.8847 - val_accuracy: 0.7000 - lr: 2.5000e-05\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.9778\n",
            "Epoch 21: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 13s 277ms/step - loss: 0.0785 - accuracy: 0.9778 - val_loss: 0.8072 - val_accuracy: 0.7111 - lr: 2.5000e-05\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 0.9861\n",
            "Epoch 22: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 13s 286ms/step - loss: 0.0299 - accuracy: 0.9861 - val_loss: 0.5885 - val_accuracy: 0.7556 - lr: 2.5000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.83      0.68      0.75        28\n",
            "      Normal       0.95      0.68      0.79        31\n",
            "Tuberculosis       0.62      0.90      0.74        31\n",
            "\n",
            "    accuracy                           0.76        90\n",
            "   macro avg       0.80      0.75      0.76        90\n",
            "weighted avg       0.80      0.76      0.76        90\n",
            "\n",
            "Fold #2\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1452 - accuracy: 0.9361\n",
            "Epoch 1: val_accuracy improved from -inf to 1.00000, saving model to  Kmodel8_soft_pre_bi2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi2.h5 /assets\n",
            "45/45 [==============================] - 49s 1s/step - loss: 0.1452 - accuracy: 0.9361 - val_loss: 0.0220 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 0.9500\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 13s 282ms/step - loss: 0.1095 - accuracy: 0.9500 - val_loss: 0.0257 - val_accuracy: 0.9889 - lr: 2.5000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0522 - accuracy: 0.9722\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 13s 281ms/step - loss: 0.0522 - accuracy: 0.9722 - val_loss: 0.0664 - val_accuracy: 0.9778 - lr: 2.5000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9722\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 13s 281ms/step - loss: 0.0577 - accuracy: 0.9722 - val_loss: 0.1403 - val_accuracy: 0.9111 - lr: 2.5000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0717 - accuracy: 0.9694\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0717 - accuracy: 0.9694 - val_loss: 0.0496 - val_accuracy: 0.9778 - lr: 2.5000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9750\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0674 - accuracy: 0.9750 - val_loss: 0.0713 - val_accuracy: 0.9556 - lr: 2.5000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0490 - accuracy: 0.9750\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0490 - accuracy: 0.9750 - val_loss: 0.1024 - val_accuracy: 0.9222 - lr: 2.5000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.9778\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0446 - accuracy: 0.9778 - val_loss: 0.0879 - val_accuracy: 0.9333 - lr: 1.2500e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0562 - accuracy: 0.9694\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 13s 276ms/step - loss: 0.0562 - accuracy: 0.9694 - val_loss: 0.0671 - val_accuracy: 0.9556 - lr: 1.2500e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.9833\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 13s 275ms/step - loss: 0.0473 - accuracy: 0.9833 - val_loss: 0.0821 - val_accuracy: 0.9333 - lr: 1.2500e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9722\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.0487 - accuracy: 0.9722 - val_loss: 0.1469 - val_accuracy: 0.8778 - lr: 1.2500e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 0.9833\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0410 - accuracy: 0.9833 - val_loss: 0.1154 - val_accuracy: 0.9000 - lr: 1.2500e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9861\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "45/45 [==============================] - 13s 276ms/step - loss: 0.0269 - accuracy: 0.9861 - val_loss: 0.1358 - val_accuracy: 0.9000 - lr: 1.2500e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9833\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0334 - accuracy: 0.9833 - val_loss: 0.1713 - val_accuracy: 0.8778 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9806\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 13s 276ms/step - loss: 0.0397 - accuracy: 0.9806 - val_loss: 0.1972 - val_accuracy: 0.8667 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 0.9778\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 13s 276ms/step - loss: 0.0435 - accuracy: 0.9778 - val_loss: 0.1256 - val_accuracy: 0.8889 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.74      0.85        34\n",
            "      Normal       1.00      0.96      0.98        27\n",
            "Tuberculosis       0.74      1.00      0.85        29\n",
            "\n",
            "    accuracy                           0.89        90\n",
            "   macro avg       0.91      0.90      0.89        90\n",
            "weighted avg       0.92      0.89      0.89        90\n",
            "\n",
            "Fold #3\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.9944\n",
            "Epoch 1: val_accuracy improved from -inf to 0.96667, saving model to  Kmodel8_soft_pre_bi3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi3.h5 /assets\n",
            "45/45 [==============================] - 49s 1s/step - loss: 0.0265 - accuracy: 0.9944 - val_loss: 0.0778 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9889\n",
            "Epoch 2: val_accuracy did not improve from 0.96667\n",
            "45/45 [==============================] - 13s 277ms/step - loss: 0.0262 - accuracy: 0.9889 - val_loss: 0.1421 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9944\n",
            "Epoch 3: val_accuracy did not improve from 0.96667\n",
            "45/45 [==============================] - 13s 279ms/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 0.1183 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9833\n",
            "Epoch 4: val_accuracy improved from 0.96667 to 0.97778, saving model to  Kmodel8_soft_pre_bi3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi3.h5 /assets\n",
            "45/45 [==============================] - 49s 1s/step - loss: 0.0404 - accuracy: 0.9833 - val_loss: 0.0682 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9917\n",
            "Epoch 5: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0311 - accuracy: 0.9917 - val_loss: 0.1142 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 0.9917\n",
            "Epoch 6: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0282 - accuracy: 0.9917 - val_loss: 0.0489 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.9722\n",
            "Epoch 7: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 13s 278ms/step - loss: 0.0531 - accuracy: 0.9722 - val_loss: 0.0636 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9833\n",
            "Epoch 8: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 13s 286ms/step - loss: 0.0256 - accuracy: 0.9833 - val_loss: 0.0723 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 0.9944\n",
            "Epoch 9: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 13s 289ms/step - loss: 0.0205 - accuracy: 0.9944 - val_loss: 0.1298 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9972\n",
            "Epoch 10: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 12s 273ms/step - loss: 0.0144 - accuracy: 0.9972 - val_loss: 0.0694 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9889\n",
            "Epoch 11: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 13s 281ms/step - loss: 0.0294 - accuracy: 0.9889 - val_loss: 0.1260 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9972\n",
            "Epoch 12: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 13s 279ms/step - loss: 0.0148 - accuracy: 0.9972 - val_loss: 0.1116 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9861\n",
            "Epoch 13: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 13s 287ms/step - loss: 0.0248 - accuracy: 0.9861 - val_loss: 0.0756 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9944\n",
            "Epoch 14: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 13s 276ms/step - loss: 0.0157 - accuracy: 0.9944 - val_loss: 0.0697 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9944\n",
            "Epoch 15: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 13s 283ms/step - loss: 0.0157 - accuracy: 0.9944 - val_loss: 0.0592 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9944\n",
            "Epoch 16: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 13s 277ms/step - loss: 0.0147 - accuracy: 0.9944 - val_loss: 0.0652 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 13s 281ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9889\n",
            "Epoch 18: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 13s 279ms/step - loss: 0.0289 - accuracy: 0.9889 - val_loss: 0.0989 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9833\n",
            "Epoch 19: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 13s 285ms/step - loss: 0.0235 - accuracy: 0.9833 - val_loss: 0.1341 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.89      0.94        27\n",
            "      Normal       1.00      0.97      0.98        33\n",
            "Tuberculosis       0.88      1.00      0.94        30\n",
            "\n",
            "    accuracy                           0.96        90\n",
            "   macro avg       0.96      0.95      0.95        90\n",
            "weighted avg       0.96      0.96      0.96        90\n",
            "\n",
            "Fold #4\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9972\n",
            "Epoch 1: val_accuracy improved from -inf to 0.96667, saving model to  Kmodel8_soft_pre_bi4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi4.h5 /assets\n",
            "45/45 [==============================] - 50s 1s/step - loss: 0.0166 - accuracy: 0.9972 - val_loss: 0.1123 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9972\n",
            "Epoch 2: val_accuracy did not improve from 0.96667\n",
            "45/45 [==============================] - 13s 285ms/step - loss: 0.0110 - accuracy: 0.9972 - val_loss: 0.1409 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9889\n",
            "Epoch 3: val_accuracy did not improve from 0.96667\n",
            "45/45 [==============================] - 13s 284ms/step - loss: 0.0180 - accuracy: 0.9889 - val_loss: 0.0754 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9861\n",
            "Epoch 4: val_accuracy did not improve from 0.96667\n",
            "45/45 [==============================] - 13s 281ms/step - loss: 0.0240 - accuracy: 0.9861 - val_loss: 0.0837 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.9972\n",
            "Epoch 5: val_accuracy improved from 0.96667 to 0.97778, saving model to  Kmodel8_soft_pre_bi4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi4.h5 /assets\n",
            "45/45 [==============================] - 48s 1s/step - loss: 0.0130 - accuracy: 0.9972 - val_loss: 0.0779 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy improved from 0.97778 to 0.98889, saving model to  Kmodel8_soft_pre_bi4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi4.h5 /assets\n",
            "45/45 [==============================] - 48s 1s/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.9944\n",
            "Epoch 8: val_accuracy improved from 0.98889 to 1.00000, saving model to  Kmodel8_soft_pre_bi4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi4.h5 /assets\n",
            "45/45 [==============================] - 47s 1s/step - loss: 0.0215 - accuracy: 0.9944 - val_loss: 0.0303 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 0.9806\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0360 - accuracy: 0.9806 - val_loss: 0.0309 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9972\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0133 - accuracy: 0.9972 - val_loss: 0.0362 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9917\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.0153 - accuracy: 0.9917 - val_loss: 0.0853 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9944\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0108 - accuracy: 0.9944 - val_loss: 0.0778 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9917\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.0204 - accuracy: 0.9917 - val_loss: 0.0501 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 272ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9972\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.0076 - accuracy: 0.9972 - val_loss: 0.0451 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0573 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9944\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0209 - accuracy: 0.9944 - val_loss: 0.0898 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9889\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0230 - accuracy: 0.9889 - val_loss: 0.0858 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9972\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.0946 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0831 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.9944\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0128 - accuracy: 0.9944 - val_loss: 0.1053 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.83      0.91        30\n",
            "      Normal       1.00      0.97      0.98        31\n",
            "Tuberculosis       0.83      1.00      0.91        29\n",
            "\n",
            "    accuracy                           0.93        90\n",
            "   macro avg       0.94      0.93      0.93        90\n",
            "weighted avg       0.94      0.93      0.93        90\n",
            "\n",
            "Fold #5\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 1: val_accuracy improved from -inf to 0.98889, saving model to  Kmodel8_soft_pre_bi5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi5.h5 /assets\n",
            "45/45 [==============================] - 48s 1s/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 2: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 3: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 270ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9944\n",
            "Epoch 4: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 271ms/step - loss: 0.0106 - accuracy: 0.9944 - val_loss: 0.0174 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 5: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9972\n",
            "Epoch 6: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.0098 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9944\n",
            "Epoch 7: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0123 - accuracy: 0.9944 - val_loss: 0.0144 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9944\n",
            "Epoch 8: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0154 - accuracy: 0.9944 - val_loss: 0.0278 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9972\n",
            "Epoch 10: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 270ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.0314 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9972\n",
            "Epoch 11: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 270ms/step - loss: 0.0056 - accuracy: 0.9972 - val_loss: 0.0376 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9917\n",
            "Epoch 12: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 272ms/step - loss: 0.0161 - accuracy: 0.9917 - val_loss: 0.0516 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 273ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0563 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9972\n",
            "Epoch 14: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.0554 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9972\n",
            "Epoch 16: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0237 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.97      0.98        31\n",
            "      Normal       1.00      1.00      1.00        28\n",
            "Tuberculosis       0.97      1.00      0.98        31\n",
            "\n",
            "    accuracy                           0.99        90\n",
            "   macro avg       0.99      0.99      0.99        90\n",
            "weighted avg       0.99      0.99      0.99        90\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.97      0.82      0.89       150\n",
            "      Normal       0.99      0.91      0.95       150\n",
            "Tuberculosis       0.79      0.98      0.88       150\n",
            "\n",
            "    accuracy                           0.90       450\n",
            "   macro avg       0.92      0.90      0.91       450\n",
            "weighted avg       0.92      0.90      0.91       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "H_Incep.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7gTdnI-0VqX",
        "outputId": "a7099b4a-6b54-4e85-b962-042098cedca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy', 'lr'])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = H_Incep.history['lr']\n",
        "\n",
        "plt.figure(figsize=(20,15))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(lr, label = \" Learning rate\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZdFZUZc0dEI",
        "outputId": "562df815-f22f-4aab-af1a-d13480c460b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7efd69e456d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8 soft pre bi adam  \n"
      ],
      "metadata": {
        "id": "XhGoWt8CHxA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 8\n",
        "filepath = \"Kmodel8_soft_pre_bi_adam.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k5-3GpI6epe",
        "outputId": "23c8e8f4-35fe-499d-d7db-428e9f957220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:05<00:00, 87.26it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel8_soft_pre_bi_adam{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "qTbqFtDF6cwy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "593ca483-aa81-4019-dfd7-bf0fc35aec9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold #1\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.5132 - accuracy: 0.5972\n",
            "Epoch 1: val_accuracy improved from -inf to 0.52222, saving model to  Kmodel8_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_adam1.h5 /assets\n",
            "45/45 [==============================] - 78s 2s/step - loss: 0.5132 - accuracy: 0.5972 - val_loss: 0.6663 - val_accuracy: 0.5222 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.3175 - accuracy: 0.8083\n",
            "Epoch 2: val_accuracy improved from 0.52222 to 0.72222, saving model to  Kmodel8_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_adam1.h5 /assets\n",
            "45/45 [==============================] - 49s 1s/step - loss: 0.3175 - accuracy: 0.8083 - val_loss: 0.3642 - val_accuracy: 0.7222 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2747 - accuracy: 0.8417\n",
            "Epoch 3: val_accuracy improved from 0.72222 to 0.74444, saving model to  Kmodel8_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_adam1.h5 /assets\n",
            "45/45 [==============================] - 49s 1s/step - loss: 0.2747 - accuracy: 0.8417 - val_loss: 0.3847 - val_accuracy: 0.7444 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2252 - accuracy: 0.8611\n",
            "Epoch 4: val_accuracy improved from 0.74444 to 0.76667, saving model to  Kmodel8_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_adam1.h5 /assets\n",
            "45/45 [==============================] - 49s 1s/step - loss: 0.2252 - accuracy: 0.8611 - val_loss: 0.4821 - val_accuracy: 0.7667 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2298 - accuracy: 0.8611\n",
            "Epoch 5: val_accuracy did not improve from 0.76667\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.2298 - accuracy: 0.8611 - val_loss: 0.4175 - val_accuracy: 0.7667 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1609 - accuracy: 0.9167\n",
            "Epoch 6: val_accuracy did not improve from 0.76667\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.1609 - accuracy: 0.9167 - val_loss: 0.6214 - val_accuracy: 0.7444 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1184 - accuracy: 0.9444\n",
            "Epoch 7: val_accuracy did not improve from 0.76667\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.1184 - accuracy: 0.9444 - val_loss: 0.5268 - val_accuracy: 0.7556 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1325 - accuracy: 0.9333\n",
            "Epoch 8: val_accuracy did not improve from 0.76667\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.1325 - accuracy: 0.9333 - val_loss: 0.9235 - val_accuracy: 0.6778 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1442 - accuracy: 0.9333\n",
            "Epoch 9: val_accuracy improved from 0.76667 to 0.82222, saving model to  Kmodel8_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_adam1.h5 /assets\n",
            "45/45 [==============================] - 48s 1s/step - loss: 0.1442 - accuracy: 0.9333 - val_loss: 0.3693 - val_accuracy: 0.8222 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1026 - accuracy: 0.9472\n",
            "Epoch 10: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.1026 - accuracy: 0.9472 - val_loss: 0.9582 - val_accuracy: 0.5889 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1202 - accuracy: 0.9333\n",
            "Epoch 11: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.1202 - accuracy: 0.9333 - val_loss: 0.4999 - val_accuracy: 0.7556 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9694\n",
            "Epoch 12: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.0836 - accuracy: 0.9694 - val_loss: 0.4232 - val_accuracy: 0.8222 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9694\n",
            "Epoch 13: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.0525 - accuracy: 0.9694 - val_loss: 0.4989 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 0.9472\n",
            "Epoch 14: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.1018 - accuracy: 0.9472 - val_loss: 1.4822 - val_accuracy: 0.6333 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9472\n",
            "Epoch 15: val_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.1060 - accuracy: 0.9472 - val_loss: 0.5934 - val_accuracy: 0.7778 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0720 - accuracy: 0.9778\n",
            "Epoch 16: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.0720 - accuracy: 0.9778 - val_loss: 0.5113 - val_accuracy: 0.7889 - lr: 5.0000e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9972\n",
            "Epoch 17: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.0246 - accuracy: 0.9972 - val_loss: 0.7061 - val_accuracy: 0.7556 - lr: 5.0000e-05\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0463 - accuracy: 0.9806\n",
            "Epoch 18: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.0463 - accuracy: 0.9806 - val_loss: 0.6795 - val_accuracy: 0.7667 - lr: 5.0000e-05\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.9778\n",
            "Epoch 19: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.0399 - accuracy: 0.9778 - val_loss: 0.6775 - val_accuracy: 0.7778 - lr: 5.0000e-05\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.9861\n",
            "Epoch 20: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0433 - accuracy: 0.9861 - val_loss: 0.4554 - val_accuracy: 0.8222 - lr: 5.0000e-05\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0490 - accuracy: 0.9694\n",
            "Epoch 21: val_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.0490 - accuracy: 0.9694 - val_loss: 0.6164 - val_accuracy: 0.7333 - lr: 5.0000e-05\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9917\n",
            "Epoch 22: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0331 - accuracy: 0.9917 - val_loss: 0.5481 - val_accuracy: 0.7889 - lr: 2.5000e-05\n",
            "Epoch 23/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9917\n",
            "Epoch 23: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0338 - accuracy: 0.9917 - val_loss: 0.4764 - val_accuracy: 0.8000 - lr: 2.5000e-05\n",
            "Epoch 24/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 0.9861\n",
            "Epoch 24: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0402 - accuracy: 0.9861 - val_loss: 0.7190 - val_accuracy: 0.7556 - lr: 2.5000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.93      0.50      0.65        28\n",
            "      Normal       0.93      0.81      0.86        31\n",
            "Tuberculosis       0.60      0.94      0.73        31\n",
            "\n",
            "    accuracy                           0.76        90\n",
            "   macro avg       0.82      0.75      0.75        90\n",
            "weighted avg       0.82      0.76      0.75        90\n",
            "\n",
            "Fold #2\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1414 - accuracy: 0.9472\n",
            "Epoch 1: val_accuracy improved from -inf to 0.98889, saving model to  Kmodel8_soft_pre_bi_adam2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_adam2.h5 /assets\n",
            "45/45 [==============================] - 50s 1s/step - loss: 0.1414 - accuracy: 0.9472 - val_loss: 0.0297 - val_accuracy: 0.9889 - lr: 2.5000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9667\n",
            "Epoch 2: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.0680 - accuracy: 0.9667 - val_loss: 0.0686 - val_accuracy: 0.9667 - lr: 2.5000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.9667\n",
            "Epoch 3: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0698 - accuracy: 0.9667 - val_loss: 0.1303 - val_accuracy: 0.9222 - lr: 2.5000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9722\n",
            "Epoch 4: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.0581 - accuracy: 0.9722 - val_loss: 0.1006 - val_accuracy: 0.9333 - lr: 2.5000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0484 - accuracy: 0.9806\n",
            "Epoch 5: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0484 - accuracy: 0.9806 - val_loss: 0.1063 - val_accuracy: 0.9333 - lr: 2.5000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 0.9889\n",
            "Epoch 6: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0357 - accuracy: 0.9889 - val_loss: 0.1682 - val_accuracy: 0.9111 - lr: 2.5000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.9750\n",
            "Epoch 7: val_accuracy did not improve from 0.98889\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0505 - accuracy: 0.9750 - val_loss: 0.2024 - val_accuracy: 0.8778 - lr: 2.5000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9778\n",
            "Epoch 8: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0481 - accuracy: 0.9778 - val_loss: 0.1038 - val_accuracy: 0.9444 - lr: 1.2500e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 0.9778\n",
            "Epoch 9: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0499 - accuracy: 0.9778 - val_loss: 0.0962 - val_accuracy: 0.9444 - lr: 1.2500e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9917\n",
            "Epoch 10: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.0260 - accuracy: 0.9917 - val_loss: 0.1499 - val_accuracy: 0.9111 - lr: 1.2500e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9861\n",
            "Epoch 11: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0474 - accuracy: 0.9861 - val_loss: 0.1716 - val_accuracy: 0.9111 - lr: 1.2500e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9917\n",
            "Epoch 12: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0268 - accuracy: 0.9917 - val_loss: 0.1825 - val_accuracy: 0.8889 - lr: 1.2500e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9917\n",
            "Epoch 13: val_accuracy did not improve from 0.98889\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0322 - accuracy: 0.9917 - val_loss: 0.1715 - val_accuracy: 0.8889 - lr: 1.2500e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9889\n",
            "Epoch 14: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.0220 - accuracy: 0.9889 - val_loss: 0.1496 - val_accuracy: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9861\n",
            "Epoch 15: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0311 - accuracy: 0.9861 - val_loss: 0.1543 - val_accuracy: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9889\n",
            "Epoch 16: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0365 - accuracy: 0.9889 - val_loss: 0.1368 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.79      0.89        34\n",
            "      Normal       1.00      1.00      1.00        27\n",
            "Tuberculosis       0.81      1.00      0.89        29\n",
            "\n",
            "    accuracy                           0.92        90\n",
            "   macro avg       0.94      0.93      0.93        90\n",
            "weighted avg       0.94      0.92      0.92        90\n",
            "\n",
            "Fold #3\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9917\n",
            "Epoch 1: val_accuracy improved from -inf to 0.98889, saving model to  Kmodel8_soft_pre_bi_adam3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_adam3.h5 /assets\n",
            "45/45 [==============================] - 50s 1s/step - loss: 0.0274 - accuracy: 0.9917 - val_loss: 0.0542 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9917\n",
            "Epoch 2: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.0327 - accuracy: 0.9917 - val_loss: 0.0366 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9889\n",
            "Epoch 3: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.0234 - accuracy: 0.9889 - val_loss: 0.0295 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9944\n",
            "Epoch 4: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0222 - accuracy: 0.9944 - val_loss: 0.0335 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9861\n",
            "Epoch 5: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0211 - accuracy: 0.9861 - val_loss: 0.0485 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9917\n",
            "Epoch 6: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0290 - accuracy: 0.9917 - val_loss: 0.0321 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 0.9917\n",
            "Epoch 7: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0192 - accuracy: 0.9917 - val_loss: 0.0273 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.9889\n",
            "Epoch 9: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0285 - accuracy: 0.9889 - val_loss: 0.0624 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9972\n",
            "Epoch 10: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0219 - accuracy: 0.9972 - val_loss: 0.0611 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9917\n",
            "Epoch 11: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0238 - accuracy: 0.9917 - val_loss: 0.0500 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0229 - accuracy: 0.9944\n",
            "Epoch 12: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0229 - accuracy: 0.9944 - val_loss: 0.0700 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9972\n",
            "Epoch 13: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 13s 276ms/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.0421 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9944\n",
            "Epoch 14: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0160 - accuracy: 0.9944 - val_loss: 0.0395 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9944\n",
            "Epoch 15: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.0186 - accuracy: 0.9944 - val_loss: 0.0431 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0312 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.96      0.98        27\n",
            "      Normal       1.00      1.00      1.00        33\n",
            "Tuberculosis       0.97      1.00      0.98        30\n",
            "\n",
            "    accuracy                           0.99        90\n",
            "   macro avg       0.99      0.99      0.99        90\n",
            "weighted avg       0.99      0.99      0.99        90\n",
            "\n",
            "Fold #4\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9972\n",
            "Epoch 1: val_accuracy improved from -inf to 1.00000, saving model to  Kmodel8_soft_pre_bi_adam4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_adam4.h5 /assets\n",
            "45/45 [==============================] - 50s 1s/step - loss: 0.0131 - accuracy: 0.9972 - val_loss: 0.0233 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9889\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0257 - accuracy: 0.9889 - val_loss: 0.0510 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9917\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.0188 - accuracy: 0.9917 - val_loss: 0.0439 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9944\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.0134 - accuracy: 0.9944 - val_loss: 0.0413 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9889\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0383 - accuracy: 0.9889 - val_loss: 0.0398 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9972\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0150 - accuracy: 0.9972 - val_loss: 0.0351 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.0302 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9972\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0176 - accuracy: 0.9972 - val_loss: 0.0323 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9806\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0401 - accuracy: 0.9806 - val_loss: 0.0278 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9917\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0211 - accuracy: 0.9917 - val_loss: 0.0458 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9972\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0153 - accuracy: 0.9972 - val_loss: 0.0453 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9917\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.0172 - accuracy: 0.9917 - val_loss: 0.0626 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0575 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.97      0.98        30\n",
            "      Normal       1.00      0.94      0.97        31\n",
            "Tuberculosis       0.91      1.00      0.95        29\n",
            "\n",
            "    accuracy                           0.97        90\n",
            "   macro avg       0.97      0.97      0.97        90\n",
            "weighted avg       0.97      0.97      0.97        90\n",
            "\n",
            "Fold #5\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9972\n",
            "Epoch 1: val_accuracy improved from -inf to 0.98889, saving model to  Kmodel8_soft_pre_bi_adam5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_adam5.h5 /assets\n",
            "45/45 [==============================] - 49s 1s/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.0263 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9972\n",
            "Epoch 2: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.0125 - accuracy: 0.9972 - val_loss: 0.0361 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 1.0000\n",
            "Epoch 3: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 0.9917\n",
            "Epoch 4: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.0282 - accuracy: 0.9917 - val_loss: 0.0272 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 1.0000\n",
            "Epoch 5: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9972\n",
            "Epoch 6: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.0118 - accuracy: 0.9972 - val_loss: 0.0276 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9944\n",
            "Epoch 8: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0165 - accuracy: 0.9944 - val_loss: 0.0167 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9972\n",
            "Epoch 9: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0237 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9972\n",
            "Epoch 10: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0172 - accuracy: 0.9972 - val_loss: 0.0234 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.9944\n",
            "Epoch 11: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0132 - accuracy: 0.9944 - val_loss: 0.0319 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9889\n",
            "Epoch 12: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0235 - accuracy: 0.9889 - val_loss: 0.0358 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9972\n",
            "Epoch 13: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0113 - accuracy: 0.9972 - val_loss: 0.0455 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9944\n",
            "Epoch 14: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0139 - accuracy: 0.9944 - val_loss: 0.0365 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9917\n",
            "Epoch 15: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0133 - accuracy: 0.9917 - val_loss: 0.0447 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.97      0.98        31\n",
            "      Normal       1.00      1.00      1.00        28\n",
            "Tuberculosis       0.97      1.00      0.98        31\n",
            "\n",
            "    accuracy                           0.99        90\n",
            "   macro avg       0.99      0.99      0.99        90\n",
            "weighted avg       0.99      0.99      0.99        90\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.99      0.84      0.91       150\n",
            "      Normal       0.99      0.95      0.97       150\n",
            "Tuberculosis       0.83      0.99      0.90       150\n",
            "\n",
            "    accuracy                           0.92       450\n",
            "   macro avg       0.94      0.92      0.93       450\n",
            "weighted avg       0.94      0.92      0.93       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8 soft pre bi sgd  \n"
      ],
      "metadata": {
        "id": "4CfquesGP-rZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 8\n",
        "filepath = \"Kmodel8_soft_pre_bi_sgd.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee99b589-85fb-439e-fff3-1e46200ff5e8",
        "id": "gdxYY4UjP-ra"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:05<00:00, 86.61it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel8_soft_pre_bi_sgd{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "uqOS1R8QP-ra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eda714ad-df3c-4c06-9181-6d0652aeb5c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold #1\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7086 - accuracy: 0.3083\n",
            "Epoch 1: val_accuracy improved from -inf to 0.34444, saving model to  Kmodel8_soft_pre_bi_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd1.h5 /assets\n",
            "45/45 [==============================] - 93s 1s/step - loss: 0.7086 - accuracy: 0.3083 - val_loss: 0.7040 - val_accuracy: 0.3444 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6998 - accuracy: 0.3500\n",
            "Epoch 2: val_accuracy did not improve from 0.34444\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.6998 - accuracy: 0.3500 - val_loss: 0.7079 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6975 - accuracy: 0.2889\n",
            "Epoch 3: val_accuracy improved from 0.34444 to 0.37778, saving model to  Kmodel8_soft_pre_bi_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd1.h5 /assets\n",
            "45/45 [==============================] - 47s 1s/step - loss: 0.6975 - accuracy: 0.2889 - val_loss: 0.7001 - val_accuracy: 0.3778 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6811 - accuracy: 0.3556\n",
            "Epoch 4: val_accuracy improved from 0.37778 to 0.41111, saving model to  Kmodel8_soft_pre_bi_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd1.h5 /assets\n",
            "45/45 [==============================] - 47s 1s/step - loss: 0.6811 - accuracy: 0.3556 - val_loss: 0.6875 - val_accuracy: 0.4111 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6799 - accuracy: 0.3389\n",
            "Epoch 5: val_accuracy improved from 0.41111 to 0.43333, saving model to  Kmodel8_soft_pre_bi_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd1.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.6799 - accuracy: 0.3389 - val_loss: 0.6771 - val_accuracy: 0.4333 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6726 - accuracy: 0.3306\n",
            "Epoch 6: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.6726 - accuracy: 0.3306 - val_loss: 0.6706 - val_accuracy: 0.4222 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6683 - accuracy: 0.3611\n",
            "Epoch 7: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.6683 - accuracy: 0.3611 - val_loss: 0.6659 - val_accuracy: 0.4000 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6610 - accuracy: 0.3667\n",
            "Epoch 8: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.6610 - accuracy: 0.3667 - val_loss: 0.6613 - val_accuracy: 0.3778 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6614 - accuracy: 0.3417\n",
            "Epoch 9: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.6614 - accuracy: 0.3417 - val_loss: 0.6578 - val_accuracy: 0.3778 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6540 - accuracy: 0.3694\n",
            "Epoch 10: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6540 - accuracy: 0.3694 - val_loss: 0.6541 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6589 - accuracy: 0.3528\n",
            "Epoch 11: val_accuracy did not improve from 0.43333\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6589 - accuracy: 0.3528 - val_loss: 0.6510 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6456 - accuracy: 0.4000\n",
            "Epoch 12: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.6456 - accuracy: 0.4000 - val_loss: 0.6496 - val_accuracy: 0.3889 - lr: 5.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6447 - accuracy: 0.4139\n",
            "Epoch 13: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6447 - accuracy: 0.4139 - val_loss: 0.6474 - val_accuracy: 0.3889 - lr: 5.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6434 - accuracy: 0.4167\n",
            "Epoch 14: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6434 - accuracy: 0.4167 - val_loss: 0.6463 - val_accuracy: 0.3889 - lr: 5.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6431 - accuracy: 0.3972\n",
            "Epoch 15: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.6431 - accuracy: 0.3972 - val_loss: 0.6451 - val_accuracy: 0.3889 - lr: 5.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6412 - accuracy: 0.4500\n",
            "Epoch 16: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6412 - accuracy: 0.4500 - val_loss: 0.6440 - val_accuracy: 0.3778 - lr: 5.0000e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6448 - accuracy: 0.3861\n",
            "Epoch 17: val_accuracy did not improve from 0.43333\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6448 - accuracy: 0.3861 - val_loss: 0.6425 - val_accuracy: 0.3889 - lr: 5.0000e-05\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6382 - accuracy: 0.4111\n",
            "Epoch 18: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6382 - accuracy: 0.4111 - val_loss: 0.6420 - val_accuracy: 0.3889 - lr: 2.5000e-05\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6458 - accuracy: 0.3694\n",
            "Epoch 19: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6458 - accuracy: 0.3694 - val_loss: 0.6408 - val_accuracy: 0.3889 - lr: 2.5000e-05\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6378 - accuracy: 0.3944\n",
            "Epoch 20: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.6378 - accuracy: 0.3944 - val_loss: 0.6402 - val_accuracy: 0.3889 - lr: 2.5000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.33      0.32      0.33        28\n",
            "      Normal       0.51      0.65      0.57        31\n",
            "Tuberculosis       0.25      0.19      0.22        31\n",
            "\n",
            "    accuracy                           0.39        90\n",
            "   macro avg       0.37      0.39      0.37        90\n",
            "weighted avg       0.37      0.39      0.37        90\n",
            "\n",
            "Fold #2\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6356 - accuracy: 0.4028\n",
            "Epoch 1: val_accuracy improved from -inf to 0.46667, saving model to  Kmodel8_soft_pre_bi_sgd2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd2.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.6356 - accuracy: 0.4028 - val_loss: 0.6351 - val_accuracy: 0.4667 - lr: 2.5000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6406 - accuracy: 0.4139\n",
            "Epoch 2: val_accuracy did not improve from 0.46667\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6406 - accuracy: 0.4139 - val_loss: 0.6342 - val_accuracy: 0.4667 - lr: 2.5000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6358 - accuracy: 0.4250\n",
            "Epoch 3: val_accuracy improved from 0.46667 to 0.51111, saving model to  Kmodel8_soft_pre_bi_sgd2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd2.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.6358 - accuracy: 0.4250 - val_loss: 0.6339 - val_accuracy: 0.5111 - lr: 2.5000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6358 - accuracy: 0.4083\n",
            "Epoch 4: val_accuracy did not improve from 0.51111\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6358 - accuracy: 0.4083 - val_loss: 0.6335 - val_accuracy: 0.5000 - lr: 2.5000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6347 - accuracy: 0.4389\n",
            "Epoch 5: val_accuracy did not improve from 0.51111\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6347 - accuracy: 0.4389 - val_loss: 0.6330 - val_accuracy: 0.5000 - lr: 2.5000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6351 - accuracy: 0.4111\n",
            "Epoch 6: val_accuracy did not improve from 0.51111\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.6351 - accuracy: 0.4111 - val_loss: 0.6323 - val_accuracy: 0.5000 - lr: 2.5000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6369 - accuracy: 0.4056\n",
            "Epoch 7: val_accuracy did not improve from 0.51111\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6369 - accuracy: 0.4056 - val_loss: 0.6317 - val_accuracy: 0.5000 - lr: 2.5000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6360 - accuracy: 0.3889\n",
            "Epoch 8: val_accuracy did not improve from 0.51111\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6360 - accuracy: 0.3889 - val_loss: 0.6302 - val_accuracy: 0.4889 - lr: 2.5000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6371 - accuracy: 0.4222\n",
            "Epoch 9: val_accuracy did not improve from 0.51111\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.6371 - accuracy: 0.4222 - val_loss: 0.6299 - val_accuracy: 0.4889 - lr: 2.5000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6354 - accuracy: 0.4389\n",
            "Epoch 10: val_accuracy did not improve from 0.51111\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6354 - accuracy: 0.4389 - val_loss: 0.6303 - val_accuracy: 0.4889 - lr: 1.2500e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6333 - accuracy: 0.4250\n",
            "Epoch 11: val_accuracy did not improve from 0.51111\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6333 - accuracy: 0.4250 - val_loss: 0.6313 - val_accuracy: 0.4667 - lr: 1.2500e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6349 - accuracy: 0.4167\n",
            "Epoch 12: val_accuracy did not improve from 0.51111\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6349 - accuracy: 0.4167 - val_loss: 0.6308 - val_accuracy: 0.4889 - lr: 1.2500e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6380 - accuracy: 0.4139\n",
            "Epoch 13: val_accuracy improved from 0.51111 to 0.52222, saving model to  Kmodel8_soft_pre_bi_sgd2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd2.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.6380 - accuracy: 0.4139 - val_loss: 0.6303 - val_accuracy: 0.5222 - lr: 1.2500e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6370 - accuracy: 0.4306\n",
            "Epoch 14: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6370 - accuracy: 0.4306 - val_loss: 0.6297 - val_accuracy: 0.5222 - lr: 1.2500e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6336 - accuracy: 0.4500\n",
            "Epoch 15: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6336 - accuracy: 0.4500 - val_loss: 0.6297 - val_accuracy: 0.5222 - lr: 1.2500e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6352 - accuracy: 0.3750\n",
            "Epoch 16: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6352 - accuracy: 0.3750 - val_loss: 0.6294 - val_accuracy: 0.5111 - lr: 1.2500e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6328 - accuracy: 0.4583\n",
            "Epoch 17: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6328 - accuracy: 0.4583 - val_loss: 0.6293 - val_accuracy: 0.5111 - lr: 1.2500e-05\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6317 - accuracy: 0.4583\n",
            "Epoch 18: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6317 - accuracy: 0.4583 - val_loss: 0.6278 - val_accuracy: 0.5111 - lr: 1.2500e-05\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6329 - accuracy: 0.4361\n",
            "Epoch 19: val_accuracy did not improve from 0.52222\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6329 - accuracy: 0.4361 - val_loss: 0.6283 - val_accuracy: 0.5111 - lr: 1.2500e-05\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6285 - accuracy: 0.4306\n",
            "Epoch 20: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6285 - accuracy: 0.4306 - val_loss: 0.6273 - val_accuracy: 0.5111 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6347 - accuracy: 0.3917\n",
            "Epoch 21: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6347 - accuracy: 0.3917 - val_loss: 0.6283 - val_accuracy: 0.5111 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6324 - accuracy: 0.4056\n",
            "Epoch 22: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6324 - accuracy: 0.4056 - val_loss: 0.6283 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6296 - accuracy: 0.4444\n",
            "Epoch 23: val_accuracy improved from 0.52222 to 0.53333, saving model to  Kmodel8_soft_pre_bi_sgd2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd2.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.6296 - accuracy: 0.4444 - val_loss: 0.6278 - val_accuracy: 0.5333 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6275 - accuracy: 0.4583\n",
            "Epoch 24: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6275 - accuracy: 0.4583 - val_loss: 0.6274 - val_accuracy: 0.5333 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6303 - accuracy: 0.4222\n",
            "Epoch 25: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.6303 - accuracy: 0.4222 - val_loss: 0.6270 - val_accuracy: 0.5333 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6269 - accuracy: 0.4667\n",
            "Epoch 26: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6269 - accuracy: 0.4667 - val_loss: 0.6266 - val_accuracy: 0.5333 - lr: 1.0000e-05\n",
            "Epoch 27/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6316 - accuracy: 0.4056\n",
            "Epoch 27: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6316 - accuracy: 0.4056 - val_loss: 0.6265 - val_accuracy: 0.5333 - lr: 1.0000e-05\n",
            "Epoch 28/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6305 - accuracy: 0.4389\n",
            "Epoch 28: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6305 - accuracy: 0.4389 - val_loss: 0.6259 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 29/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6297 - accuracy: 0.4639\n",
            "Epoch 29: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6297 - accuracy: 0.4639 - val_loss: 0.6264 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 30/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6289 - accuracy: 0.4389\n",
            "Epoch 30: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6289 - accuracy: 0.4389 - val_loss: 0.6267 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 31/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6294 - accuracy: 0.4222\n",
            "Epoch 31: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6294 - accuracy: 0.4222 - val_loss: 0.6266 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 32/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6249 - accuracy: 0.4250\n",
            "Epoch 32: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.6249 - accuracy: 0.4250 - val_loss: 0.6261 - val_accuracy: 0.5333 - lr: 1.0000e-05\n",
            "Epoch 33/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6325 - accuracy: 0.4056\n",
            "Epoch 33: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.6325 - accuracy: 0.4056 - val_loss: 0.6264 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 34/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6227 - accuracy: 0.5139\n",
            "Epoch 34: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6227 - accuracy: 0.5139 - val_loss: 0.6265 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 35/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6314 - accuracy: 0.4361\n",
            "Epoch 35: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6314 - accuracy: 0.4361 - val_loss: 0.6256 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 36/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6252 - accuracy: 0.4722\n",
            "Epoch 36: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6252 - accuracy: 0.4722 - val_loss: 0.6253 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 37/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6304 - accuracy: 0.4194\n",
            "Epoch 37: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6304 - accuracy: 0.4194 - val_loss: 0.6249 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 38/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6290 - accuracy: 0.4306\n",
            "Epoch 38: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.6290 - accuracy: 0.4306 - val_loss: 0.6248 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.59      0.29      0.39        34\n",
            "      Normal       0.48      0.89      0.62        27\n",
            "Tuberculosis       0.57      0.45      0.50        29\n",
            "\n",
            "    accuracy                           0.52        90\n",
            "   macro avg       0.54      0.54      0.51        90\n",
            "weighted avg       0.55      0.52      0.50        90\n",
            "\n",
            "Fold #3\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6319 - accuracy: 0.4083\n",
            "Epoch 1: val_accuracy improved from -inf to 0.52222, saving model to  Kmodel8_soft_pre_bi_sgd3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd3.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.6319 - accuracy: 0.4083 - val_loss: 0.6209 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6349 - accuracy: 0.4333\n",
            "Epoch 2: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.6349 - accuracy: 0.4333 - val_loss: 0.6211 - val_accuracy: 0.5111 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6328 - accuracy: 0.4500\n",
            "Epoch 3: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.6328 - accuracy: 0.4500 - val_loss: 0.6200 - val_accuracy: 0.5111 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6304 - accuracy: 0.4472\n",
            "Epoch 4: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 254ms/step - loss: 0.6304 - accuracy: 0.4472 - val_loss: 0.6198 - val_accuracy: 0.5111 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6266 - accuracy: 0.4611\n",
            "Epoch 5: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.6266 - accuracy: 0.4611 - val_loss: 0.6205 - val_accuracy: 0.5111 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6315 - accuracy: 0.4472\n",
            "Epoch 6: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.6315 - accuracy: 0.4472 - val_loss: 0.6203 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6289 - accuracy: 0.4472\n",
            "Epoch 7: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.6289 - accuracy: 0.4472 - val_loss: 0.6195 - val_accuracy: 0.5111 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6186 - accuracy: 0.5111\n",
            "Epoch 8: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6186 - accuracy: 0.5111 - val_loss: 0.6197 - val_accuracy: 0.5111 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6258 - accuracy: 0.4361\n",
            "Epoch 9: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.6258 - accuracy: 0.4361 - val_loss: 0.6200 - val_accuracy: 0.5111 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6262 - accuracy: 0.4611\n",
            "Epoch 10: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.6262 - accuracy: 0.4611 - val_loss: 0.6188 - val_accuracy: 0.5111 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6331 - accuracy: 0.4194\n",
            "Epoch 11: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6331 - accuracy: 0.4194 - val_loss: 0.6186 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6249 - accuracy: 0.4778\n",
            "Epoch 12: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6249 - accuracy: 0.4778 - val_loss: 0.6183 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6301 - accuracy: 0.4722\n",
            "Epoch 13: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6301 - accuracy: 0.4722 - val_loss: 0.6186 - val_accuracy: 0.5111 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6243 - accuracy: 0.4778\n",
            "Epoch 14: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6243 - accuracy: 0.4778 - val_loss: 0.6188 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6264 - accuracy: 0.4556\n",
            "Epoch 15: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6264 - accuracy: 0.4556 - val_loss: 0.6188 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6232 - accuracy: 0.4778\n",
            "Epoch 16: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.6232 - accuracy: 0.4778 - val_loss: 0.6180 - val_accuracy: 0.5111 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.56      0.33      0.42        27\n",
            "      Normal       0.56      0.82      0.67        33\n",
            "Tuberculosis       0.38      0.33      0.36        30\n",
            "\n",
            "    accuracy                           0.51        90\n",
            "   macro avg       0.50      0.49      0.48        90\n",
            "weighted avg       0.50      0.51      0.49        90\n",
            "\n",
            "Fold #4\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6254 - accuracy: 0.4611\n",
            "Epoch 1: val_accuracy improved from -inf to 0.38889, saving model to  Kmodel8_soft_pre_bi_sgd4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd4.h5 /assets\n",
            "45/45 [==============================] - 47s 1s/step - loss: 0.6254 - accuracy: 0.4611 - val_loss: 0.6385 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6221 - accuracy: 0.4778\n",
            "Epoch 2: val_accuracy did not improve from 0.38889\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6221 - accuracy: 0.4778 - val_loss: 0.6388 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6274 - accuracy: 0.4361\n",
            "Epoch 3: val_accuracy improved from 0.38889 to 0.40000, saving model to  Kmodel8_soft_pre_bi_sgd4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd4.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.6274 - accuracy: 0.4361 - val_loss: 0.6383 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6283 - accuracy: 0.4139\n",
            "Epoch 4: val_accuracy did not improve from 0.40000\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6283 - accuracy: 0.4139 - val_loss: 0.6379 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6242 - accuracy: 0.4500\n",
            "Epoch 5: val_accuracy did not improve from 0.40000\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6242 - accuracy: 0.4500 - val_loss: 0.6379 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6234 - accuracy: 0.4417\n",
            "Epoch 6: val_accuracy did not improve from 0.40000\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.6234 - accuracy: 0.4417 - val_loss: 0.6381 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6243 - accuracy: 0.4583\n",
            "Epoch 7: val_accuracy did not improve from 0.40000\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6243 - accuracy: 0.4583 - val_loss: 0.6382 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6250 - accuracy: 0.4472\n",
            "Epoch 8: val_accuracy did not improve from 0.40000\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6250 - accuracy: 0.4472 - val_loss: 0.6385 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6197 - accuracy: 0.4833\n",
            "Epoch 9: val_accuracy did not improve from 0.40000\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6197 - accuracy: 0.4833 - val_loss: 0.6384 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6283 - accuracy: 0.4389\n",
            "Epoch 10: val_accuracy did not improve from 0.40000\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6283 - accuracy: 0.4389 - val_loss: 0.6375 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6253 - accuracy: 0.4806\n",
            "Epoch 11: val_accuracy did not improve from 0.40000\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6253 - accuracy: 0.4806 - val_loss: 0.6374 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6254 - accuracy: 0.4333\n",
            "Epoch 12: val_accuracy did not improve from 0.40000\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.6254 - accuracy: 0.4333 - val_loss: 0.6373 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6201 - accuracy: 0.4750\n",
            "Epoch 13: val_accuracy did not improve from 0.40000\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.6201 - accuracy: 0.4750 - val_loss: 0.6362 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6234 - accuracy: 0.4500\n",
            "Epoch 14: val_accuracy did not improve from 0.40000\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.6234 - accuracy: 0.4500 - val_loss: 0.6361 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6275 - accuracy: 0.3917\n",
            "Epoch 15: val_accuracy did not improve from 0.40000\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6275 - accuracy: 0.3917 - val_loss: 0.6361 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6240 - accuracy: 0.4611\n",
            "Epoch 16: val_accuracy improved from 0.40000 to 0.41111, saving model to  Kmodel8_soft_pre_bi_sgd4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd4.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.6240 - accuracy: 0.4611 - val_loss: 0.6357 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6183 - accuracy: 0.4639\n",
            "Epoch 17: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6183 - accuracy: 0.4639 - val_loss: 0.6352 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6281 - accuracy: 0.4472\n",
            "Epoch 18: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.6281 - accuracy: 0.4472 - val_loss: 0.6347 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6215 - accuracy: 0.4583\n",
            "Epoch 19: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6215 - accuracy: 0.4583 - val_loss: 0.6350 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6222 - accuracy: 0.4583\n",
            "Epoch 20: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6222 - accuracy: 0.4583 - val_loss: 0.6352 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6239 - accuracy: 0.4611\n",
            "Epoch 21: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.6239 - accuracy: 0.4611 - val_loss: 0.6350 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6168 - accuracy: 0.5028\n",
            "Epoch 22: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.6168 - accuracy: 0.5028 - val_loss: 0.6354 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6211 - accuracy: 0.4611\n",
            "Epoch 23: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.6211 - accuracy: 0.4611 - val_loss: 0.6360 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6197 - accuracy: 0.4778\n",
            "Epoch 24: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.6197 - accuracy: 0.4778 - val_loss: 0.6360 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6191 - accuracy: 0.4722\n",
            "Epoch 25: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.6191 - accuracy: 0.4722 - val_loss: 0.6356 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6232 - accuracy: 0.4417\n",
            "Epoch 26: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6232 - accuracy: 0.4417 - val_loss: 0.6356 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 27/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6179 - accuracy: 0.4944\n",
            "Epoch 27: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.6179 - accuracy: 0.4944 - val_loss: 0.6346 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 28/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6217 - accuracy: 0.4667\n",
            "Epoch 28: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.6217 - accuracy: 0.4667 - val_loss: 0.6342 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 29/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6186 - accuracy: 0.4944\n",
            "Epoch 29: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.6186 - accuracy: 0.4944 - val_loss: 0.6342 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 30/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6189 - accuracy: 0.5028\n",
            "Epoch 30: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.6189 - accuracy: 0.5028 - val_loss: 0.6339 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 31/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6251 - accuracy: 0.4306\n",
            "Epoch 31: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.6251 - accuracy: 0.4306 - val_loss: 0.6338 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.53      0.27      0.36        30\n",
            "      Normal       0.46      0.58      0.51        31\n",
            "Tuberculosis       0.28      0.34      0.31        29\n",
            "\n",
            "    accuracy                           0.40        90\n",
            "   macro avg       0.42      0.40      0.39        90\n",
            "weighted avg       0.43      0.40      0.39        90\n",
            "\n",
            "Fold #5\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6213 - accuracy: 0.4556\n",
            "Epoch 1: val_accuracy improved from -inf to 0.44444, saving model to  Kmodel8_soft_pre_bi_sgd5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd5.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.6213 - accuracy: 0.4556 - val_loss: 0.6210 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6185 - accuracy: 0.4556\n",
            "Epoch 2: val_accuracy did not improve from 0.44444\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.6185 - accuracy: 0.4556 - val_loss: 0.6210 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6244 - accuracy: 0.4583\n",
            "Epoch 3: val_accuracy did not improve from 0.44444\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6244 - accuracy: 0.4583 - val_loss: 0.6209 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6122 - accuracy: 0.5528\n",
            "Epoch 4: val_accuracy did not improve from 0.44444\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.6122 - accuracy: 0.5528 - val_loss: 0.6209 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6133 - accuracy: 0.5250\n",
            "Epoch 5: val_accuracy improved from 0.44444 to 0.45556, saving model to  Kmodel8_soft_pre_bi_sgd5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd5.h5 /assets\n",
            "45/45 [==============================] - 45s 1s/step - loss: 0.6133 - accuracy: 0.5250 - val_loss: 0.6198 - val_accuracy: 0.4556 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6231 - accuracy: 0.4444\n",
            "Epoch 6: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.6231 - accuracy: 0.4444 - val_loss: 0.6204 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6130 - accuracy: 0.4889\n",
            "Epoch 7: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.6130 - accuracy: 0.4889 - val_loss: 0.6205 - val_accuracy: 0.4556 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6257 - accuracy: 0.4528\n",
            "Epoch 8: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6257 - accuracy: 0.4528 - val_loss: 0.6198 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6165 - accuracy: 0.4750\n",
            "Epoch 9: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.6165 - accuracy: 0.4750 - val_loss: 0.6193 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6233 - accuracy: 0.4417\n",
            "Epoch 10: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.6233 - accuracy: 0.4417 - val_loss: 0.6187 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6176 - accuracy: 0.4861\n",
            "Epoch 11: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.6176 - accuracy: 0.4861 - val_loss: 0.6192 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6169 - accuracy: 0.5000\n",
            "Epoch 12: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6169 - accuracy: 0.5000 - val_loss: 0.6191 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6187 - accuracy: 0.4667\n",
            "Epoch 13: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6187 - accuracy: 0.4667 - val_loss: 0.6189 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6088 - accuracy: 0.5278\n",
            "Epoch 14: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.6088 - accuracy: 0.5278 - val_loss: 0.6182 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6165 - accuracy: 0.4500\n",
            "Epoch 15: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.6165 - accuracy: 0.4500 - val_loss: 0.6184 - val_accuracy: 0.4556 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6212 - accuracy: 0.4556\n",
            "Epoch 16: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.6212 - accuracy: 0.4556 - val_loss: 0.6189 - val_accuracy: 0.4556 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6153 - accuracy: 0.4972\n",
            "Epoch 17: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.6153 - accuracy: 0.4972 - val_loss: 0.6187 - val_accuracy: 0.4556 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6158 - accuracy: 0.4750\n",
            "Epoch 18: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.6158 - accuracy: 0.4750 - val_loss: 0.6179 - val_accuracy: 0.4556 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6192 - accuracy: 0.4750\n",
            "Epoch 19: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.6192 - accuracy: 0.4750 - val_loss: 0.6177 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6118 - accuracy: 0.5444\n",
            "Epoch 20: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.6118 - accuracy: 0.5444 - val_loss: 0.6176 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.61      0.35      0.45        31\n",
            "      Normal       0.44      0.79      0.56        28\n",
            "Tuberculosis       0.32      0.23      0.26        31\n",
            "\n",
            "    accuracy                           0.44        90\n",
            "   macro avg       0.46      0.46      0.43        90\n",
            "weighted avg       0.46      0.44      0.42        90\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.51      0.31      0.39       150\n",
            "      Normal       0.49      0.74      0.59       150\n",
            "Tuberculosis       0.35      0.31      0.33       150\n",
            "\n",
            "    accuracy                           0.45       450\n",
            "   macro avg       0.45      0.45      0.43       450\n",
            "weighted avg       0.45      0.45      0.43       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8 soft pre cate \n"
      ],
      "metadata": {
        "id": "gIezSP7KHxA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 8\n",
        "filepath = \"Kmodel8_soft_pre_cate.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "6af5c167-6393-47b9-a4ca-3407a512b810",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7LqShb-HxA5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:05<00:00, 87.44it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel8_soft_pre_cate{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "zInSrqiRHxA-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9090cb40-36bc-4443-e2c0-8f11f422d634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold #1\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7615 - accuracy: 0.6528\n",
            "Epoch 1: val_accuracy improved from -inf to 0.60000, saving model to  Kmodel8_soft_pre_cate1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate1.h5 /assets\n",
            "45/45 [==============================] - 59s 1s/step - loss: 0.7615 - accuracy: 0.6528 - val_loss: 0.8505 - val_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.5673 - accuracy: 0.7750\n",
            "Epoch 2: val_accuracy improved from 0.60000 to 0.71111, saving model to  Kmodel8_soft_pre_cate1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate1.h5 /assets\n",
            "45/45 [==============================] - 47s 1s/step - loss: 0.5673 - accuracy: 0.7750 - val_loss: 0.7341 - val_accuracy: 0.7111 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.5094 - accuracy: 0.8000\n",
            "Epoch 3: val_accuracy did not improve from 0.71111\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.5094 - accuracy: 0.8000 - val_loss: 1.2492 - val_accuracy: 0.6222 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.3652 - accuracy: 0.8583\n",
            "Epoch 4: val_accuracy improved from 0.71111 to 0.77778, saving model to  Kmodel8_soft_pre_cate1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate1.h5 /assets\n",
            "45/45 [==============================] - 47s 1s/step - loss: 0.3652 - accuracy: 0.8583 - val_loss: 0.5917 - val_accuracy: 0.7778 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2976 - accuracy: 0.8944\n",
            "Epoch 5: val_accuracy did not improve from 0.77778\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.2976 - accuracy: 0.8944 - val_loss: 1.0703 - val_accuracy: 0.6889 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2514 - accuracy: 0.9056\n",
            "Epoch 6: val_accuracy improved from 0.77778 to 0.78889, saving model to  Kmodel8_soft_pre_cate1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate1.h5 /assets\n",
            "45/45 [==============================] - 47s 1s/step - loss: 0.2514 - accuracy: 0.9056 - val_loss: 0.7613 - val_accuracy: 0.7889 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2582 - accuracy: 0.9000\n",
            "Epoch 7: val_accuracy did not improve from 0.78889\n",
            "45/45 [==============================] - 12s 273ms/step - loss: 0.2582 - accuracy: 0.9000 - val_loss: 2.4470 - val_accuracy: 0.6556 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2248 - accuracy: 0.9056\n",
            "Epoch 8: val_accuracy did not improve from 0.78889\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.2248 - accuracy: 0.9056 - val_loss: 1.5605 - val_accuracy: 0.7111 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1829 - accuracy: 0.9278\n",
            "Epoch 9: val_accuracy did not improve from 0.78889\n",
            "45/45 [==============================] - 12s 270ms/step - loss: 0.1829 - accuracy: 0.9278 - val_loss: 0.9775 - val_accuracy: 0.7556 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1219 - accuracy: 0.9583\n",
            "Epoch 10: val_accuracy did not improve from 0.78889\n",
            "45/45 [==============================] - 12s 270ms/step - loss: 0.1219 - accuracy: 0.9583 - val_loss: 2.0539 - val_accuracy: 0.7111 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2220 - accuracy: 0.9278\n",
            "Epoch 11: val_accuracy did not improve from 0.78889\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.2220 - accuracy: 0.9278 - val_loss: 0.9083 - val_accuracy: 0.7444 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1024 - accuracy: 0.9639\n",
            "Epoch 12: val_accuracy improved from 0.78889 to 0.83333, saving model to  Kmodel8_soft_pre_cate1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate1.h5 /assets\n",
            "45/45 [==============================] - 47s 1s/step - loss: 0.1024 - accuracy: 0.9639 - val_loss: 0.6529 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1252 - accuracy: 0.9611\n",
            "Epoch 13: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.1252 - accuracy: 0.9611 - val_loss: 1.0029 - val_accuracy: 0.8111 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1025 - accuracy: 0.9694\n",
            "Epoch 14: val_accuracy improved from 0.83333 to 0.85556, saving model to  Kmodel8_soft_pre_cate1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate1.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.1025 - accuracy: 0.9694 - val_loss: 0.8471 - val_accuracy: 0.8556 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1467 - accuracy: 0.9528\n",
            "Epoch 15: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.1467 - accuracy: 0.9528 - val_loss: 3.2847 - val_accuracy: 0.5444 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1153 - accuracy: 0.9500\n",
            "Epoch 16: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.1153 - accuracy: 0.9500 - val_loss: 1.6126 - val_accuracy: 0.7556 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0988 - accuracy: 0.9667\n",
            "Epoch 17: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0988 - accuracy: 0.9667 - val_loss: 0.6817 - val_accuracy: 0.8222 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1100 - accuracy: 0.9583\n",
            "Epoch 18: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.1100 - accuracy: 0.9583 - val_loss: 1.8598 - val_accuracy: 0.7444 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1012 - accuracy: 0.9556\n",
            "Epoch 19: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.1012 - accuracy: 0.9556 - val_loss: 2.2946 - val_accuracy: 0.6889 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1059 - accuracy: 0.9639\n",
            "Epoch 20: val_accuracy did not improve from 0.85556\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.1059 - accuracy: 0.9639 - val_loss: 1.0209 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.9750\n",
            "Epoch 21: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0609 - accuracy: 0.9750 - val_loss: 1.0149 - val_accuracy: 0.7778 - lr: 5.0000e-05\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9861\n",
            "Epoch 22: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0370 - accuracy: 0.9861 - val_loss: 2.4755 - val_accuracy: 0.7111 - lr: 5.0000e-05\n",
            "Epoch 23/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.9861\n",
            "Epoch 23: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0458 - accuracy: 0.9861 - val_loss: 0.7551 - val_accuracy: 0.8444 - lr: 5.0000e-05\n",
            "Epoch 24/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9861\n",
            "Epoch 24: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.0330 - accuracy: 0.9861 - val_loss: 1.0272 - val_accuracy: 0.8000 - lr: 5.0000e-05\n",
            "Epoch 25/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9972\n",
            "Epoch 25: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0187 - accuracy: 0.9972 - val_loss: 1.5656 - val_accuracy: 0.7778 - lr: 5.0000e-05\n",
            "Epoch 26/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.9861\n",
            "Epoch 26: val_accuracy did not improve from 0.85556\n",
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0296 - accuracy: 0.9861 - val_loss: 1.9463 - val_accuracy: 0.7778 - lr: 5.0000e-05\n",
            "Epoch 27/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0806 - accuracy: 0.9750\n",
            "Epoch 27: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0806 - accuracy: 0.9750 - val_loss: 1.2162 - val_accuracy: 0.8111 - lr: 2.5000e-05\n",
            "Epoch 28/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9944\n",
            "Epoch 28: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0232 - accuracy: 0.9944 - val_loss: 1.3735 - val_accuracy: 0.8111 - lr: 2.5000e-05\n",
            "Epoch 29/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9833\n",
            "Epoch 29: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0554 - accuracy: 0.9833 - val_loss: 1.5852 - val_accuracy: 0.7778 - lr: 2.5000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.43      0.60        28\n",
            "      Normal       0.97      0.90      0.93        31\n",
            "Tuberculosis       0.61      0.97      0.75        31\n",
            "\n",
            "    accuracy                           0.78        90\n",
            "   macro avg       0.86      0.77      0.76        90\n",
            "weighted avg       0.85      0.78      0.77        90\n",
            "\n",
            "Fold #2\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2068 - accuracy: 0.9417\n",
            "Epoch 1: val_accuracy improved from -inf to 1.00000, saving model to  Kmodel8_soft_pre_cate2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate2.h5 /assets\n",
            "45/45 [==============================] - 47s 1s/step - loss: 0.2068 - accuracy: 0.9417 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1723 - accuracy: 0.9556\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.1723 - accuracy: 0.9556 - val_loss: 0.0066 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0691 - accuracy: 0.9833\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0691 - accuracy: 0.9833 - val_loss: 0.0184 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0559 - accuracy: 0.9861\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0559 - accuracy: 0.9861 - val_loss: 0.0066 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0732 - accuracy: 0.9750\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0732 - accuracy: 0.9750 - val_loss: 0.0299 - val_accuracy: 0.9889 - lr: 2.5000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.9806\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0795 - accuracy: 0.9806 - val_loss: 0.0040 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 0.9889\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0242 - accuracy: 0.9889 - val_loss: 0.0022 - val_accuracy: 1.0000 - lr: 1.2500e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9889\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.0248 - accuracy: 0.9889 - val_loss: 0.0035 - val_accuracy: 1.0000 - lr: 1.2500e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0558 - accuracy: 0.9833\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.0558 - accuracy: 0.9833 - val_loss: 0.0089 - val_accuracy: 1.0000 - lr: 1.2500e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9889\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.0352 - accuracy: 0.9889 - val_loss: 0.0092 - val_accuracy: 1.0000 - lr: 1.2500e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9944\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 271ms/step - loss: 0.0197 - accuracy: 0.9944 - val_loss: 0.0052 - val_accuracy: 1.0000 - lr: 1.2500e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9889\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0397 - accuracy: 0.9889 - val_loss: 0.0123 - val_accuracy: 1.0000 - lr: 1.2500e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9833\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0272 - accuracy: 0.9833 - val_loss: 0.0489 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9944\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 270ms/step - loss: 0.0203 - accuracy: 0.9944 - val_loss: 0.0771 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9944\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0159 - accuracy: 0.9944 - val_loss: 0.1632 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.79      0.89        34\n",
            "      Normal       1.00      1.00      1.00        27\n",
            "Tuberculosis       0.81      1.00      0.89        29\n",
            "\n",
            "    accuracy                           0.92        90\n",
            "   macro avg       0.94      0.93      0.93        90\n",
            "weighted avg       0.94      0.92      0.92        90\n",
            "\n",
            "Fold #3\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9972\n",
            "Epoch 1: val_accuracy improved from -inf to 0.96667, saving model to  Kmodel8_soft_pre_cate3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate3.h5 /assets\n",
            "45/45 [==============================] - 47s 1s/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.0678 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9944\n",
            "Epoch 2: val_accuracy improved from 0.96667 to 0.98889, saving model to  Kmodel8_soft_pre_cate3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate3.h5 /assets\n",
            "45/45 [==============================] - 47s 1s/step - loss: 0.0202 - accuracy: 0.9944 - val_loss: 0.0351 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9917\n",
            "Epoch 3: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0185 - accuracy: 0.9917 - val_loss: 0.0308 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0412 - accuracy: 0.9917\n",
            "Epoch 4: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0412 - accuracy: 0.9917 - val_loss: 0.0296 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9861\n",
            "Epoch 5: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0269 - accuracy: 0.9861 - val_loss: 0.0486 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9917\n",
            "Epoch 7: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0222 - accuracy: 0.9917 - val_loss: 0.0296 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9944\n",
            "Epoch 10: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0348 - accuracy: 0.9944 - val_loss: 0.0332 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9917\n",
            "Epoch 12: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 0.0478 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 270ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9972\n",
            "Epoch 14: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0066 - accuracy: 0.9972 - val_loss: 0.0260 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9944\n",
            "Epoch 15: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 270ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.0383 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9972\n",
            "Epoch 17: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.0185 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.96      0.98        27\n",
            "      Normal       1.00      1.00      1.00        33\n",
            "Tuberculosis       0.97      1.00      0.98        30\n",
            "\n",
            "    accuracy                           0.99        90\n",
            "   macro avg       0.99      0.99      0.99        90\n",
            "weighted avg       0.99      0.99      0.99        90\n",
            "\n",
            "Fold #4\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 1: val_accuracy improved from -inf to 0.97778, saving model to  Kmodel8_soft_pre_cate4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate4.h5 /assets\n",
            "45/45 [==============================] - 47s 1s/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.9833\n",
            "Epoch 2: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.0659 - accuracy: 0.9833 - val_loss: 0.0804 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9889\n",
            "Epoch 3: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0269 - accuracy: 0.9889 - val_loss: 0.0716 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 4: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 12s 275ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0826 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9944\n",
            "Epoch 5: val_accuracy improved from 0.97778 to 0.98889, saving model to  Kmodel8_soft_pre_cate4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate4.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.0151 - accuracy: 0.9944 - val_loss: 0.0483 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9972\n",
            "Epoch 9: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 0.1204 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9972\n",
            "Epoch 10: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0063 - accuracy: 0.9972 - val_loss: 0.1011 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9972\n",
            "Epoch 11: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0066 - accuracy: 0.9972 - val_loss: 0.0960 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9944\n",
            "Epoch 14: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0144 - accuracy: 0.9944 - val_loss: 0.0606 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0628 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9944\n",
            "Epoch 17: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0138 - accuracy: 0.9944 - val_loss: 0.1102 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9944\n",
            "Epoch 18: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0072 - accuracy: 0.9944 - val_loss: 0.0931 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9972\n",
            "Epoch 19: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0072 - accuracy: 0.9972 - val_loss: 0.0838 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9917\n",
            "Epoch 20: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0138 - accuracy: 0.9917 - val_loss: 0.0684 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.93      0.97        30\n",
            "      Normal       1.00      1.00      1.00        31\n",
            "Tuberculosis       0.94      1.00      0.97        29\n",
            "\n",
            "    accuracy                           0.98        90\n",
            "   macro avg       0.98      0.98      0.98        90\n",
            "weighted avg       0.98      0.98      0.98        90\n",
            "\n",
            "Fold #5\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 1: val_accuracy improved from -inf to 0.97778, saving model to  Kmodel8_soft_pre_cate5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate5.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 2: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 3: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9972\n",
            "Epoch 4: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0823 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 5: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9944\n",
            "Epoch 6: val_accuracy improved from 0.97778 to 0.98889, saving model to  Kmodel8_soft_pre_cate5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate5.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 0.0290 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0292 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy improved from 0.98889 to 1.00000, saving model to  Kmodel8_soft_pre_cate5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate5.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9972\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0047 - accuracy: 0.9972 - val_loss: 0.0146 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9944\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0140 - accuracy: 0.9944 - val_loss: 0.0377 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9944\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0111 - accuracy: 0.9944 - val_loss: 0.0647 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0327 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9972\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0036 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9944\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0118 - accuracy: 0.9944 - val_loss: 0.0140 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9972\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0073 - accuracy: 0.9972 - val_loss: 0.0199 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9972\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.0274 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9972\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0060 - accuracy: 0.9972 - val_loss: 0.0354 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9972\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0047 - accuracy: 0.9972 - val_loss: 0.0458 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.94      0.97        31\n",
            "      Normal       1.00      1.00      1.00        28\n",
            "Tuberculosis       0.94      1.00      0.97        31\n",
            "\n",
            "    accuracy                           0.98        90\n",
            "   macro avg       0.98      0.98      0.98        90\n",
            "weighted avg       0.98      0.98      0.98        90\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.81      0.90       150\n",
            "      Normal       0.99      0.98      0.99       150\n",
            "Tuberculosis       0.83      0.99      0.90       150\n",
            "\n",
            "    accuracy                           0.93       450\n",
            "   macro avg       0.94      0.93      0.93       450\n",
            "weighted avg       0.94      0.93      0.93       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8 soft pre cate adam\n"
      ],
      "metadata": {
        "id": "nbfA8plqHxBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 8\n",
        "filepath = \"Kmodel8_soft_pre_cate_adam.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "95a53f9d-8f4b-4b3d-d67f-a1c4255339dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOXzS-frHxBA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [02:37<00:00,  2.86it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel8_soft_pre_cate_adam{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "8TXqdL-wHxBA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "674f7c85-0eb4-4e9d-b6cc-2678dee7cd31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "87924736/87910968 [==============================] - 1s 0us/step\n",
            "Fold #1\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7665 - accuracy: 0.6139\n",
            "Epoch 1: val_accuracy improved from -inf to 0.56667, saving model to  Kmodel8_soft_pre_cate_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_adam1.h5 /assets\n",
            "45/45 [==============================] - 240s 5s/step - loss: 0.7665 - accuracy: 0.6139 - val_loss: 1.0940 - val_accuracy: 0.5667 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.5185 - accuracy: 0.8056\n",
            "Epoch 2: val_accuracy improved from 0.56667 to 0.78889, saving model to  Kmodel8_soft_pre_cate_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_adam1.h5 /assets\n",
            "45/45 [==============================] - 222s 5s/step - loss: 0.5185 - accuracy: 0.8056 - val_loss: 0.5704 - val_accuracy: 0.7889 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "42/45 [===========================>..] - ETA: 11s - loss: 0.4034 - accuracy: 0.8452"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8 soft pre cate sgd\n"
      ],
      "metadata": {
        "id": "W_E0EHBiQlIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 8\n",
        "filepath = \"Kmodel8_soft_pre_cate_sgd.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "id": "ZHY8s-kPQlIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel8_soft_pre_cate_sgd{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "xEFeEAyBQlIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 16\n"
      ],
      "metadata": {
        "id": "AdgXpLcnREHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 16  soft pre bi\n"
      ],
      "metadata": {
        "id": "NZUvi2SEREHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 16\n",
        "filepath = \"Kmodel16_soft_pre_bi.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "id": "L5EfGRXwREHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f33b3a67-92fd-4145-b7a1-144ead7f4e7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [03:49<00:00,  1.96it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel16_soft_pre_bi{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "wzmw0gyPREHo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9ebfe1d-d63f-4f05-a8ee-e4f38cdb48c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "87924736/87910968 [==============================] - 1s 0us/step\n",
            "Fold #1\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.4811 - accuracy: 0.6628\n",
            "Epoch 1: val_accuracy improved from -inf to 0.34444, saving model to  Kmodel16_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi1.h5 /assets\n",
            "22/22 [==============================] - 227s 10s/step - loss: 0.4811 - accuracy: 0.6628 - val_loss: 1.0341 - val_accuracy: 0.3444 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.3386 - accuracy: 0.8081\n",
            "Epoch 2: val_accuracy improved from 0.34444 to 0.47778, saving model to  Kmodel16_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi1.h5 /assets\n",
            "22/22 [==============================] - 216s 10s/step - loss: 0.3386 - accuracy: 0.8081 - val_loss: 0.9141 - val_accuracy: 0.4778 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.2409 - accuracy: 0.8488\n",
            "Epoch 3: val_accuracy improved from 0.47778 to 0.53333, saving model to  Kmodel16_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi1.h5 /assets\n",
            "22/22 [==============================] - 217s 10s/step - loss: 0.2409 - accuracy: 0.8488 - val_loss: 0.8740 - val_accuracy: 0.5333 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1648 - accuracy: 0.8953\n",
            "Epoch 4: val_accuracy improved from 0.53333 to 0.62222, saving model to  Kmodel16_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi1.h5 /assets\n",
            "22/22 [==============================] - 216s 10s/step - loss: 0.1648 - accuracy: 0.8953 - val_loss: 0.8616 - val_accuracy: 0.6222 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1802 - accuracy: 0.9070\n",
            "Epoch 5: val_accuracy did not improve from 0.62222\n",
            "22/22 [==============================] - 182s 8s/step - loss: 0.1802 - accuracy: 0.9070 - val_loss: 1.0653 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1243 - accuracy: 0.9244\n",
            "Epoch 6: val_accuracy improved from 0.62222 to 0.71111, saving model to  Kmodel16_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi1.h5 /assets\n",
            "22/22 [==============================] - 211s 10s/step - loss: 0.1243 - accuracy: 0.9244 - val_loss: 0.7703 - val_accuracy: 0.7111 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1157 - accuracy: 0.9419\n",
            "Epoch 7: val_accuracy improved from 0.71111 to 0.76667, saving model to  Kmodel16_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi1.h5 /assets\n",
            "22/22 [==============================] - 206s 9s/step - loss: 0.1157 - accuracy: 0.9419 - val_loss: 0.7463 - val_accuracy: 0.7667 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1382 - accuracy: 0.9244\n",
            "Epoch 8: val_accuracy did not improve from 0.76667\n",
            "22/22 [==============================] - 178s 8s/step - loss: 0.1382 - accuracy: 0.9244 - val_loss: 0.7506 - val_accuracy: 0.7111 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.9651\n",
            "Epoch 9: val_accuracy did not improve from 0.76667\n",
            "22/22 [==============================] - 176s 8s/step - loss: 0.0633 - accuracy: 0.9651 - val_loss: 1.0351 - val_accuracy: 0.7444 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 0.9535\n",
            "Epoch 10: val_accuracy did not improve from 0.76667\n",
            "22/22 [==============================] - 175s 8s/step - loss: 0.0983 - accuracy: 0.9535 - val_loss: 0.8169 - val_accuracy: 0.7444 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9564\n",
            "Epoch 11: val_accuracy improved from 0.76667 to 0.77778, saving model to  Kmodel16_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi1.h5 /assets\n",
            "22/22 [==============================] - 206s 9s/step - loss: 0.0680 - accuracy: 0.9564 - val_loss: 0.7305 - val_accuracy: 0.7778 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0579 - accuracy: 0.9767\n",
            "Epoch 12: val_accuracy did not improve from 0.77778\n",
            "22/22 [==============================] - 177s 8s/step - loss: 0.0579 - accuracy: 0.9767 - val_loss: 0.9532 - val_accuracy: 0.7111 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9826\n",
            "Epoch 13: val_accuracy improved from 0.77778 to 0.83333, saving model to  Kmodel16_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi1.h5 /assets\n",
            "22/22 [==============================] - 209s 10s/step - loss: 0.0351 - accuracy: 0.9826 - val_loss: 0.5902 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.9709\n",
            "Epoch 14: val_accuracy did not improve from 0.83333\n",
            "22/22 [==============================] - 176s 8s/step - loss: 0.0454 - accuracy: 0.9709 - val_loss: 0.6669 - val_accuracy: 0.7556 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9709\n",
            "Epoch 15: val_accuracy improved from 0.83333 to 0.85556, saving model to  Kmodel16_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi1.h5 /assets\n",
            "22/22 [==============================] - 206s 9s/step - loss: 0.0537 - accuracy: 0.9709 - val_loss: 0.4069 - val_accuracy: 0.8556 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9855\n",
            "Epoch 16: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 175s 8s/step - loss: 0.0581 - accuracy: 0.9855 - val_loss: 0.4812 - val_accuracy: 0.8222 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9913\n",
            "Epoch 17: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 176s 8s/step - loss: 0.0292 - accuracy: 0.9913 - val_loss: 0.9138 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.9709\n",
            "Epoch 18: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 177s 8s/step - loss: 0.0601 - accuracy: 0.9709 - val_loss: 1.1632 - val_accuracy: 0.6333 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.9855\n",
            "Epoch 19: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 182s 8s/step - loss: 0.0305 - accuracy: 0.9855 - val_loss: 1.2841 - val_accuracy: 0.6333 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.9535\n",
            "Epoch 20: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 185s 8s/step - loss: 0.0706 - accuracy: 0.9535 - val_loss: 0.3794 - val_accuracy: 0.8111 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.9709\n",
            "Epoch 21: val_accuracy did not improve from 0.85556\n",
            "\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "22/22 [==============================] - 182s 8s/step - loss: 0.0500 - accuracy: 0.9709 - val_loss: 0.8250 - val_accuracy: 0.7222 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0441 - accuracy: 0.9797\n",
            "Epoch 22: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 177s 8s/step - loss: 0.0441 - accuracy: 0.9797 - val_loss: 0.6373 - val_accuracy: 0.7222 - lr: 5.0000e-05\n",
            "Epoch 23/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9884\n",
            "Epoch 23: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 177s 8s/step - loss: 0.0288 - accuracy: 0.9884 - val_loss: 0.5780 - val_accuracy: 0.7778 - lr: 5.0000e-05\n",
            "Epoch 24/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9913\n",
            "Epoch 24: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 176s 8s/step - loss: 0.0187 - accuracy: 0.9913 - val_loss: 0.7870 - val_accuracy: 0.7333 - lr: 5.0000e-05\n",
            "Epoch 25/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9913\n",
            "Epoch 25: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 175s 8s/step - loss: 0.0150 - accuracy: 0.9913 - val_loss: 0.7849 - val_accuracy: 0.7222 - lr: 5.0000e-05\n",
            "Epoch 26/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9972\n",
            "Epoch 26: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 179s 8s/step - loss: 0.0134 - accuracy: 0.9972 - val_loss: 1.2737 - val_accuracy: 0.6778 - lr: 5.0000e-05\n",
            "Epoch 27/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9942\n",
            "Epoch 27: val_accuracy did not improve from 0.85556\n",
            "\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "22/22 [==============================] - 175s 8s/step - loss: 0.0131 - accuracy: 0.9942 - val_loss: 1.5037 - val_accuracy: 0.6333 - lr: 5.0000e-05\n",
            "Epoch 28/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9942\n",
            "Epoch 28: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 175s 8s/step - loss: 0.0221 - accuracy: 0.9942 - val_loss: 1.1743 - val_accuracy: 0.6667 - lr: 2.5000e-05\n",
            "Epoch 29/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9971\n",
            "Epoch 29: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 174s 8s/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 1.0045 - val_accuracy: 0.6889 - lr: 2.5000e-05\n",
            "Epoch 30/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9913\n",
            "Epoch 30: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 175s 8s/step - loss: 0.0165 - accuracy: 0.9913 - val_loss: 0.8076 - val_accuracy: 0.7111 - lr: 2.5000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.36      0.53        28\n",
            "      Normal       0.83      0.81      0.82        31\n",
            "Tuberculosis       0.58      0.94      0.72        31\n",
            "\n",
            "    accuracy                           0.71        90\n",
            "   macro avg       0.80      0.70      0.69        90\n",
            "weighted avg       0.80      0.71      0.69        90\n",
            "\n",
            "Fold #2\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1146 - accuracy: 0.9535\n",
            "Epoch 1: val_accuracy improved from -inf to 0.98889, saving model to  Kmodel16_soft_pre_bi2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi2.h5 /assets\n",
            "22/22 [==============================] - 203s 9s/step - loss: 0.1146 - accuracy: 0.9535 - val_loss: 0.0100 - val_accuracy: 0.9889 - lr: 2.5000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9738\n",
            "Epoch 2: val_accuracy improved from 0.98889 to 1.00000, saving model to  Kmodel16_soft_pre_bi2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi2.h5 /assets\n",
            "22/22 [==============================] - 203s 9s/step - loss: 0.0487 - accuracy: 0.9738 - val_loss: 0.0014 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0524 - accuracy: 0.9709\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0524 - accuracy: 0.9709 - val_loss: 3.8147e-04 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9826\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0236 - accuracy: 0.9826 - val_loss: 0.0016 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9886\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 176s 8s/step - loss: 0.0209 - accuracy: 0.9886 - val_loss: 8.1388e-04 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9913\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0235 - accuracy: 0.9913 - val_loss: 0.0078 - val_accuracy: 0.9889 - lr: 2.5000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9889 - lr: 2.5000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9738\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0459 - accuracy: 0.9738 - val_loss: 0.0081 - val_accuracy: 0.9889 - lr: 2.5000e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9884\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0273 - accuracy: 0.9884 - val_loss: 0.0130 - val_accuracy: 0.9889 - lr: 1.2500e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9913\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0222 - accuracy: 0.9913 - val_loss: 0.0138 - val_accuracy: 0.9889 - lr: 1.2500e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 0.9855\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0315 - accuracy: 0.9855 - val_loss: 0.0216 - val_accuracy: 0.9889 - lr: 1.2500e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9971\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0081 - accuracy: 0.9971 - val_loss: 0.0327 - val_accuracy: 0.9889 - lr: 1.2500e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9913\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0153 - accuracy: 0.9913 - val_loss: 0.0377 - val_accuracy: 0.9889 - lr: 1.2500e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9971\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.0401 - val_accuracy: 0.9889 - lr: 1.2500e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9942\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0200 - accuracy: 0.9942 - val_loss: 0.0504 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9971\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0078 - accuracy: 0.9971 - val_loss: 0.0691 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.88      0.94        34\n",
            "      Normal       1.00      1.00      1.00        27\n",
            "Tuberculosis       0.88      1.00      0.94        29\n",
            "\n",
            "    accuracy                           0.96        90\n",
            "   macro avg       0.96      0.96      0.96        90\n",
            "weighted avg       0.96      0.96      0.96        90\n",
            "\n",
            "Fold #3\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9884\n",
            "Epoch 1: val_accuracy improved from -inf to 0.97778, saving model to  Kmodel16_soft_pre_bi3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi3.h5 /assets\n",
            "22/22 [==============================] - 203s 9s/step - loss: 0.0260 - accuracy: 0.9884 - val_loss: 0.0388 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9942\n",
            "Epoch 2: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0153 - accuracy: 0.9942 - val_loss: 0.0930 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9971\n",
            "Epoch 3: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 174s 8s/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.1105 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000\n",
            "Epoch 4: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9942\n",
            "Epoch 5: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 182s 8s/step - loss: 0.0125 - accuracy: 0.9942 - val_loss: 0.1297 - val_accuracy: 0.9111 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 194s 9s/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9855\n",
            "Epoch 7: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 187s 9s/step - loss: 0.0332 - accuracy: 0.9855 - val_loss: 0.0696 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9942\n",
            "Epoch 8: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 192s 9s/step - loss: 0.0103 - accuracy: 0.9942 - val_loss: 0.0523 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9942\n",
            "Epoch 9: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 187s 9s/step - loss: 0.0086 - accuracy: 0.9942 - val_loss: 0.1190 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9971\n",
            "Epoch 10: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 187s 8s/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.0876 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9913\n",
            "Epoch 11: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 187s 8s/step - loss: 0.0164 - accuracy: 0.9913 - val_loss: 0.1074 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9971\n",
            "Epoch 12: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 185s 8s/step - loss: 0.0055 - accuracy: 0.9971 - val_loss: 0.0755 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9971\n",
            "Epoch 13: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 184s 8s/step - loss: 0.0071 - accuracy: 0.9971 - val_loss: 0.0917 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9971\n",
            "Epoch 14: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 187s 8s/step - loss: 0.0055 - accuracy: 0.9971 - val_loss: 0.1051 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 187s 8s/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0719 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9971\n",
            "Epoch 16: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 182s 8s/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.1134 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.81      0.90        27\n",
            "      Normal       1.00      0.97      0.98        33\n",
            "Tuberculosis       0.83      1.00      0.91        30\n",
            "\n",
            "    accuracy                           0.93        90\n",
            "   macro avg       0.94      0.93      0.93        90\n",
            "weighted avg       0.94      0.93      0.93        90\n",
            "\n",
            "Fold #4\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 1: val_accuracy improved from -inf to 1.00000, saving model to  Kmodel16_soft_pre_bi4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi4.h5 /assets\n",
            "22/22 [==============================] - 203s 9s/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9971\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.0288 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9971\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0050 - accuracy: 0.9971 - val_loss: 0.0412 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9972\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 175s 8s/step - loss: 0.0064 - accuracy: 0.9972 - val_loss: 0.0233 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 174s 8s/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9971\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 174s 8s/step - loss: 0.0064 - accuracy: 0.9971 - val_loss: 0.0215 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9971\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0066 - accuracy: 0.9971 - val_loss: 0.0447 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9942\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0070 - accuracy: 0.9942 - val_loss: 0.0402 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9943\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 175s 8s/step - loss: 0.0106 - accuracy: 0.9943 - val_loss: 0.0274 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9943\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 175s 8s/step - loss: 0.0109 - accuracy: 0.9943 - val_loss: 0.0255 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9971\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0063 - accuracy: 0.9971 - val_loss: 0.0496 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9971\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0061 - accuracy: 0.9971 - val_loss: 0.0436 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.97      0.98        30\n",
            "      Normal       1.00      0.97      0.98        31\n",
            "Tuberculosis       0.94      1.00      0.97        29\n",
            "\n",
            "    accuracy                           0.98        90\n",
            "   macro avg       0.98      0.98      0.98        90\n",
            "weighted avg       0.98      0.98      0.98        90\n",
            "\n",
            "Fold #5\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 1: val_accuracy improved from -inf to 0.97778, saving model to  Kmodel16_soft_pre_bi5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi5.h5 /assets\n",
            "22/22 [==============================] - 202s 9s/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9971\n",
            "Epoch 2: val_accuracy improved from 0.97778 to 0.98889, saving model to  Kmodel16_soft_pre_bi5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi5.h5 /assets\n",
            "22/22 [==============================] - 201s 9s/step - loss: 0.0079 - accuracy: 0.9971 - val_loss: 0.0146 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9971\n",
            "Epoch 3: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0049 - accuracy: 0.9971 - val_loss: 0.0164 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9971\n",
            "Epoch 4: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0043 - accuracy: 0.9971 - val_loss: 0.0158 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 5: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9971\n",
            "Epoch 6: val_accuracy improved from 0.98889 to 1.00000, saving model to  Kmodel16_soft_pre_bi5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi5.h5 /assets\n",
            "22/22 [==============================] - 201s 9s/step - loss: 0.0057 - accuracy: 0.9971 - val_loss: 0.0124 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9972\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 176s 8s/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0101 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9971\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0044 - accuracy: 0.9971 - val_loss: 0.0043 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 174s 8s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 176s 8s/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 183s 9s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 183s 8s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9971\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 182s 8s/step - loss: 0.0074 - accuracy: 0.9971 - val_loss: 0.0012 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 175s 8s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 178s 8s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 175s 8s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 178s 8s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 174s 8s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 180s 8s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      1.00      1.00        31\n",
            "      Normal       1.00      1.00      1.00        28\n",
            "Tuberculosis       1.00      1.00      1.00        31\n",
            "\n",
            "    accuracy                           1.00        90\n",
            "   macro avg       1.00      1.00      1.00        90\n",
            "weighted avg       1.00      1.00      1.00        90\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.81      0.90       150\n",
            "      Normal       0.97      0.95      0.96       150\n",
            "Tuberculosis       0.82      0.99      0.89       150\n",
            "\n",
            "    accuracy                           0.92       450\n",
            "   macro avg       0.93      0.92      0.92       450\n",
            "weighted avg       0.93      0.92      0.92       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 16 soft pre bi adam  \n"
      ],
      "metadata": {
        "id": "2hRe1jTCREHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 16\n",
        "filepath = \"Kmodel16_soft_pre_bi_adam.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45a25858-463b-4866-fabd-c3bc0859732b",
        "id": "UDNgWM_ZREHq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [02:11<00:00,  3.43it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel16_soft_pre_bi_adam{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "OoraKn4qREHr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d14c40c7-d3d2-4356-a9e9-9d76520308e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold #1\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.5259 - accuracy: 0.6335\n",
            "Epoch 1: val_accuracy improved from -inf to 0.40000, saving model to  Kmodel16_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_adam1.h5 /assets\n",
            "22/22 [==============================] - 57s 2s/step - loss: 0.5259 - accuracy: 0.6335 - val_loss: 0.9410 - val_accuracy: 0.4000 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.3359 - accuracy: 0.7791\n",
            "Epoch 2: val_accuracy improved from 0.40000 to 0.47778, saving model to  Kmodel16_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_adam1.h5 /assets\n",
            "22/22 [==============================] - 49s 2s/step - loss: 0.3359 - accuracy: 0.7791 - val_loss: 1.1569 - val_accuracy: 0.4778 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.2637 - accuracy: 0.8401\n",
            "Epoch 3: val_accuracy improved from 0.47778 to 0.63333, saving model to  Kmodel16_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_adam1.h5 /assets\n",
            "22/22 [==============================] - 47s 2s/step - loss: 0.2637 - accuracy: 0.8401 - val_loss: 0.6881 - val_accuracy: 0.6333 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1774 - accuracy: 0.9091\n",
            "Epoch 4: val_accuracy did not improve from 0.63333\n",
            "22/22 [==============================] - 11s 483ms/step - loss: 0.1774 - accuracy: 0.9091 - val_loss: 0.6700 - val_accuracy: 0.6333 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1393 - accuracy: 0.9403\n",
            "Epoch 5: val_accuracy did not improve from 0.63333\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.1393 - accuracy: 0.9403 - val_loss: 0.8650 - val_accuracy: 0.6222 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1489 - accuracy: 0.9390\n",
            "Epoch 6: val_accuracy improved from 0.63333 to 0.74444, saving model to  Kmodel16_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_adam1.h5 /assets\n",
            "22/22 [==============================] - 48s 2s/step - loss: 0.1489 - accuracy: 0.9390 - val_loss: 0.6166 - val_accuracy: 0.7444 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0996 - accuracy: 0.9448\n",
            "Epoch 7: val_accuracy did not improve from 0.74444\n",
            "22/22 [==============================] - 11s 472ms/step - loss: 0.0996 - accuracy: 0.9448 - val_loss: 0.5960 - val_accuracy: 0.7111 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.9477\n",
            "Epoch 8: val_accuracy did not improve from 0.74444\n",
            "22/22 [==============================] - 10s 469ms/step - loss: 0.0790 - accuracy: 0.9477 - val_loss: 0.6190 - val_accuracy: 0.7444 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.9651\n",
            "Epoch 9: val_accuracy did not improve from 0.74444\n",
            "22/22 [==============================] - 10s 469ms/step - loss: 0.0695 - accuracy: 0.9651 - val_loss: 0.5351 - val_accuracy: 0.7444 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0996 - accuracy: 0.9360\n",
            "Epoch 10: val_accuracy did not improve from 0.74444\n",
            "22/22 [==============================] - 11s 475ms/step - loss: 0.0996 - accuracy: 0.9360 - val_loss: 1.1618 - val_accuracy: 0.6778 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0720 - accuracy: 0.9593\n",
            "Epoch 11: val_accuracy did not improve from 0.74444\n",
            "22/22 [==============================] - 11s 473ms/step - loss: 0.0720 - accuracy: 0.9593 - val_loss: 0.8025 - val_accuracy: 0.7111 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.9680\n",
            "Epoch 12: val_accuracy improved from 0.74444 to 0.75556, saving model to  Kmodel16_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_adam1.h5 /assets\n",
            "22/22 [==============================] - 49s 2s/step - loss: 0.0598 - accuracy: 0.9680 - val_loss: 0.4558 - val_accuracy: 0.7556 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9738\n",
            "Epoch 13: val_accuracy did not improve from 0.75556\n",
            "22/22 [==============================] - 11s 476ms/step - loss: 0.0577 - accuracy: 0.9738 - val_loss: 0.7550 - val_accuracy: 0.7556 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 0.9884\n",
            "Epoch 14: val_accuracy improved from 0.75556 to 0.81111, saving model to  Kmodel16_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_adam1.h5 /assets\n",
            "22/22 [==============================] - 47s 2s/step - loss: 0.0297 - accuracy: 0.9884 - val_loss: 0.5964 - val_accuracy: 0.8111 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.9767\n",
            "Epoch 15: val_accuracy improved from 0.81111 to 0.86667, saving model to  Kmodel16_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_adam1.h5 /assets\n",
            "22/22 [==============================] - 45s 2s/step - loss: 0.0433 - accuracy: 0.9767 - val_loss: 0.2795 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9855\n",
            "Epoch 16: val_accuracy did not improve from 0.86667\n",
            "22/22 [==============================] - 10s 466ms/step - loss: 0.0342 - accuracy: 0.9855 - val_loss: 0.9066 - val_accuracy: 0.7111 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9680\n",
            "Epoch 17: val_accuracy did not improve from 0.86667\n",
            "22/22 [==============================] - 11s 471ms/step - loss: 0.0555 - accuracy: 0.9680 - val_loss: 0.9911 - val_accuracy: 0.6778 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0662 - accuracy: 0.9622\n",
            "Epoch 18: val_accuracy did not improve from 0.86667\n",
            "22/22 [==============================] - 11s 469ms/step - loss: 0.0662 - accuracy: 0.9622 - val_loss: 0.5961 - val_accuracy: 0.7111 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.9886\n",
            "Epoch 19: val_accuracy did not improve from 0.86667\n",
            "22/22 [==============================] - 11s 470ms/step - loss: 0.0388 - accuracy: 0.9886 - val_loss: 0.7913 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.9797\n",
            "Epoch 20: val_accuracy improved from 0.86667 to 0.92222, saving model to  Kmodel16_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_adam1.h5 /assets\n",
            "22/22 [==============================] - 47s 2s/step - loss: 0.0385 - accuracy: 0.9797 - val_loss: 0.2232 - val_accuracy: 0.9222 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9884\n",
            "Epoch 21: val_accuracy did not improve from 0.92222\n",
            "22/22 [==============================] - 10s 465ms/step - loss: 0.0337 - accuracy: 0.9884 - val_loss: 0.2427 - val_accuracy: 0.8778 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0640 - accuracy: 0.9680\n",
            "Epoch 22: val_accuracy did not improve from 0.92222\n",
            "22/22 [==============================] - 10s 464ms/step - loss: 0.0640 - accuracy: 0.9680 - val_loss: 1.2457 - val_accuracy: 0.6778 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.9622\n",
            "Epoch 23: val_accuracy did not improve from 0.92222\n",
            "22/22 [==============================] - 11s 473ms/step - loss: 0.0897 - accuracy: 0.9622 - val_loss: 0.9135 - val_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0762 - accuracy: 0.9709\n",
            "Epoch 24: val_accuracy did not improve from 0.92222\n",
            "22/22 [==============================] - 11s 475ms/step - loss: 0.0762 - accuracy: 0.9709 - val_loss: 0.3472 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 0.9767\n",
            "Epoch 25: val_accuracy did not improve from 0.92222\n",
            "22/22 [==============================] - 11s 470ms/step - loss: 0.0475 - accuracy: 0.9767 - val_loss: 0.3843 - val_accuracy: 0.8222 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9884\n",
            "Epoch 26: val_accuracy did not improve from 0.92222\n",
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "22/22 [==============================] - 11s 468ms/step - loss: 0.0303 - accuracy: 0.9884 - val_loss: 0.8012 - val_accuracy: 0.7222 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9797\n",
            "Epoch 27: val_accuracy did not improve from 0.92222\n",
            "22/22 [==============================] - 11s 471ms/step - loss: 0.0437 - accuracy: 0.9797 - val_loss: 0.6561 - val_accuracy: 0.7444 - lr: 5.0000e-05\n",
            "Epoch 28/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9942\n",
            "Epoch 28: val_accuracy did not improve from 0.92222\n",
            "22/22 [==============================] - 11s 470ms/step - loss: 0.0218 - accuracy: 0.9942 - val_loss: 0.5739 - val_accuracy: 0.7778 - lr: 5.0000e-05\n",
            "Epoch 29/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9942\n",
            "Epoch 29: val_accuracy did not improve from 0.92222\n",
            "22/22 [==============================] - 11s 468ms/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.5362 - val_accuracy: 0.8000 - lr: 5.0000e-05\n",
            "Epoch 30/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.92222\n",
            "22/22 [==============================] - 11s 474ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.5462 - val_accuracy: 0.7778 - lr: 5.0000e-05\n",
            "Epoch 31/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9971\n",
            "Epoch 31: val_accuracy did not improve from 0.92222\n",
            "22/22 [==============================] - 11s 470ms/step - loss: 0.0115 - accuracy: 0.9971 - val_loss: 0.6847 - val_accuracy: 0.7667 - lr: 5.0000e-05\n",
            "Epoch 32/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9942\n",
            "Epoch 32: val_accuracy did not improve from 0.92222\n",
            "\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "22/22 [==============================] - 10s 467ms/step - loss: 0.0145 - accuracy: 0.9942 - val_loss: 0.5828 - val_accuracy: 0.8000 - lr: 5.0000e-05\n",
            "Epoch 33/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9971\n",
            "Epoch 33: val_accuracy did not improve from 0.92222\n",
            "22/22 [==============================] - 10s 468ms/step - loss: 0.0125 - accuracy: 0.9971 - val_loss: 0.5153 - val_accuracy: 0.8111 - lr: 2.5000e-05\n",
            "Epoch 34/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.9913\n",
            "Epoch 34: val_accuracy did not improve from 0.92222\n",
            "22/22 [==============================] - 10s 467ms/step - loss: 0.0233 - accuracy: 0.9913 - val_loss: 0.5020 - val_accuracy: 0.8111 - lr: 2.5000e-05\n",
            "Epoch 35/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9971\n",
            "Epoch 35: val_accuracy did not improve from 0.92222\n",
            "22/22 [==============================] - 11s 470ms/step - loss: 0.0123 - accuracy: 0.9971 - val_loss: 0.5433 - val_accuracy: 0.8000 - lr: 2.5000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.61      0.76        28\n",
            "      Normal       0.96      0.77      0.86        31\n",
            "Tuberculosis       0.65      1.00      0.78        31\n",
            "\n",
            "    accuracy                           0.80        90\n",
            "   macro avg       0.87      0.79      0.80        90\n",
            "weighted avg       0.86      0.80      0.80        90\n",
            "\n",
            "Fold #2\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0849 - accuracy: 0.9535\n",
            "Epoch 1: val_accuracy improved from -inf to 1.00000, saving model to  Kmodel16_soft_pre_bi_adam2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_adam2.h5 /assets\n",
            "22/22 [==============================] - 50s 2s/step - loss: 0.0849 - accuracy: 0.9535 - val_loss: 0.0180 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.9767\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 491ms/step - loss: 0.0388 - accuracy: 0.9767 - val_loss: 0.0150 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 0.9855\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 500ms/step - loss: 0.0402 - accuracy: 0.9855 - val_loss: 0.0256 - val_accuracy: 0.9889 - lr: 2.5000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9709\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 483ms/step - loss: 0.0496 - accuracy: 0.9709 - val_loss: 0.0401 - val_accuracy: 0.9778 - lr: 2.5000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9855\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 0.0341 - accuracy: 0.9855 - val_loss: 0.0436 - val_accuracy: 0.9889 - lr: 2.5000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9884\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 470ms/step - loss: 0.0237 - accuracy: 0.9884 - val_loss: 0.0310 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9971\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "22/22 [==============================] - 11s 472ms/step - loss: 0.0120 - accuracy: 0.9971 - val_loss: 0.0241 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9913\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 470ms/step - loss: 0.0238 - accuracy: 0.9913 - val_loss: 0.0281 - val_accuracy: 1.0000 - lr: 1.2500e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9971\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 10s 466ms/step - loss: 0.0163 - accuracy: 0.9971 - val_loss: 0.0380 - val_accuracy: 0.9889 - lr: 1.2500e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9971\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 468ms/step - loss: 0.0121 - accuracy: 0.9971 - val_loss: 0.0534 - val_accuracy: 0.9889 - lr: 1.2500e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9913\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 470ms/step - loss: 0.0163 - accuracy: 0.9913 - val_loss: 0.0557 - val_accuracy: 0.9778 - lr: 1.2500e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9971\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 502ms/step - loss: 0.0187 - accuracy: 0.9971 - val_loss: 0.0445 - val_accuracy: 0.9889 - lr: 1.2500e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9971\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "22/22 [==============================] - 11s 513ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.0299 - val_accuracy: 1.0000 - lr: 1.2500e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9738\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 505ms/step - loss: 0.0544 - accuracy: 0.9738 - val_loss: 0.0438 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9971\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 10s 467ms/step - loss: 0.0117 - accuracy: 0.9971 - val_loss: 0.0703 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9971\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 472ms/step - loss: 0.0112 - accuracy: 0.9971 - val_loss: 0.0778 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.79      0.89        34\n",
            "      Normal       1.00      1.00      1.00        27\n",
            "Tuberculosis       0.81      1.00      0.89        29\n",
            "\n",
            "    accuracy                           0.92        90\n",
            "   macro avg       0.94      0.93      0.93        90\n",
            "weighted avg       0.94      0.92      0.92        90\n",
            "\n",
            "Fold #3\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9942\n",
            "Epoch 1: val_accuracy improved from -inf to 0.94444, saving model to  Kmodel16_soft_pre_bi_adam3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_adam3.h5 /assets\n",
            "22/22 [==============================] - 47s 2s/step - loss: 0.0101 - accuracy: 0.9942 - val_loss: 0.0936 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 1.0000\n",
            "Epoch 2: val_accuracy did not improve from 0.94444\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0905 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9971\n",
            "Epoch 3: val_accuracy did not improve from 0.94444\n",
            "22/22 [==============================] - 11s 490ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.0808 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9913\n",
            "Epoch 4: val_accuracy did not improve from 0.94444\n",
            "22/22 [==============================] - 11s 500ms/step - loss: 0.0177 - accuracy: 0.9913 - val_loss: 0.0799 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9942\n",
            "Epoch 5: val_accuracy did not improve from 0.94444\n",
            "22/22 [==============================] - 11s 503ms/step - loss: 0.0111 - accuracy: 0.9942 - val_loss: 0.0836 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy did not improve from 0.94444\n",
            "22/22 [==============================] - 11s 502ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9971\n",
            "Epoch 7: val_accuracy did not improve from 0.94444\n",
            "22/22 [==============================] - 11s 477ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.1119 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9971\n",
            "Epoch 8: val_accuracy did not improve from 0.94444\n",
            "22/22 [==============================] - 11s 466ms/step - loss: 0.0114 - accuracy: 0.9971 - val_loss: 0.1351 - val_accuracy: 0.9111 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9913\n",
            "Epoch 9: val_accuracy did not improve from 0.94444\n",
            "22/22 [==============================] - 10s 467ms/step - loss: 0.0168 - accuracy: 0.9913 - val_loss: 0.1491 - val_accuracy: 0.9000 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9855\n",
            "Epoch 10: val_accuracy did not improve from 0.94444\n",
            "22/22 [==============================] - 10s 468ms/step - loss: 0.0316 - accuracy: 0.9855 - val_loss: 0.1121 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9942\n",
            "Epoch 11: val_accuracy did not improve from 0.94444\n",
            "22/22 [==============================] - 10s 469ms/step - loss: 0.0122 - accuracy: 0.9942 - val_loss: 0.1199 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.94444\n",
            "22/22 [==============================] - 10s 465ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9972\n",
            "Epoch 13: val_accuracy did not improve from 0.94444\n",
            "22/22 [==============================] - 11s 474ms/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.1270 - val_accuracy: 0.9111 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9971\n",
            "Epoch 14: val_accuracy did not improve from 0.94444\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.1346 - val_accuracy: 0.9000 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9971\n",
            "Epoch 15: val_accuracy did not improve from 0.94444\n",
            "22/22 [==============================] - 11s 468ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.1204 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9942\n",
            "Epoch 16: val_accuracy did not improve from 0.94444\n",
            "22/22 [==============================] - 10s 469ms/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.1174 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.74      0.85        27\n",
            "      Normal       1.00      1.00      1.00        33\n",
            "Tuberculosis       0.81      1.00      0.90        30\n",
            "\n",
            "    accuracy                           0.92        90\n",
            "   macro avg       0.94      0.91      0.92        90\n",
            "weighted avg       0.94      0.92      0.92        90\n",
            "\n",
            "Fold #4\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9971\n",
            "Epoch 1: val_accuracy improved from -inf to 0.96667, saving model to  Kmodel16_soft_pre_bi_adam4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_adam4.h5 /assets\n",
            "22/22 [==============================] - 51s 2s/step - loss: 0.0120 - accuracy: 0.9971 - val_loss: 0.0370 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9942\n",
            "Epoch 2: val_accuracy improved from 0.96667 to 0.97778, saving model to  Kmodel16_soft_pre_bi_adam4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_adam4.h5 /assets\n",
            "22/22 [==============================] - 50s 2s/step - loss: 0.0102 - accuracy: 0.9942 - val_loss: 0.0400 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9942\n",
            "Epoch 3: val_accuracy improved from 0.97778 to 1.00000, saving model to  Kmodel16_soft_pre_bi_adam4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_adam4.h5 /assets\n",
            "22/22 [==============================] - 46s 2s/step - loss: 0.0139 - accuracy: 0.9942 - val_loss: 0.0298 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0259 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9971\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 480ms/step - loss: 0.0113 - accuracy: 0.9971 - val_loss: 0.0202 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9971\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 477ms/step - loss: 0.0073 - accuracy: 0.9971 - val_loss: 0.0174 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9913\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 10s 466ms/step - loss: 0.0187 - accuracy: 0.9913 - val_loss: 0.0087 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 471ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 484ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 477ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 477ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9971\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 467ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.0174 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9942\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 10s 479ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.0213 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9971\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 482ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 0.0286 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 10s 465ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9971\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 472ms/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 0.0528 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 472ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 11s 472ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      1.00      1.00        30\n",
            "      Normal       1.00      1.00      1.00        31\n",
            "Tuberculosis       1.00      1.00      1.00        29\n",
            "\n",
            "    accuracy                           1.00        90\n",
            "   macro avg       1.00      1.00      1.00        90\n",
            "weighted avg       1.00      1.00      1.00        90\n",
            "\n",
            "Fold #5\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9971\n",
            "Epoch 1: val_accuracy improved from -inf to 0.98889, saving model to  Kmodel16_soft_pre_bi_adam5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_adam5.h5 /assets\n",
            "22/22 [==============================] - 50s 2s/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 0.0240 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9971\n",
            "Epoch 2: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 473ms/step - loss: 0.0181 - accuracy: 0.9971 - val_loss: 0.0311 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9971\n",
            "Epoch 3: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 481ms/step - loss: 0.0126 - accuracy: 0.9971 - val_loss: 0.0303 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 1.0000\n",
            "Epoch 4: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 466ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 5: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 474ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9971\n",
            "Epoch 6: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 10s 469ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 0.0355 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 471ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 470ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 474ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9971\n",
            "Epoch 10: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 485ms/step - loss: 0.0052 - accuracy: 0.9971 - val_loss: 0.0463 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9971\n",
            "Epoch 11: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 488ms/step - loss: 0.0067 - accuracy: 0.9971 - val_loss: 0.0406 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 489ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9971\n",
            "Epoch 13: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 478ms/step - loss: 0.0060 - accuracy: 0.9971 - val_loss: 0.0305 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 473ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9971\n",
            "Epoch 15: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 473ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.0386 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 11s 472ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.90      0.95        31\n",
            "      Normal       1.00      1.00      1.00        28\n",
            "Tuberculosis       0.91      1.00      0.95        31\n",
            "\n",
            "    accuracy                           0.97        90\n",
            "   macro avg       0.97      0.97      0.97        90\n",
            "weighted avg       0.97      0.97      0.97        90\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.81      0.90       150\n",
            "      Normal       0.99      0.95      0.97       150\n",
            "Tuberculosis       0.82      1.00      0.90       150\n",
            "\n",
            "    accuracy                           0.92       450\n",
            "   macro avg       0.94      0.92      0.92       450\n",
            "weighted avg       0.94      0.92      0.92       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 16 soft pre bi sgd  \n"
      ],
      "metadata": {
        "id": "oiU4sPwaREHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 16\n",
        "filepath = \"Kmodel16_soft_pre_bi_sgd.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b03506-eddb-4c17-f5fe-976c247895dd",
        "id": "Wd75Y7DjREHr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:06<00:00, 66.43it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel16_soft_pre_bi_sgd{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "vc536jz1REHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 16 soft pre cate \n"
      ],
      "metadata": {
        "id": "2nwMmcCSREHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 16\n",
        "filepath = \"Kmodel16_soft_pre_cate.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "8f62ba84-295e-4d23-a2f7-57bc97196ed3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hMfVEfpREHt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:10<00:00, 41.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel16_soft_pre_cate{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "re6ML_NsREHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####16 soft pre cate adam\n"
      ],
      "metadata": {
        "id": "V1-B4YN5REHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 16                                                       ##\n",
        "filepath = \"Kmodel16_soft_pre_cate_adam.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "4ade8ad3-0a08-4391-b9cc-b535897670e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkxTvAKFREHu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:04<00:00, 92.81it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel16_soft_pre_cate_adam{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "bRGqY3paREHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 16 soft pre cate sgd\n"
      ],
      "metadata": {
        "id": "b3TXk6OsREHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 16                                                       ##\n",
        "filepath = \"Kmodel16_soft_pre_cate_sgd.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "4ade8ad3-0a08-4391-b9cc-b535897670e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFF_2ASxREHv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:04<00:00, 92.81it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel16_soft_pre_cate_sgd{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "elc3h1RWREHv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "fb733fbd-1204-43f3-f6bc-ad687bd8f59a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "87924736/87910968 [==============================] - 1s 0us/step\n",
            "Fold #1\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 1.1461 - accuracy: 0.2849\n",
            "Epoch 1: val_accuracy improved from -inf to 0.34444, saving model to  Kmodel16_soft_pre_cate_sgd1.h5 \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-84214e01e06e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m                                                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_Incep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_Incep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                                                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_Incep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mpred_Incep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_Incep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_Incep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1435\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1436\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_should_save_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[0;34m(self, epoch, batch, logs)\u001b[0m\n\u001b[1;32m   1441\u001b[0m                     filepath, overwrite=True, options=self._options)\n\u001b[1;32m   1442\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1444\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m   2383\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 2385\u001b[0;31m                     signatures, options, save_traces)\n\u001b[0m\u001b[1;32m   2386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtraceback_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSharedObjectSavingScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m       saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[0;32m--> 152\u001b[0;31m                             signatures, options, save_traces)\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_option_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_traces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m       saved_nodes, node_paths = save_lib.save_and_return_nodes(\n\u001b[0;32m---> 94\u001b[0;31m           model, filepath, signatures, options)\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# Save all metadata to a separate file in the SavedModel directory.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m   _, exported_graph, object_saver, asset_info, saved_nodes, node_paths = (\n\u001b[0;32m-> 1369\u001b[0;31m       _build_meta_graph(obj, signatures, options, meta_graph_def))\n\u001b[0m\u001b[1;32m   1370\u001b[0m   saved_model.saved_model_schema_version = (\n\u001b[1;32m   1371\u001b[0m       constants.SAVED_MODEL_SCHEMA_VERSION)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0msave_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1536\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_build_meta_graph_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1476\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msignatures\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m     signatures = signature_serialization.find_function_to_export(\n\u001b[0;32m-> 1478\u001b[0;31m         checkpoint_graph_view)\n\u001b[0m\u001b[1;32m   1479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m   signatures, wrapped_functions = (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/signature_serialization.py\u001b[0m in \u001b[0;36mfind_function_to_export\u001b[0;34m(saveable_view)\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0;31m# serving that model way later in the process stops working.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0mpossible_signatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdef_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConcreteFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36mlist_children\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    134\u001b[0m               \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m               \u001b[0msave_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaveType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVEDMODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m               cache=self._serialization_cache))\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_children_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m       \u001b[0;32myield\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackableReference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/graph_view.py\u001b[0m in \u001b[0;36mlist_children\u001b[0;34m(self, obj, save_type, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     children = [base.TrackableReference(name, ref) for name, ref\n\u001b[0;32m--> 256\u001b[0;31m                 in obj._trackable_children(save_type, **kwargs).items()]\n\u001b[0m\u001b[1;32m    257\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_trackable_children\u001b[0;34m(self, save_type, **kwargs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msave_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSaveType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVEDMODEL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m       \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cache\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_legacy_saved_model_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1480\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m       raise ValueError(\"Unexpected format passed to `_trackable_children`. \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_get_legacy_saved_model_children\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m     \u001b[0;31m# Retrieve functions attached to the object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1490\u001b[0;31m     \u001b[0mfunctions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_functions_for_serialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m     \u001b[0;31m# Trace concrete functions to force side-effects:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_list_functions_for_serialization\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m   3080\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_tf_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m     functions = super(\n\u001b[0;32m-> 3082\u001b[0;31m         Model, self)._list_functions_for_serialization(serialization_cache)\n\u001b[0m\u001b[1;32m   3083\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_list_functions_for_serialization\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m   3167\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_list_functions_for_serialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3168\u001b[0m     return (self._trackable_saved_model_saver\n\u001b[0;32m-> 3169\u001b[0;31m             .list_functions_for_serialization(serialization_cache))\n\u001b[0m\u001b[1;32m   3170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3171\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/base_serialization.py\u001b[0m in \u001b[0;36mlist_functions_for_serialization\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     91\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mfns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions_to_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# The parent AutoTrackable class saves all user-defined tf.functions, and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py\u001b[0m in \u001b[0;36mfunctions_to_serialize\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfunctions_to_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     return (self._get_serialized_attributes(\n\u001b[0;32m---> 73\u001b[0;31m         serialization_cache).functions_to_serialize)\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_serialized_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py\u001b[0m in \u001b[0;36m_get_serialized_attributes\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     object_dict, function_dict = self._get_serialized_attributes_internal(\n\u001b[0;32m---> 89\u001b[0;31m         serialization_cache)\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mserialized_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_and_validate_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/model_serialization.py\u001b[0m in \u001b[0;36m_get_serialized_attributes_internal\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     55\u001b[0m     objects, functions = (\n\u001b[1;32m     56\u001b[0m         super(ModelSavedModelSaver, self)._get_serialized_attributes_internal(\n\u001b[0;32m---> 57\u001b[0;31m             serialization_cache))\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mfunctions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_default_save_signature'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py\u001b[0m in \u001b[0;36m_get_serialized_attributes_internal\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;34m\"\"\"Returns dictionary of serialized attributes.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mobjects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_layer_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mfunctions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_layer_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;31m# Attribute validator requires that the default save signature is added to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;31m# function dict, even if the value is None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mwrap_layer_functions\u001b[0;34m(layer, serialization_cache)\u001b[0m\n\u001b[1;32m    195\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayerCall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m           \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[0;31m# Restore overwritten functions and losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mtracing_scope\u001b[0;34m()\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated_internal_learning_phase_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m           \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m     \u001b[0;31m# Implements GenericFunction.get_concrete_function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m     \u001b[0mconcrete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_garbage_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m     \u001b[0mconcrete\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1242\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m         \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1244\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1245\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_uninitialized_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    784\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    785\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 786\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2981\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2983\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2984\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_call_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3292\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3293\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                                    graph_function)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3138\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m       with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m    571\u001b[0m           layer._compute_dtype_object):  # pylint: disable=protected-access\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m     \u001b[0m_restore_layer_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/utils.py\u001b[0m in \u001b[0;36mwrap_with_training_arg\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     return control_flow_util.smart_cond(\n\u001b[1;32m    169\u001b[0m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         lambda: replace_training_and_call(False))\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m   \u001b[0;31m# Create arg spec for decorated function. If 'training' is not defined in the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/control_flow_util.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m    104\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[1;32m    105\u001b[0m   return tf.__internal__.smart_cond.smart_cond(\n\u001b[0;32m--> 106\u001b[0;31m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     return control_flow_ops.cond(pred, true_fn=true_fn, false_fn=false_fn,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    168\u001b[0m     return control_flow_util.smart_cond(\n\u001b[1;32m    169\u001b[0m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         lambda: replace_training_and_call(False))\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m   \u001b[0;31m# Create arg spec for decorated function. If 'training' is not defined in the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/utils.py\u001b[0m in \u001b[0;36mreplace_training_and_call\u001b[0;34m(training)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m       \u001b[0mset_training_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_arg_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     return control_flow_util.smart_cond(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_and_return_conditional_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_create_call_fn_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    608\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrapped_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    961\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    784\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    785\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 786\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2981\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2983\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2984\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_call_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3292\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3293\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                                    graph_function)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3138\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m       with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m    571\u001b[0m           layer._compute_dtype_object):  # pylint: disable=protected-access\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m     \u001b[0m_restore_layer_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/utils.py\u001b[0m in \u001b[0;36mwrap_with_training_arg\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     return control_flow_util.smart_cond(\n\u001b[1;32m    169\u001b[0m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         lambda: replace_training_and_call(False))\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m   \u001b[0;31m# Create arg spec for decorated function. If 'training' is not defined in the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/control_flow_util.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m    104\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[1;32m    105\u001b[0m   return tf.__internal__.smart_cond.smart_cond(\n\u001b[0;32m--> 106\u001b[0;31m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     return control_flow_ops.cond(pred, true_fn=true_fn, false_fn=false_fn,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    168\u001b[0m     return control_flow_util.smart_cond(\n\u001b[1;32m    169\u001b[0m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         lambda: replace_training_and_call(False))\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m   \u001b[0;31m# Create arg spec for decorated function. If 'training' is not defined in the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/utils.py\u001b[0m in \u001b[0;36mreplace_training_and_call\u001b[0;34m(training)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m       \u001b[0mset_training_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_arg_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     return control_flow_util.smart_cond(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mcall_and_return_conditional_losses\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_return_conditional_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[0;34m\"\"\"Returns layer (call_output, conditional losses) tuple.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m     \u001b[0mcall_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mversion_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_v1_layer_or_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m       conditional_losses = layer.get_losses_for(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    450\u001b[0m     \"\"\"\n\u001b[1;32m    451\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 452\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1074\u001b[0m         training=training_mode):\n\u001b[1;32m   1075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;31m# guarding for is a Layer instance (Functional API), which does not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# have a `shape` attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Inputs to a layer should be tensors. Got: {x}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \"\"\"\n\u001b[1;32m    569\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_val\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_api_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_c_api_shape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mc_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_graph\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     shape_vec, unknown_shape = pywrap_tf_session.TF_GraphGetTensorShapeHelper(\n\u001b[0;32m--> 577\u001b[0;31m         c_graph, self._as_tf_output())\n\u001b[0m\u001b[1;32m    578\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0munknown_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munknown_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_tf_output\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tf_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tf_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tf_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 32"
      ],
      "metadata": {
        "id": "TDetFQwMSKk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 32  soft pre bi\n"
      ],
      "metadata": {
        "id": "tUqsoIt5SKk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 32\n",
        "filepath = \"Kmodel32_soft_pre_bi.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "id": "dGYBzI9tSKk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel32_soft_pre_bi{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "shIE2WLlSKk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 32 soft pre bi adam  \n"
      ],
      "metadata": {
        "id": "17rbmbkJSKk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 32\n",
        "filepath = \"Kmodel32_soft_pre_bi_adam.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b03506-eddb-4c17-f5fe-976c247895dd",
        "id": "0Rc1AYwDSKk6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:06<00:00, 66.43it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel32_soft_pre_bi_adam{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "Z1tVkD0KSKk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 32 soft pre bi sgd  \n"
      ],
      "metadata": {
        "id": "52QbOgEXSKk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 32\n",
        "filepath = \"Kmodel32_soft_pre_bi_sgd.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b03506-eddb-4c17-f5fe-976c247895dd",
        "id": "p3cQUFuaSKk7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:06<00:00, 66.43it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel32_soft_pre_bi_sgd{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "IQLrE14OSKk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 32 soft pre cate \n"
      ],
      "metadata": {
        "id": "YmWai2hhSKk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 32\n",
        "filepath = \"Kmodel32_soft_pre_cate.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "8f62ba84-295e-4d23-a2f7-57bc97196ed3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9iMBwwkSKk9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:10<00:00, 41.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel32_soft_pre_cate{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "OU3Vt4nBSKk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 32 soft pre cate adam\n"
      ],
      "metadata": {
        "id": "Zrg0ZciqSKk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 32\n",
        "filepath = \"Kmodel32_soft_pre_cate_adam.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "4ade8ad3-0a08-4391-b9cc-b535897670e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6IwQDaZSKk-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:04<00:00, 92.81it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel32_soft_pre_cate_adam{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "SNUh7FzdSKk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 32 soft pre cate sgd\n"
      ],
      "metadata": {
        "id": "PInBxnIXSKk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 32\n",
        "filepath = \"Kmodel32_soft_pre_cate_sgd.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "4ade8ad3-0a08-4391-b9cc-b535897670e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zakBZsBzSKk_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:04<00:00, 92.81it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel32_soft_pre_cate_sgd{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "H9ZZNa8dSKk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 \n"
      ],
      "metadata": {
        "id": "GEk-rt9_StVQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1  soft pre bi\n"
      ],
      "metadata": {
        "id": "QDaLgRIyStVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 1\n",
        "filepath = \"Kmodel1_soft_pre_bi.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "id": "GGUJhDI9StVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel1_soft_pre_bi{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "6Vd84ZFgStVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1 soft pre bi adam  \n"
      ],
      "metadata": {
        "id": "OlSZVkmtStVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 1\n",
        "filepath = \"Kmodel1_soft_pre_bi_adam.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b03506-eddb-4c17-f5fe-976c247895dd",
        "id": "g1Xl88J7StVT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:06<00:00, 66.43it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel1_soft_pre_bi_adam{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "eRLREz42StVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1 soft pre bi sgd  \n"
      ],
      "metadata": {
        "id": "VUeDos-7StVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 1\n",
        "filepath = \"Kmodel1_soft_pre_bi_sgd.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "536c5f1b-3f2a-4871-908e-4b063c67ad8b",
        "id": "RL_Q1Si5StVU"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:13<00:00, 32.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel1_soft_pre_bi_sgd{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "4mZ0oZ-MStVU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5ee9ed5-418c-473a-e1fa-933f6d037d98"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold #1\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6972 - accuracy: 0.3389\n",
            "Epoch 1: val_accuracy improved from -inf to 0.27778, saving model to  Kmodel1_soft_pre_bi_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi_sgd1.h5 /assets\n",
            "360/360 [==============================] - 83s 188ms/step - loss: 0.6972 - accuracy: 0.3389 - val_loss: 0.6729 - val_accuracy: 0.2778 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6573 - accuracy: 0.3306\n",
            "Epoch 2: val_accuracy improved from 0.27778 to 0.31111, saving model to  Kmodel1_soft_pre_bi_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi_sgd1.h5 /assets\n",
            "360/360 [==============================] - 62s 173ms/step - loss: 0.6573 - accuracy: 0.3306 - val_loss: 0.6523 - val_accuracy: 0.3111 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6430 - accuracy: 0.3417\n",
            "Epoch 3: val_accuracy improved from 0.31111 to 0.33333, saving model to  Kmodel1_soft_pre_bi_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi_sgd1.h5 /assets\n",
            "360/360 [==============================] - 63s 176ms/step - loss: 0.6430 - accuracy: 0.3417 - val_loss: 0.6454 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6393 - accuracy: 0.3167\n",
            "Epoch 4: val_accuracy did not improve from 0.33333\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6393 - accuracy: 0.3167 - val_loss: 0.6431 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6371 - accuracy: 0.3389\n",
            "Epoch 5: val_accuracy did not improve from 0.33333\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6371 - accuracy: 0.3389 - val_loss: 0.6414 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6371 - accuracy: 0.3167\n",
            "Epoch 6: val_accuracy did not improve from 0.33333\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6371 - accuracy: 0.3167 - val_loss: 0.6437 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6371 - accuracy: 0.3278\n",
            "Epoch 7: val_accuracy did not improve from 0.33333\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6371 - accuracy: 0.3278 - val_loss: 0.6419 - val_accuracy: 0.3111 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6365 - accuracy: 0.3472\n",
            "Epoch 8: val_accuracy did not improve from 0.33333\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6365 - accuracy: 0.3472 - val_loss: 0.6408 - val_accuracy: 0.3111 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6361 - accuracy: 0.3389\n",
            "Epoch 9: val_accuracy did not improve from 0.33333\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6361 - accuracy: 0.3389 - val_loss: 0.6417 - val_accuracy: 0.3000 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6367 - accuracy: 0.3250\n",
            "Epoch 10: val_accuracy did not improve from 0.33333\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6367 - accuracy: 0.3250 - val_loss: 0.6419 - val_accuracy: 0.3111 - lr: 5.0000e-05\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6361 - accuracy: 0.3444\n",
            "Epoch 11: val_accuracy did not improve from 0.33333\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6361 - accuracy: 0.3444 - val_loss: 0.6403 - val_accuracy: 0.3111 - lr: 5.0000e-05\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6367 - accuracy: 0.3250\n",
            "Epoch 12: val_accuracy did not improve from 0.33333\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6367 - accuracy: 0.3250 - val_loss: 0.6413 - val_accuracy: 0.3222 - lr: 5.0000e-05\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6360 - accuracy: 0.3444\n",
            "Epoch 13: val_accuracy did not improve from 0.33333\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6360 - accuracy: 0.3444 - val_loss: 0.6414 - val_accuracy: 0.3222 - lr: 5.0000e-05\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6362 - accuracy: 0.3833\n",
            "Epoch 14: val_accuracy did not improve from 0.33333\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6362 - accuracy: 0.3833 - val_loss: 0.6398 - val_accuracy: 0.3222 - lr: 5.0000e-05\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6358 - accuracy: 0.3472\n",
            "Epoch 15: val_accuracy improved from 0.33333 to 0.35556, saving model to  Kmodel1_soft_pre_bi_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi_sgd1.h5 /assets\n",
            "360/360 [==============================] - 62s 173ms/step - loss: 0.6358 - accuracy: 0.3472 - val_loss: 0.6424 - val_accuracy: 0.3556 - lr: 5.0000e-05\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6372 - accuracy: 0.3333\n",
            "Epoch 16: val_accuracy did not improve from 0.35556\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6372 - accuracy: 0.3333 - val_loss: 0.6401 - val_accuracy: 0.2889 - lr: 5.0000e-05\n",
            "Epoch 17/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6360 - accuracy: 0.3611\n",
            "Epoch 17: val_accuracy did not improve from 0.35556\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6360 - accuracy: 0.3611 - val_loss: 0.6392 - val_accuracy: 0.3111 - lr: 5.0000e-05\n",
            "Epoch 18/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6358 - accuracy: 0.3417\n",
            "Epoch 18: val_accuracy did not improve from 0.35556\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6358 - accuracy: 0.3417 - val_loss: 0.6422 - val_accuracy: 0.2778 - lr: 5.0000e-05\n",
            "Epoch 19/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6364 - accuracy: 0.3472\n",
            "Epoch 19: val_accuracy did not improve from 0.35556\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6364 - accuracy: 0.3472 - val_loss: 0.6417 - val_accuracy: 0.3333 - lr: 5.0000e-05\n",
            "Epoch 20/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6359 - accuracy: 0.3750\n",
            "Epoch 20: val_accuracy did not improve from 0.35556\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6359 - accuracy: 0.3750 - val_loss: 0.6415 - val_accuracy: 0.3000 - lr: 5.0000e-05\n",
            "Epoch 21/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6367 - accuracy: 0.3139\n",
            "Epoch 21: val_accuracy improved from 0.35556 to 0.37778, saving model to  Kmodel1_soft_pre_bi_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi_sgd1.h5 /assets\n",
            "360/360 [==============================] - 61s 170ms/step - loss: 0.6367 - accuracy: 0.3139 - val_loss: 0.6380 - val_accuracy: 0.3778 - lr: 5.0000e-05\n",
            "Epoch 22/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6362 - accuracy: 0.3778\n",
            "Epoch 22: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6362 - accuracy: 0.3778 - val_loss: 0.6417 - val_accuracy: 0.3000 - lr: 5.0000e-05\n",
            "Epoch 23/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6361 - accuracy: 0.3444\n",
            "Epoch 23: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6361 - accuracy: 0.3444 - val_loss: 0.6424 - val_accuracy: 0.3444 - lr: 5.0000e-05\n",
            "Epoch 24/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6362 - accuracy: 0.3361\n",
            "Epoch 24: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6362 - accuracy: 0.3361 - val_loss: 0.6408 - val_accuracy: 0.3000 - lr: 5.0000e-05\n",
            "Epoch 25/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6358 - accuracy: 0.3667\n",
            "Epoch 25: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6358 - accuracy: 0.3667 - val_loss: 0.6397 - val_accuracy: 0.3222 - lr: 5.0000e-05\n",
            "Epoch 26/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6359 - accuracy: 0.3750\n",
            "Epoch 26: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 28s 77ms/step - loss: 0.6359 - accuracy: 0.3750 - val_loss: 0.6442 - val_accuracy: 0.2778 - lr: 5.0000e-05\n",
            "Epoch 27/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6357 - accuracy: 0.3778\n",
            "Epoch 27: val_accuracy did not improve from 0.37778\n",
            "\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6357 - accuracy: 0.3778 - val_loss: 0.6403 - val_accuracy: 0.3000 - lr: 5.0000e-05\n",
            "Epoch 28/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6360 - accuracy: 0.3694\n",
            "Epoch 28: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6360 - accuracy: 0.3694 - val_loss: 0.6400 - val_accuracy: 0.3222 - lr: 2.5000e-05\n",
            "Epoch 29/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6362 - accuracy: 0.3389\n",
            "Epoch 29: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6362 - accuracy: 0.3389 - val_loss: 0.6398 - val_accuracy: 0.3222 - lr: 2.5000e-05\n",
            "Epoch 30/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6356 - accuracy: 0.3639\n",
            "Epoch 30: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6356 - accuracy: 0.3639 - val_loss: 0.6410 - val_accuracy: 0.2667 - lr: 2.5000e-05\n",
            "Epoch 31/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6356 - accuracy: 0.3611\n",
            "Epoch 31: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6356 - accuracy: 0.3611 - val_loss: 0.6405 - val_accuracy: 0.2889 - lr: 2.5000e-05\n",
            "Epoch 32/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6356 - accuracy: 0.3750\n",
            "Epoch 32: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6356 - accuracy: 0.3750 - val_loss: 0.6402 - val_accuracy: 0.3222 - lr: 2.5000e-05\n",
            "Epoch 33/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6353 - accuracy: 0.3806\n",
            "Epoch 33: val_accuracy did not improve from 0.37778\n",
            "\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6353 - accuracy: 0.3806 - val_loss: 0.6391 - val_accuracy: 0.3222 - lr: 2.5000e-05\n",
            "Epoch 34/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6356 - accuracy: 0.3806\n",
            "Epoch 34: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6356 - accuracy: 0.3806 - val_loss: 0.6427 - val_accuracy: 0.2889 - lr: 1.2500e-05\n",
            "Epoch 35/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6365 - accuracy: 0.3472\n",
            "Epoch 35: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6365 - accuracy: 0.3472 - val_loss: 0.6396 - val_accuracy: 0.2889 - lr: 1.2500e-05\n",
            "Epoch 36/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6355 - accuracy: 0.3694\n",
            "Epoch 36: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6355 - accuracy: 0.3694 - val_loss: 0.6399 - val_accuracy: 0.3222 - lr: 1.2500e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.22      0.14      0.17        28\n",
            "      Normal       0.34      0.45      0.39        31\n",
            "Tuberculosis       0.35      0.35      0.35        31\n",
            "\n",
            "    accuracy                           0.32        90\n",
            "   macro avg       0.31      0.32      0.31        90\n",
            "weighted avg       0.31      0.32      0.31        90\n",
            "\n",
            "Fold #2\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6361 - accuracy: 0.3611\n",
            "Epoch 1: val_accuracy improved from -inf to 0.38889, saving model to  Kmodel1_soft_pre_bi_sgd2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi_sgd2.h5 /assets\n",
            "360/360 [==============================] - 63s 175ms/step - loss: 0.6361 - accuracy: 0.3611 - val_loss: 0.6424 - val_accuracy: 0.3889 - lr: 1.2500e-05\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6358 - accuracy: 0.3694\n",
            "Epoch 2: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6358 - accuracy: 0.3694 - val_loss: 0.6466 - val_accuracy: 0.3556 - lr: 1.2500e-05\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6357 - accuracy: 0.3639\n",
            "Epoch 3: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6357 - accuracy: 0.3639 - val_loss: 0.6441 - val_accuracy: 0.3778 - lr: 1.2500e-05\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6357 - accuracy: 0.3583\n",
            "Epoch 4: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6357 - accuracy: 0.3583 - val_loss: 0.6456 - val_accuracy: 0.3556 - lr: 1.2500e-05\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6355 - accuracy: 0.3750\n",
            "Epoch 5: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6355 - accuracy: 0.3750 - val_loss: 0.6420 - val_accuracy: 0.3778 - lr: 1.2500e-05\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6357 - accuracy: 0.3972\n",
            "Epoch 6: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6357 - accuracy: 0.3972 - val_loss: 0.6482 - val_accuracy: 0.3444 - lr: 1.2500e-05\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6355 - accuracy: 0.3944\n",
            "Epoch 7: val_accuracy did not improve from 0.38889\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6355 - accuracy: 0.3944 - val_loss: 0.6444 - val_accuracy: 0.3667 - lr: 1.2500e-05\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6354 - accuracy: 0.3861\n",
            "Epoch 8: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6354 - accuracy: 0.3861 - val_loss: 0.6451 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6355 - accuracy: 0.3667\n",
            "Epoch 9: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6355 - accuracy: 0.3667 - val_loss: 0.6443 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6362 - accuracy: 0.3639\n",
            "Epoch 10: val_accuracy improved from 0.38889 to 0.41111, saving model to  Kmodel1_soft_pre_bi_sgd2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi_sgd2.h5 /assets\n",
            "360/360 [==============================] - 62s 172ms/step - loss: 0.6362 - accuracy: 0.3639 - val_loss: 0.6427 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6352 - accuracy: 0.3917\n",
            "Epoch 11: val_accuracy did not improve from 0.41111\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6352 - accuracy: 0.3917 - val_loss: 0.6425 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6352 - accuracy: 0.3778\n",
            "Epoch 12: val_accuracy did not improve from 0.41111\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6352 - accuracy: 0.3778 - val_loss: 0.6455 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6352 - accuracy: 0.3889\n",
            "Epoch 13: val_accuracy did not improve from 0.41111\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6352 - accuracy: 0.3889 - val_loss: 0.6449 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6353 - accuracy: 0.3694\n",
            "Epoch 14: val_accuracy did not improve from 0.41111\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6353 - accuracy: 0.3694 - val_loss: 0.6439 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6357 - accuracy: 0.3917\n",
            "Epoch 15: val_accuracy did not improve from 0.41111\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6357 - accuracy: 0.3917 - val_loss: 0.6445 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6358 - accuracy: 0.3639\n",
            "Epoch 16: val_accuracy did not improve from 0.41111\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6358 - accuracy: 0.3639 - val_loss: 0.6469 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6356 - accuracy: 0.3694\n",
            "Epoch 17: val_accuracy did not improve from 0.41111\n",
            "360/360 [==============================] - 28s 76ms/step - loss: 0.6356 - accuracy: 0.3694 - val_loss: 0.6445 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6353 - accuracy: 0.3750\n",
            "Epoch 18: val_accuracy did not improve from 0.41111\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6353 - accuracy: 0.3750 - val_loss: 0.6438 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6359 - accuracy: 0.3361\n",
            "Epoch 19: val_accuracy did not improve from 0.41111\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6359 - accuracy: 0.3361 - val_loss: 0.6461 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6350 - accuracy: 0.3778\n",
            "Epoch 20: val_accuracy did not improve from 0.41111\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6350 - accuracy: 0.3778 - val_loss: 0.6435 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6348 - accuracy: 0.3917\n",
            "Epoch 21: val_accuracy did not improve from 0.41111\n",
            "360/360 [==============================] - 28s 76ms/step - loss: 0.6348 - accuracy: 0.3917 - val_loss: 0.6448 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6358 - accuracy: 0.3722\n",
            "Epoch 22: val_accuracy did not improve from 0.41111\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6358 - accuracy: 0.3722 - val_loss: 0.6461 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6362 - accuracy: 0.3417\n",
            "Epoch 23: val_accuracy did not improve from 0.41111\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6362 - accuracy: 0.3417 - val_loss: 0.6474 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6361 - accuracy: 0.3472\n",
            "Epoch 24: val_accuracy did not improve from 0.41111\n",
            "360/360 [==============================] - 28s 76ms/step - loss: 0.6361 - accuracy: 0.3472 - val_loss: 0.6460 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6355 - accuracy: 0.3528\n",
            "Epoch 25: val_accuracy did not improve from 0.41111\n",
            "360/360 [==============================] - 28s 76ms/step - loss: 0.6355 - accuracy: 0.3528 - val_loss: 0.6449 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.36      0.26      0.31        34\n",
            "      Normal       0.35      0.33      0.34        27\n",
            "Tuberculosis       0.41      0.55      0.47        29\n",
            "\n",
            "    accuracy                           0.38        90\n",
            "   macro avg       0.37      0.38      0.37        90\n",
            "weighted avg       0.37      0.38      0.37        90\n",
            "\n",
            "Fold #3\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6355 - accuracy: 0.3667\n",
            "Epoch 1: val_accuracy improved from -inf to 0.34444, saving model to  Kmodel1_soft_pre_bi_sgd3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi_sgd3.h5 /assets\n",
            "360/360 [==============================] - 63s 175ms/step - loss: 0.6355 - accuracy: 0.3667 - val_loss: 0.6391 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6355 - accuracy: 0.3750\n",
            "Epoch 2: val_accuracy improved from 0.34444 to 0.35556, saving model to  Kmodel1_soft_pre_bi_sgd3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi_sgd3.h5 /assets\n",
            "360/360 [==============================] - 63s 175ms/step - loss: 0.6355 - accuracy: 0.3750 - val_loss: 0.6396 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6358 - accuracy: 0.3528\n",
            "Epoch 3: val_accuracy improved from 0.35556 to 0.36667, saving model to  Kmodel1_soft_pre_bi_sgd3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi_sgd3.h5 /assets\n",
            "360/360 [==============================] - 63s 174ms/step - loss: 0.6358 - accuracy: 0.3528 - val_loss: 0.6399 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6353 - accuracy: 0.3667\n",
            "Epoch 4: val_accuracy did not improve from 0.36667\n",
            "360/360 [==============================] - 28s 77ms/step - loss: 0.6353 - accuracy: 0.3667 - val_loss: 0.6397 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6356 - accuracy: 0.3667\n",
            "Epoch 5: val_accuracy improved from 0.36667 to 0.38889, saving model to  Kmodel1_soft_pre_bi_sgd3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi_sgd3.h5 /assets\n",
            "360/360 [==============================] - 62s 173ms/step - loss: 0.6356 - accuracy: 0.3667 - val_loss: 0.6387 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6354 - accuracy: 0.3861\n",
            "Epoch 6: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6354 - accuracy: 0.3861 - val_loss: 0.6407 - val_accuracy: 0.3222 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6354 - accuracy: 0.3944\n",
            "Epoch 7: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 28s 76ms/step - loss: 0.6354 - accuracy: 0.3944 - val_loss: 0.6395 - val_accuracy: 0.3222 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6358 - accuracy: 0.3611\n",
            "Epoch 8: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6358 - accuracy: 0.3611 - val_loss: 0.6381 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6356 - accuracy: 0.3472\n",
            "Epoch 9: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6356 - accuracy: 0.3472 - val_loss: 0.6403 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6359 - accuracy: 0.3806\n",
            "Epoch 10: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6359 - accuracy: 0.3806 - val_loss: 0.6396 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6349 - accuracy: 0.4250\n",
            "Epoch 11: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6349 - accuracy: 0.4250 - val_loss: 0.6413 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6354 - accuracy: 0.3722\n",
            "Epoch 12: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6354 - accuracy: 0.3722 - val_loss: 0.6409 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6360 - accuracy: 0.3417\n",
            "Epoch 13: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6360 - accuracy: 0.3417 - val_loss: 0.6396 - val_accuracy: 0.3111 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6354 - accuracy: 0.3528\n",
            "Epoch 14: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6354 - accuracy: 0.3528 - val_loss: 0.6395 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6356 - accuracy: 0.3944\n",
            "Epoch 15: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6356 - accuracy: 0.3944 - val_loss: 0.6386 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6353 - accuracy: 0.3889\n",
            "Epoch 16: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 28s 76ms/step - loss: 0.6353 - accuracy: 0.3889 - val_loss: 0.6407 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6354 - accuracy: 0.3528\n",
            "Epoch 17: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6354 - accuracy: 0.3528 - val_loss: 0.6406 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6363 - accuracy: 0.3389\n",
            "Epoch 18: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 28s 76ms/step - loss: 0.6363 - accuracy: 0.3389 - val_loss: 0.6407 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6350 - accuracy: 0.3833\n",
            "Epoch 19: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6350 - accuracy: 0.3833 - val_loss: 0.6397 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6351 - accuracy: 0.3972\n",
            "Epoch 20: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6351 - accuracy: 0.3972 - val_loss: 0.6389 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.40      0.37      0.38        27\n",
            "      Normal       0.43      0.39      0.41        33\n",
            "Tuberculosis       0.31      0.37      0.34        30\n",
            "\n",
            "    accuracy                           0.38        90\n",
            "   macro avg       0.38      0.38      0.38        90\n",
            "weighted avg       0.38      0.38      0.38        90\n",
            "\n",
            "Fold #4\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6356 - accuracy: 0.3556\n",
            "Epoch 1: val_accuracy improved from -inf to 0.31111, saving model to  Kmodel1_soft_pre_bi_sgd4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi_sgd4.h5 /assets\n",
            "360/360 [==============================] - 61s 169ms/step - loss: 0.6356 - accuracy: 0.3556 - val_loss: 0.6445 - val_accuracy: 0.3111 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6350 - accuracy: 0.3639\n",
            "Epoch 2: val_accuracy did not improve from 0.31111\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6350 - accuracy: 0.3639 - val_loss: 0.6473 - val_accuracy: 0.3111 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6355 - accuracy: 0.3611\n",
            "Epoch 3: val_accuracy did not improve from 0.31111\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6355 - accuracy: 0.3611 - val_loss: 0.6475 - val_accuracy: 0.2889 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6354 - accuracy: 0.3833\n",
            "Epoch 4: val_accuracy improved from 0.31111 to 0.34444, saving model to  Kmodel1_soft_pre_bi_sgd4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi_sgd4.h5 /assets\n",
            "360/360 [==============================] - 61s 170ms/step - loss: 0.6354 - accuracy: 0.3833 - val_loss: 0.6453 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6354 - accuracy: 0.4056\n",
            "Epoch 5: val_accuracy did not improve from 0.34444\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 0.6354 - accuracy: 0.4056 - val_loss: 0.6446 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6359 - accuracy: 0.3528\n",
            "Epoch 6: val_accuracy improved from 0.34444 to 0.37778, saving model to  Kmodel1_soft_pre_bi_sgd4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi_sgd4.h5 /assets\n",
            "360/360 [==============================] - 60s 168ms/step - loss: 0.6359 - accuracy: 0.3528 - val_loss: 0.6454 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6352 - accuracy: 0.3917\n",
            "Epoch 7: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 0.6352 - accuracy: 0.3917 - val_loss: 0.6453 - val_accuracy: 0.3000 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6355 - accuracy: 0.3917\n",
            "Epoch 8: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 0.6355 - accuracy: 0.3917 - val_loss: 0.6448 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6358 - accuracy: 0.3667\n",
            "Epoch 9: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 0.6358 - accuracy: 0.3667 - val_loss: 0.6459 - val_accuracy: 0.3111 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6358 - accuracy: 0.3806\n",
            "Epoch 10: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 0.6358 - accuracy: 0.3806 - val_loss: 0.6451 - val_accuracy: 0.3000 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6357 - accuracy: 0.3528\n",
            "Epoch 11: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6357 - accuracy: 0.3528 - val_loss: 0.6448 - val_accuracy: 0.3111 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6352 - accuracy: 0.4056\n",
            "Epoch 12: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 0.6352 - accuracy: 0.4056 - val_loss: 0.6454 - val_accuracy: 0.2778 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6357 - accuracy: 0.3611\n",
            "Epoch 13: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 0.6357 - accuracy: 0.3611 - val_loss: 0.6445 - val_accuracy: 0.3111 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6361 - accuracy: 0.3528\n",
            "Epoch 14: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 0.6361 - accuracy: 0.3528 - val_loss: 0.6461 - val_accuracy: 0.3111 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6362 - accuracy: 0.3333\n",
            "Epoch 15: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6362 - accuracy: 0.3333 - val_loss: 0.6469 - val_accuracy: 0.3111 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6352 - accuracy: 0.4111\n",
            "Epoch 16: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6352 - accuracy: 0.4111 - val_loss: 0.6468 - val_accuracy: 0.2667 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6356 - accuracy: 0.3556\n",
            "Epoch 17: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 0.6356 - accuracy: 0.3556 - val_loss: 0.6451 - val_accuracy: 0.3222 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6361 - accuracy: 0.3528\n",
            "Epoch 18: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 0.6361 - accuracy: 0.3528 - val_loss: 0.6450 - val_accuracy: 0.3000 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6351 - accuracy: 0.3861\n",
            "Epoch 19: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 0.6351 - accuracy: 0.3861 - val_loss: 0.6457 - val_accuracy: 0.3222 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6349 - accuracy: 0.4333\n",
            "Epoch 20: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 0.6349 - accuracy: 0.4333 - val_loss: 0.6464 - val_accuracy: 0.2667 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6354 - accuracy: 0.4028\n",
            "Epoch 21: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 0.6354 - accuracy: 0.4028 - val_loss: 0.6457 - val_accuracy: 0.3111 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.40      0.40      0.40        30\n",
            "      Normal       0.25      0.26      0.25        31\n",
            "Tuberculosis       0.29      0.28      0.28        29\n",
            "\n",
            "    accuracy                           0.31        90\n",
            "   macro avg       0.31      0.31      0.31        90\n",
            "weighted avg       0.31      0.31      0.31        90\n",
            "\n",
            "Fold #5\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6355 - accuracy: 0.3861\n",
            "Epoch 1: val_accuracy improved from -inf to 0.33333, saving model to  Kmodel1_soft_pre_bi_sgd5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi_sgd5.h5 /assets\n",
            "360/360 [==============================] - 62s 172ms/step - loss: 0.6355 - accuracy: 0.3861 - val_loss: 0.6415 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6356 - accuracy: 0.3806\n",
            "Epoch 2: val_accuracy did not improve from 0.33333\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6356 - accuracy: 0.3806 - val_loss: 0.6417 - val_accuracy: 0.3111 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6354 - accuracy: 0.3694\n",
            "Epoch 3: val_accuracy did not improve from 0.33333\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 0.6354 - accuracy: 0.3694 - val_loss: 0.6436 - val_accuracy: 0.3111 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6357 - accuracy: 0.4028\n",
            "Epoch 4: val_accuracy improved from 0.33333 to 0.34444, saving model to  Kmodel1_soft_pre_bi_sgd5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi_sgd5.h5 /assets\n",
            "360/360 [==============================] - 60s 167ms/step - loss: 0.6357 - accuracy: 0.4028 - val_loss: 0.6423 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6357 - accuracy: 0.3667\n",
            "Epoch 5: val_accuracy did not improve from 0.34444\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6357 - accuracy: 0.3667 - val_loss: 0.6426 - val_accuracy: 0.3222 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6354 - accuracy: 0.4028\n",
            "Epoch 6: val_accuracy did not improve from 0.34444\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6354 - accuracy: 0.4028 - val_loss: 0.6442 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6358 - accuracy: 0.3861\n",
            "Epoch 7: val_accuracy did not improve from 0.34444\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 0.6358 - accuracy: 0.3861 - val_loss: 0.6433 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6363 - accuracy: 0.3639\n",
            "Epoch 8: val_accuracy improved from 0.34444 to 0.35556, saving model to  Kmodel1_soft_pre_bi_sgd5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi_sgd5.h5 /assets\n",
            "360/360 [==============================] - 60s 168ms/step - loss: 0.6363 - accuracy: 0.3639 - val_loss: 0.6431 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6354 - accuracy: 0.3917\n",
            "Epoch 9: val_accuracy did not improve from 0.35556\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 0.6354 - accuracy: 0.3917 - val_loss: 0.6429 - val_accuracy: 0.3222 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6355 - accuracy: 0.4083\n",
            "Epoch 10: val_accuracy did not improve from 0.35556\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 0.6355 - accuracy: 0.4083 - val_loss: 0.6424 - val_accuracy: 0.3222 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6357 - accuracy: 0.3750\n",
            "Epoch 11: val_accuracy improved from 0.35556 to 0.38889, saving model to  Kmodel1_soft_pre_bi_sgd5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_bi_sgd5.h5 /assets\n",
            "360/360 [==============================] - 61s 169ms/step - loss: 0.6357 - accuracy: 0.3750 - val_loss: 0.6412 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6354 - accuracy: 0.3833\n",
            "Epoch 12: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6354 - accuracy: 0.3833 - val_loss: 0.6405 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6351 - accuracy: 0.3806\n",
            "Epoch 13: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6351 - accuracy: 0.3806 - val_loss: 0.6431 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6361 - accuracy: 0.3556\n",
            "Epoch 14: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6361 - accuracy: 0.3556 - val_loss: 0.6436 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6353 - accuracy: 0.4111\n",
            "Epoch 15: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6353 - accuracy: 0.4111 - val_loss: 0.6431 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6364 - accuracy: 0.3306\n",
            "Epoch 16: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6364 - accuracy: 0.3306 - val_loss: 0.6421 - val_accuracy: 0.3222 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6351 - accuracy: 0.3944\n",
            "Epoch 17: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6351 - accuracy: 0.3944 - val_loss: 0.6444 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6348 - accuracy: 0.4139\n",
            "Epoch 18: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6348 - accuracy: 0.4139 - val_loss: 0.6426 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6355 - accuracy: 0.4000\n",
            "Epoch 19: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 0.6355 - accuracy: 0.4000 - val_loss: 0.6432 - val_accuracy: 0.3111 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6352 - accuracy: 0.4028\n",
            "Epoch 20: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 0.6352 - accuracy: 0.4028 - val_loss: 0.6431 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6348 - accuracy: 0.4000\n",
            "Epoch 21: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 0.6348 - accuracy: 0.4000 - val_loss: 0.6440 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6350 - accuracy: 0.4333\n",
            "Epoch 22: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 0.6350 - accuracy: 0.4333 - val_loss: 0.6441 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6356 - accuracy: 0.3861\n",
            "Epoch 23: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 0.6356 - accuracy: 0.3861 - val_loss: 0.6400 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6353 - accuracy: 0.3778\n",
            "Epoch 24: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 0.6353 - accuracy: 0.3778 - val_loss: 0.6414 - val_accuracy: 0.3222 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6357 - accuracy: 0.3722\n",
            "Epoch 25: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6357 - accuracy: 0.3722 - val_loss: 0.6423 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6355 - accuracy: 0.3944\n",
            "Epoch 26: val_accuracy did not improve from 0.38889\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 0.6355 - accuracy: 0.3944 - val_loss: 0.6420 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.42      0.26      0.32        31\n",
            "      Normal       0.32      0.50      0.39        28\n",
            "Tuberculosis       0.37      0.32      0.34        31\n",
            "\n",
            "    accuracy                           0.36        90\n",
            "   macro avg       0.37      0.36      0.35        90\n",
            "weighted avg       0.37      0.36      0.35        90\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.37      0.29      0.32       150\n",
            "      Normal       0.34      0.39      0.36       150\n",
            "Tuberculosis       0.35      0.37      0.36       150\n",
            "\n",
            "    accuracy                           0.35       450\n",
            "   macro avg       0.35      0.35      0.35       450\n",
            "weighted avg       0.35      0.35      0.35       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1 soft pre cate \n"
      ],
      "metadata": {
        "id": "fc3oQRkOStVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 1\n",
        "filepath = \"Kmodel1_soft_pre_cate.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "3b823fc4-5f5d-41db-ed84-f967ba99d616",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoTbrNJKStVU"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [04:05<00:00,  1.83it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel1_soft_pre_cate{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "7_-gdbBGStVU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20923f3e-f8ec-4031-8d9b-c8c4e5e4f548"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 2s 0us/step\n",
            "87924736/87910968 [==============================] - 2s 0us/step\n",
            "Fold #1\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0959 - accuracy: 0.3611\n",
            "Epoch 1: val_accuracy improved from -inf to 0.45556, saving model to  Kmodel1_soft_pre_cate1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate1.h5 /assets\n",
            "360/360 [==============================] - 94s 202ms/step - loss: 1.0959 - accuracy: 0.3611 - val_loss: 1.0793 - val_accuracy: 0.4556 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.8068 - accuracy: 0.5889\n",
            "Epoch 2: val_accuracy improved from 0.45556 to 0.65556, saving model to  Kmodel1_soft_pre_cate1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate1.h5 /assets\n",
            "360/360 [==============================] - 65s 182ms/step - loss: 0.8068 - accuracy: 0.5889 - val_loss: 0.9109 - val_accuracy: 0.6556 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.7226 - accuracy: 0.6639\n",
            "Epoch 3: val_accuracy improved from 0.65556 to 0.68889, saving model to  Kmodel1_soft_pre_cate1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate1.h5 /assets\n",
            "360/360 [==============================] - 66s 183ms/step - loss: 0.7226 - accuracy: 0.6639 - val_loss: 0.9112 - val_accuracy: 0.6889 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6510 - accuracy: 0.6778\n",
            "Epoch 4: val_accuracy did not improve from 0.68889\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.6510 - accuracy: 0.6778 - val_loss: 1.1476 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6122 - accuracy: 0.7306\n",
            "Epoch 5: val_accuracy did not improve from 0.68889\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.6122 - accuracy: 0.7306 - val_loss: 0.8791 - val_accuracy: 0.6889 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.5953 - accuracy: 0.7167\n",
            "Epoch 6: val_accuracy did not improve from 0.68889\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.5953 - accuracy: 0.7167 - val_loss: 1.4883 - val_accuracy: 0.4444 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.5215 - accuracy: 0.7639\n",
            "Epoch 7: val_accuracy improved from 0.68889 to 0.72222, saving model to  Kmodel1_soft_pre_cate1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate1.h5 /assets\n",
            "360/360 [==============================] - 66s 184ms/step - loss: 0.5215 - accuracy: 0.7639 - val_loss: 0.8667 - val_accuracy: 0.7222 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.4248 - accuracy: 0.8333\n",
            "Epoch 8: val_accuracy did not improve from 0.72222\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 0.4248 - accuracy: 0.8333 - val_loss: 1.0578 - val_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.4419 - accuracy: 0.8111\n",
            "Epoch 9: val_accuracy improved from 0.72222 to 0.75556, saving model to  Kmodel1_soft_pre_cate1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate1.h5 /assets\n",
            "360/360 [==============================] - 66s 182ms/step - loss: 0.4419 - accuracy: 0.8111 - val_loss: 0.8632 - val_accuracy: 0.7556 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.4156 - accuracy: 0.8361\n",
            "Epoch 10: val_accuracy did not improve from 0.75556\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.4156 - accuracy: 0.8361 - val_loss: 1.4758 - val_accuracy: 0.6778 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.3665 - accuracy: 0.9000\n",
            "Epoch 11: val_accuracy did not improve from 0.75556\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.3665 - accuracy: 0.9000 - val_loss: 4.3284 - val_accuracy: 0.5222 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.2990 - accuracy: 0.8944\n",
            "Epoch 12: val_accuracy did not improve from 0.75556\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.2990 - accuracy: 0.8944 - val_loss: 1.8908 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.3678 - accuracy: 0.8806\n",
            "Epoch 13: val_accuracy did not improve from 0.75556\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.3678 - accuracy: 0.8806 - val_loss: 0.9459 - val_accuracy: 0.6222 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.2443 - accuracy: 0.9278\n",
            "Epoch 14: val_accuracy did not improve from 0.75556\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.2443 - accuracy: 0.9278 - val_loss: 1.3646 - val_accuracy: 0.6222 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.2567 - accuracy: 0.9278\n",
            "Epoch 15: val_accuracy did not improve from 0.75556\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.2567 - accuracy: 0.9278 - val_loss: 1.9345 - val_accuracy: 0.7111 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.1216 - accuracy: 0.9500\n",
            "Epoch 16: val_accuracy did not improve from 0.75556\n",
            "360/360 [==============================] - 32s 90ms/step - loss: 0.1216 - accuracy: 0.9500 - val_loss: 2.4319 - val_accuracy: 0.5778 - lr: 5.0000e-05\n",
            "Epoch 17/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.1046 - accuracy: 0.9750\n",
            "Epoch 17: val_accuracy did not improve from 0.75556\n",
            "360/360 [==============================] - 32s 89ms/step - loss: 0.1046 - accuracy: 0.9750 - val_loss: 2.3726 - val_accuracy: 0.5111 - lr: 5.0000e-05\n",
            "Epoch 18/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.9861\n",
            "Epoch 18: val_accuracy did not improve from 0.75556\n",
            "360/360 [==============================] - 32s 90ms/step - loss: 0.0588 - accuracy: 0.9861 - val_loss: 1.4582 - val_accuracy: 0.6222 - lr: 5.0000e-05\n",
            "Epoch 19/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0797 - accuracy: 0.9806\n",
            "Epoch 19: val_accuracy did not improve from 0.75556\n",
            "360/360 [==============================] - 32s 90ms/step - loss: 0.0797 - accuracy: 0.9806 - val_loss: 1.0741 - val_accuracy: 0.7111 - lr: 5.0000e-05\n",
            "Epoch 20/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.1191 - accuracy: 0.9667\n",
            "Epoch 20: val_accuracy did not improve from 0.75556\n",
            "360/360 [==============================] - 32s 89ms/step - loss: 0.1191 - accuracy: 0.9667 - val_loss: 1.4704 - val_accuracy: 0.6000 - lr: 5.0000e-05\n",
            "Epoch 21/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0743 - accuracy: 0.9806\n",
            "Epoch 21: val_accuracy did not improve from 0.75556\n",
            "\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "360/360 [==============================] - 32s 90ms/step - loss: 0.0743 - accuracy: 0.9806 - val_loss: 2.0665 - val_accuracy: 0.5222 - lr: 5.0000e-05\n",
            "Epoch 22/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0949 - accuracy: 0.9806\n",
            "Epoch 22: val_accuracy did not improve from 0.75556\n",
            "360/360 [==============================] - 32s 89ms/step - loss: 0.0949 - accuracy: 0.9806 - val_loss: 1.9387 - val_accuracy: 0.4556 - lr: 2.5000e-05\n",
            "Epoch 23/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9944\n",
            "Epoch 23: val_accuracy did not improve from 0.75556\n",
            "360/360 [==============================] - 32s 90ms/step - loss: 0.0320 - accuracy: 0.9944 - val_loss: 1.6468 - val_accuracy: 0.5778 - lr: 2.5000e-05\n",
            "Epoch 24/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 5.8690e-04 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.75556\n",
            "360/360 [==============================] - 32s 90ms/step - loss: 5.8690e-04 - accuracy: 1.0000 - val_loss: 1.6574 - val_accuracy: 0.5778 - lr: 2.5000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.42      0.82      0.55        28\n",
            "      Normal       0.93      0.45      0.61        31\n",
            "Tuberculosis       0.75      0.48      0.59        31\n",
            "\n",
            "    accuracy                           0.58        90\n",
            "   macro avg       0.70      0.59      0.58        90\n",
            "weighted avg       0.71      0.58      0.58        90\n",
            "\n",
            "Fold #2\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.4056 - accuracy: 0.9361\n",
            "Epoch 1: val_accuracy improved from -inf to 0.86667, saving model to  Kmodel1_soft_pre_cate2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate2.h5 /assets\n",
            "360/360 [==============================] - 64s 178ms/step - loss: 0.4056 - accuracy: 0.9361 - val_loss: 0.3215 - val_accuracy: 0.8667 - lr: 2.5000e-05\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.2686 - accuracy: 0.9583\n",
            "Epoch 2: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 32s 90ms/step - loss: 0.2686 - accuracy: 0.9583 - val_loss: 0.4115 - val_accuracy: 0.8556 - lr: 2.5000e-05\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.2038 - accuracy: 0.9667\n",
            "Epoch 3: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 32s 90ms/step - loss: 0.2038 - accuracy: 0.9667 - val_loss: 0.4080 - val_accuracy: 0.8556 - lr: 2.5000e-05\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.1924 - accuracy: 0.9611\n",
            "Epoch 4: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 32s 90ms/step - loss: 0.1924 - accuracy: 0.9611 - val_loss: 0.4080 - val_accuracy: 0.8556 - lr: 2.5000e-05\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.1795 - accuracy: 0.9583\n",
            "Epoch 5: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 32s 90ms/step - loss: 0.1795 - accuracy: 0.9583 - val_loss: 0.4847 - val_accuracy: 0.7667 - lr: 2.5000e-05\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.1102 - accuracy: 0.9694\n",
            "Epoch 6: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 32s 90ms/step - loss: 0.1102 - accuracy: 0.9694 - val_loss: 0.4422 - val_accuracy: 0.8667 - lr: 2.5000e-05\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9861\n",
            "Epoch 7: val_accuracy did not improve from 0.86667\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "360/360 [==============================] - 32s 90ms/step - loss: 0.0512 - accuracy: 0.9861 - val_loss: 0.4275 - val_accuracy: 0.8222 - lr: 2.5000e-05\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9861\n",
            "Epoch 8: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 32s 90ms/step - loss: 0.0244 - accuracy: 0.9861 - val_loss: 0.4324 - val_accuracy: 0.8000 - lr: 1.2500e-05\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0907 - accuracy: 0.9889\n",
            "Epoch 9: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0907 - accuracy: 0.9889 - val_loss: 0.4112 - val_accuracy: 0.8333 - lr: 1.2500e-05\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9917\n",
            "Epoch 10: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0126 - accuracy: 0.9917 - val_loss: 0.4452 - val_accuracy: 0.7667 - lr: 1.2500e-05\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9889\n",
            "Epoch 11: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 0.0680 - accuracy: 0.9889 - val_loss: 0.4580 - val_accuracy: 0.7556 - lr: 1.2500e-05\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0412 - accuracy: 0.9889\n",
            "Epoch 12: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0412 - accuracy: 0.9889 - val_loss: 0.4261 - val_accuracy: 0.8000 - lr: 1.2500e-05\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9944\n",
            "Epoch 13: val_accuracy did not improve from 0.86667\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 0.0195 - accuracy: 0.9944 - val_loss: 0.5146 - val_accuracy: 0.7667 - lr: 1.2500e-05\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9917\n",
            "Epoch 14: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 0.0220 - accuracy: 0.9917 - val_loss: 0.4677 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9972\n",
            "Epoch 15: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 0.0070 - accuracy: 0.9972 - val_loss: 0.4294 - val_accuracy: 0.7778 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9917\n",
            "Epoch 16: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 0.0370 - accuracy: 0.9917 - val_loss: 0.4328 - val_accuracy: 0.7667 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.65      0.91      0.76        34\n",
            "      Normal       1.00      0.74      0.85        27\n",
            "Tuberculosis       0.82      0.62      0.71        29\n",
            "\n",
            "    accuracy                           0.77        90\n",
            "   macro avg       0.82      0.76      0.77        90\n",
            "weighted avg       0.81      0.77      0.77        90\n",
            "\n",
            "Fold #3\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9944\n",
            "Epoch 1: val_accuracy improved from -inf to 0.83333, saving model to  Kmodel1_soft_pre_cate3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate3.h5 /assets\n",
            "360/360 [==============================] - 66s 184ms/step - loss: 0.0333 - accuracy: 0.9944 - val_loss: 0.3521 - val_accuracy: 0.8333 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 5.7749e-04 - accuracy: 1.0000\n",
            "Epoch 2: val_accuracy improved from 0.83333 to 0.85556, saving model to  Kmodel1_soft_pre_cate3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate3.h5 /assets\n",
            "360/360 [==============================] - 66s 184ms/step - loss: 5.7749e-04 - accuracy: 1.0000 - val_loss: 0.3832 - val_accuracy: 0.8556 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9944\n",
            "Epoch 3: val_accuracy improved from 0.85556 to 0.86667, saving model to  Kmodel1_soft_pre_cate3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate3.h5 /assets\n",
            "360/360 [==============================] - 67s 185ms/step - loss: 0.0230 - accuracy: 0.9944 - val_loss: 0.3641 - val_accuracy: 0.8667 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 0.9889\n",
            "Epoch 4: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 0.0686 - accuracy: 0.9889 - val_loss: 0.3673 - val_accuracy: 0.8667 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9944\n",
            "Epoch 5: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 0.0537 - accuracy: 0.9944 - val_loss: 0.4590 - val_accuracy: 0.8111 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 9.2584e-04 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 9.2584e-04 - accuracy: 1.0000 - val_loss: 0.4061 - val_accuracy: 0.8444 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.7458e-05 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 1.7458e-05 - accuracy: 1.0000 - val_loss: 0.4576 - val_accuracy: 0.8222 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.9972\n",
            "Epoch 8: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 0.0323 - accuracy: 0.9972 - val_loss: 0.3818 - val_accuracy: 0.8333 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 3.2047e-06 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 3.2047e-06 - accuracy: 1.0000 - val_loss: 0.3506 - val_accuracy: 0.8556 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.9944\n",
            "Epoch 10: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 0.0439 - accuracy: 0.9944 - val_loss: 0.3917 - val_accuracy: 0.8444 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9972\n",
            "Epoch 11: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 0.0157 - accuracy: 0.9972 - val_loss: 0.3591 - val_accuracy: 0.8444 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 3.7297e-06 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 3.7297e-06 - accuracy: 1.0000 - val_loss: 0.3540 - val_accuracy: 0.8667 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9972\n",
            "Epoch 13: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 0.0125 - accuracy: 0.9972 - val_loss: 0.3368 - val_accuracy: 0.8556 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 3.4273e-05 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 3.4273e-05 - accuracy: 1.0000 - val_loss: 0.3183 - val_accuracy: 0.8667 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9972\n",
            "Epoch 15: val_accuracy improved from 0.86667 to 0.87778, saving model to  Kmodel1_soft_pre_cate3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate3.h5 /assets\n",
            "360/360 [==============================] - 66s 184ms/step - loss: 0.0135 - accuracy: 0.9972 - val_loss: 0.3284 - val_accuracy: 0.8778 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9944\n",
            "Epoch 16: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 0.0581 - accuracy: 0.9944 - val_loss: 0.3332 - val_accuracy: 0.8556 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9972\n",
            "Epoch 17: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 0.0055 - accuracy: 0.9972 - val_loss: 0.3527 - val_accuracy: 0.8556 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 3.7416e-06 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 3.7416e-06 - accuracy: 1.0000 - val_loss: 0.3318 - val_accuracy: 0.8667 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9972\n",
            "Epoch 19: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 0.0222 - accuracy: 0.9972 - val_loss: 0.4013 - val_accuracy: 0.8444 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.8223e-05 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 33s 93ms/step - loss: 1.8223e-05 - accuracy: 1.0000 - val_loss: 0.4311 - val_accuracy: 0.8333 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 33s 93ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3605 - val_accuracy: 0.8444 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9972\n",
            "Epoch 22: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 33s 93ms/step - loss: 0.0195 - accuracy: 0.9972 - val_loss: 0.3640 - val_accuracy: 0.8444 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 5.0896e-07 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 5.0896e-07 - accuracy: 1.0000 - val_loss: 0.3704 - val_accuracy: 0.8333 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.9944\n",
            "Epoch 24: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 0.0604 - accuracy: 0.9944 - val_loss: 0.3823 - val_accuracy: 0.8444 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9972\n",
            "Epoch 25: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 0.0196 - accuracy: 0.9972 - val_loss: 0.3807 - val_accuracy: 0.8444 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 3.8149e-04 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 33s 93ms/step - loss: 3.8149e-04 - accuracy: 1.0000 - val_loss: 0.3842 - val_accuracy: 0.8333 - lr: 1.0000e-05\n",
            "Epoch 27/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 2.0139e-04 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 33s 93ms/step - loss: 2.0139e-04 - accuracy: 1.0000 - val_loss: 0.3857 - val_accuracy: 0.8444 - lr: 1.0000e-05\n",
            "Epoch 28/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 2.6094e-07 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 2.6094e-07 - accuracy: 1.0000 - val_loss: 0.3661 - val_accuracy: 0.8333 - lr: 1.0000e-05\n",
            "Epoch 29/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 9.9794e-07 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 34s 93ms/step - loss: 9.9794e-07 - accuracy: 1.0000 - val_loss: 0.3449 - val_accuracy: 0.8556 - lr: 1.0000e-05\n",
            "Epoch 30/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 7.1918e-07 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 33s 93ms/step - loss: 7.1918e-07 - accuracy: 1.0000 - val_loss: 0.4274 - val_accuracy: 0.8444 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.67      0.96      0.79        27\n",
            "      Normal       1.00      0.79      0.88        33\n",
            "Tuberculosis       0.96      0.80      0.87        30\n",
            "\n",
            "    accuracy                           0.84        90\n",
            "   macro avg       0.88      0.85      0.85        90\n",
            "weighted avg       0.89      0.84      0.85        90\n",
            "\n",
            "Fold #4\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.7318e-07 - accuracy: 1.0000\n",
            "Epoch 1: val_accuracy improved from -inf to 0.75556, saving model to  Kmodel1_soft_pre_cate4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate4.h5 /assets\n",
            "360/360 [==============================] - 66s 185ms/step - loss: 1.7318e-07 - accuracy: 1.0000 - val_loss: 0.5099 - val_accuracy: 0.7556 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9972\n",
            "Epoch 2: val_accuracy did not improve from 0.75556\n",
            "360/360 [==============================] - 34s 93ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.5012 - val_accuracy: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.9944\n",
            "Epoch 3: val_accuracy improved from 0.75556 to 0.76667, saving model to  Kmodel1_soft_pre_cate4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate4.h5 /assets\n",
            "360/360 [==============================] - 66s 184ms/step - loss: 0.0215 - accuracy: 0.9944 - val_loss: 0.4357 - val_accuracy: 0.7667 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.4869e-06 - accuracy: 1.0000\n",
            "Epoch 4: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 33s 93ms/step - loss: 1.4869e-06 - accuracy: 1.0000 - val_loss: 0.4701 - val_accuracy: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.2881e-07 - accuracy: 1.0000\n",
            "Epoch 5: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 1.2881e-07 - accuracy: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.7333 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 5.1630e-06 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 5.1630e-06 - accuracy: 1.0000 - val_loss: 0.5117 - val_accuracy: 0.6889 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9972\n",
            "Epoch 7: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 33s 91ms/step - loss: 0.0387 - accuracy: 0.9972 - val_loss: 0.4492 - val_accuracy: 0.7556 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9972\n",
            "Epoch 8: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 33s 90ms/step - loss: 0.0331 - accuracy: 0.9972 - val_loss: 0.5451 - val_accuracy: 0.7222 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 4.0093e-05 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 33s 90ms/step - loss: 4.0093e-05 - accuracy: 1.0000 - val_loss: 0.5355 - val_accuracy: 0.6778 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9972\n",
            "Epoch 10: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 33s 90ms/step - loss: 0.0183 - accuracy: 0.9972 - val_loss: 0.6262 - val_accuracy: 0.6778 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 5.7647e-07 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 33s 90ms/step - loss: 5.7647e-07 - accuracy: 1.0000 - val_loss: 0.5035 - val_accuracy: 0.7222 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 2.7118e-04 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 2.7118e-04 - accuracy: 1.0000 - val_loss: 0.4733 - val_accuracy: 0.7222 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 8.9745e-04 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 33s 93ms/step - loss: 8.9745e-04 - accuracy: 1.0000 - val_loss: 0.5043 - val_accuracy: 0.7111 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9972\n",
            "Epoch 14: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 33s 93ms/step - loss: 0.0331 - accuracy: 0.9972 - val_loss: 0.5293 - val_accuracy: 0.6889 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 8.1129e-08 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 33s 93ms/step - loss: 8.1129e-08 - accuracy: 1.0000 - val_loss: 0.5168 - val_accuracy: 0.6889 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 2.9735e-07 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 33s 93ms/step - loss: 2.9735e-07 - accuracy: 1.0000 - val_loss: 0.4873 - val_accuracy: 0.7000 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 33s 92ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5794 - val_accuracy: 0.6444 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9972\n",
            "Epoch 18: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 33s 93ms/step - loss: 0.0068 - accuracy: 0.9972 - val_loss: 0.4909 - val_accuracy: 0.7667 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.60      1.00      0.75        30\n",
            "      Normal       1.00      0.77      0.87        31\n",
            "Tuberculosis       0.94      0.52      0.67        29\n",
            "\n",
            "    accuracy                           0.77        90\n",
            "   macro avg       0.85      0.76      0.76        90\n",
            "weighted avg       0.85      0.77      0.77        90\n",
            "\n",
            "Fold #5\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 5.1326e-08 - accuracy: 1.0000\n",
            "Epoch 1: val_accuracy improved from -inf to 0.77778, saving model to  Kmodel1_soft_pre_cate5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate5.h5 /assets\n",
            "360/360 [==============================] - 66s 184ms/step - loss: 5.1326e-08 - accuracy: 1.0000 - val_loss: 0.4745 - val_accuracy: 0.7778 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 8.8079e-04 - accuracy: 1.0000\n",
            "Epoch 2: val_accuracy did not improve from 0.77778\n",
            "360/360 [==============================] - 33s 93ms/step - loss: 8.8079e-04 - accuracy: 1.0000 - val_loss: 0.5334 - val_accuracy: 0.7556 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9944\n",
            "Epoch 3: val_accuracy did not improve from 0.77778\n",
            "360/360 [==============================] - 33s 93ms/step - loss: 0.0512 - accuracy: 0.9944 - val_loss: 0.5140 - val_accuracy: 0.7778 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 4.9237e-07 - accuracy: 1.0000\n",
            "Epoch 4: val_accuracy did not improve from 0.77778\n",
            "360/360 [==============================] - 33s 93ms/step - loss: 4.9237e-07 - accuracy: 1.0000 - val_loss: 0.5126 - val_accuracy: 0.7556 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9972\n",
            "Epoch 5: val_accuracy did not improve from 0.77778\n",
            "360/360 [==============================] - 33s 93ms/step - loss: 0.0055 - accuracy: 0.9972 - val_loss: 0.4826 - val_accuracy: 0.7778 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 7.6883e-07 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy did not improve from 0.77778\n",
            "360/360 [==============================] - 33s 93ms/step - loss: 7.6883e-07 - accuracy: 1.0000 - val_loss: 0.5446 - val_accuracy: 0.7556 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 4.7021e-08 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 0.77778\n",
            "360/360 [==============================] - 34s 93ms/step - loss: 4.7021e-08 - accuracy: 1.0000 - val_loss: 0.5265 - val_accuracy: 0.7667 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 9.4374e-08 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 0.77778\n",
            "360/360 [==============================] - 33s 93ms/step - loss: 9.4374e-08 - accuracy: 1.0000 - val_loss: 0.5087 - val_accuracy: 0.7667 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 4.8346e-08 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 0.77778\n",
            "360/360 [==============================] - 33s 93ms/step - loss: 4.8346e-08 - accuracy: 1.0000 - val_loss: 0.5275 - val_accuracy: 0.7556 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 2.9802e-08 - accuracy: 1.0000\n",
            "Epoch 10: val_accuracy did not improve from 0.77778\n",
            "360/360 [==============================] - 33s 93ms/step - loss: 2.9802e-08 - accuracy: 1.0000 - val_loss: 0.5515 - val_accuracy: 0.7556 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 8.5764e-08 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 0.77778\n",
            "360/360 [==============================] - 33s 93ms/step - loss: 8.5764e-08 - accuracy: 1.0000 - val_loss: 0.5474 - val_accuracy: 0.7444 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 6.0929e-08 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.77778\n",
            "360/360 [==============================] - 34s 93ms/step - loss: 6.0929e-08 - accuracy: 1.0000 - val_loss: 0.5364 - val_accuracy: 0.7556 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 4.3048e-08 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.77778\n",
            "360/360 [==============================] - 34s 93ms/step - loss: 4.3048e-08 - accuracy: 1.0000 - val_loss: 0.5447 - val_accuracy: 0.7556 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 2.1193e-08 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 0.77778\n",
            "360/360 [==============================] - 34s 93ms/step - loss: 2.1193e-08 - accuracy: 1.0000 - val_loss: 0.4953 - val_accuracy: 0.7667 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 2.7153e-08 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.77778\n",
            "360/360 [==============================] - 34s 93ms/step - loss: 2.7153e-08 - accuracy: 1.0000 - val_loss: 0.5020 - val_accuracy: 0.7667 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9972\n",
            "Epoch 16: val_accuracy did not improve from 0.77778\n",
            "360/360 [==============================] - 34s 93ms/step - loss: 0.0071 - accuracy: 0.9972 - val_loss: 0.5135 - val_accuracy: 0.7556 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.64      0.90      0.75        31\n",
            "      Normal       1.00      0.64      0.78        28\n",
            "Tuberculosis       0.79      0.71      0.75        31\n",
            "\n",
            "    accuracy                           0.76        90\n",
            "   macro avg       0.81      0.75      0.76        90\n",
            "weighted avg       0.80      0.76      0.76        90\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.58      0.92      0.72       150\n",
            "      Normal       0.99      0.68      0.81       150\n",
            "Tuberculosis       0.85      0.63      0.72       150\n",
            "\n",
            "    accuracy                           0.74       450\n",
            "   macro avg       0.81      0.74      0.75       450\n",
            "weighted avg       0.81      0.74      0.75       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1 soft pre cate adam\n"
      ],
      "metadata": {
        "id": "6ptGRCe5StVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 1\n",
        "filepath = \"Kmodel1_soft_pre_cate_adam.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "id": "r1s9MzgGStVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel1_soft_pre_cate_adam{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "55Vty_AUStVV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff319df9-7766-4e21-ee1a-69b6d031601f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold #1\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0928 - accuracy: 0.3972\n",
            "Epoch 1: val_accuracy improved from -inf to 0.55556, saving model to  Kmodel1_soft_pre_cate_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_adam1.h5 /assets\n",
            "360/360 [==============================] - 72s 177ms/step - loss: 1.0928 - accuracy: 0.3972 - val_loss: 0.8553 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.8239 - accuracy: 0.5694\n",
            "Epoch 2: val_accuracy did not improve from 0.55556\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 0.8239 - accuracy: 0.5694 - val_loss: 1.7056 - val_accuracy: 0.5333 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.7614 - accuracy: 0.5861\n",
            "Epoch 3: val_accuracy improved from 0.55556 to 0.64444, saving model to  Kmodel1_soft_pre_cate_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_adam1.h5 /assets\n",
            "360/360 [==============================] - 62s 174ms/step - loss: 0.7614 - accuracy: 0.5861 - val_loss: 0.7851 - val_accuracy: 0.6444 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6513 - accuracy: 0.6833\n",
            "Epoch 4: val_accuracy improved from 0.64444 to 0.76667, saving model to  Kmodel1_soft_pre_cate_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_adam1.h5 /assets\n",
            "360/360 [==============================] - 63s 175ms/step - loss: 0.6513 - accuracy: 0.6833 - val_loss: 0.6624 - val_accuracy: 0.7667 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.6252 - accuracy: 0.6861\n",
            "Epoch 5: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 0.6252 - accuracy: 0.6861 - val_loss: 1.6037 - val_accuracy: 0.6444 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.5842 - accuracy: 0.7167\n",
            "Epoch 6: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 0.5842 - accuracy: 0.7167 - val_loss: 1.9140 - val_accuracy: 0.6778 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.5373 - accuracy: 0.7444\n",
            "Epoch 7: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 0.5373 - accuracy: 0.7444 - val_loss: 0.9077 - val_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.5088 - accuracy: 0.7667\n",
            "Epoch 8: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 0.5088 - accuracy: 0.7667 - val_loss: 0.8936 - val_accuracy: 0.7444 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.4461 - accuracy: 0.8278\n",
            "Epoch 9: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 0.4461 - accuracy: 0.8278 - val_loss: 1.2766 - val_accuracy: 0.7556 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.4092 - accuracy: 0.8250\n",
            "Epoch 10: val_accuracy did not improve from 0.76667\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 0.4092 - accuracy: 0.8250 - val_loss: 1.3949 - val_accuracy: 0.7444 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.2942 - accuracy: 0.9028\n",
            "Epoch 11: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 0.2942 - accuracy: 0.9028 - val_loss: 1.0995 - val_accuracy: 0.7111 - lr: 5.0000e-05\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.2704 - accuracy: 0.8833\n",
            "Epoch 12: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 0.2704 - accuracy: 0.8833 - val_loss: 0.9732 - val_accuracy: 0.7667 - lr: 5.0000e-05\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.1591 - accuracy: 0.9528\n",
            "Epoch 13: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 0.1591 - accuracy: 0.9528 - val_loss: 1.5750 - val_accuracy: 0.7556 - lr: 5.0000e-05\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.1787 - accuracy: 0.9194\n",
            "Epoch 14: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 0.1787 - accuracy: 0.9194 - val_loss: 1.8921 - val_accuracy: 0.7333 - lr: 5.0000e-05\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.1279 - accuracy: 0.9528\n",
            "Epoch 15: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 0.1279 - accuracy: 0.9528 - val_loss: 2.1553 - val_accuracy: 0.7222 - lr: 5.0000e-05\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0946 - accuracy: 0.9750\n",
            "Epoch 16: val_accuracy did not improve from 0.76667\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 0.0946 - accuracy: 0.9750 - val_loss: 3.1962 - val_accuracy: 0.7222 - lr: 5.0000e-05\n",
            "Epoch 17/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0638 - accuracy: 0.9750\n",
            "Epoch 17: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 0.0638 - accuracy: 0.9750 - val_loss: 2.1739 - val_accuracy: 0.7222 - lr: 2.5000e-05\n",
            "Epoch 18/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0541 - accuracy: 0.9889\n",
            "Epoch 18: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 0.0541 - accuracy: 0.9889 - val_loss: 1.8428 - val_accuracy: 0.7444 - lr: 2.5000e-05\n",
            "Epoch 19/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.9861\n",
            "Epoch 19: val_accuracy did not improve from 0.76667\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 0.0277 - accuracy: 0.9861 - val_loss: 1.7082 - val_accuracy: 0.7000 - lr: 2.5000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.71      0.43      0.53        28\n",
            "      Normal       0.78      1.00      0.87        31\n",
            "Tuberculosis       0.61      0.65      0.62        31\n",
            "\n",
            "    accuracy                           0.70        90\n",
            "   macro avg       0.70      0.69      0.68        90\n",
            "weighted avg       0.70      0.70      0.68        90\n",
            "\n",
            "Fold #2\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.2402 - accuracy: 0.9194\n",
            "Epoch 1: val_accuracy improved from -inf to 0.80000, saving model to  Kmodel1_soft_pre_cate_adam2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_adam2.h5 /assets\n",
            "360/360 [==============================] - 63s 175ms/step - loss: 0.2402 - accuracy: 0.9194 - val_loss: 0.7169 - val_accuracy: 0.8000 - lr: 2.5000e-05\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.1352 - accuracy: 0.9611\n",
            "Epoch 2: val_accuracy improved from 0.80000 to 0.86667, saving model to  Kmodel1_soft_pre_cate_adam2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_adam2.h5 /assets\n",
            "360/360 [==============================] - 63s 175ms/step - loss: 0.1352 - accuracy: 0.9611 - val_loss: 0.3544 - val_accuracy: 0.8667 - lr: 2.5000e-05\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.1004 - accuracy: 0.9750\n",
            "Epoch 3: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 28s 79ms/step - loss: 0.1004 - accuracy: 0.9750 - val_loss: 0.5042 - val_accuracy: 0.8111 - lr: 2.5000e-05\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.1088 - accuracy: 0.9583\n",
            "Epoch 4: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 28s 78ms/step - loss: 0.1088 - accuracy: 0.9583 - val_loss: 0.4115 - val_accuracy: 0.8333 - lr: 2.5000e-05\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.9778\n",
            "Epoch 5: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 28s 78ms/step - loss: 0.0790 - accuracy: 0.9778 - val_loss: 0.5602 - val_accuracy: 0.7889 - lr: 2.5000e-05\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 0.9917\n",
            "Epoch 6: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 28s 78ms/step - loss: 0.0403 - accuracy: 0.9917 - val_loss: 0.4293 - val_accuracy: 0.8333 - lr: 2.5000e-05\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9972\n",
            "Epoch 7: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 28s 79ms/step - loss: 0.0259 - accuracy: 0.9972 - val_loss: 0.5409 - val_accuracy: 0.8111 - lr: 2.5000e-05\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.9889\n",
            "Epoch 8: val_accuracy did not improve from 0.86667\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "360/360 [==============================] - 28s 78ms/step - loss: 0.0416 - accuracy: 0.9889 - val_loss: 0.7030 - val_accuracy: 0.7889 - lr: 2.5000e-05\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9944\n",
            "Epoch 9: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 28s 78ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.5637 - val_accuracy: 0.8000 - lr: 1.2500e-05\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9889\n",
            "Epoch 10: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 28s 78ms/step - loss: 0.0340 - accuracy: 0.9889 - val_loss: 0.4699 - val_accuracy: 0.8556 - lr: 1.2500e-05\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9917\n",
            "Epoch 11: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 28s 77ms/step - loss: 0.0336 - accuracy: 0.9917 - val_loss: 0.4549 - val_accuracy: 0.8556 - lr: 1.2500e-05\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 28s 79ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4524 - val_accuracy: 0.8444 - lr: 1.2500e-05\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9972\n",
            "Epoch 13: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 28s 78ms/step - loss: 0.0228 - accuracy: 0.9972 - val_loss: 0.5488 - val_accuracy: 0.7778 - lr: 1.2500e-05\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 0.86667\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "360/360 [==============================] - 28s 78ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.4430 - val_accuracy: 0.8556 - lr: 1.2500e-05\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 28s 78ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.4972 - val_accuracy: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 28s 78ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.4668 - val_accuracy: 0.8333 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9889\n",
            "Epoch 17: val_accuracy did not improve from 0.86667\n",
            "360/360 [==============================] - 28s 78ms/step - loss: 0.0221 - accuracy: 0.9889 - val_loss: 0.4557 - val_accuracy: 0.8222 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.96      0.71      0.81        34\n",
            "      Normal       0.75      1.00      0.86        27\n",
            "Tuberculosis       0.79      0.79      0.79        29\n",
            "\n",
            "    accuracy                           0.82        90\n",
            "   macro avg       0.83      0.83      0.82        90\n",
            "weighted avg       0.84      0.82      0.82        90\n",
            "\n",
            "Fold #3\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 1: val_accuracy improved from -inf to 0.94444, saving model to  Kmodel1_soft_pre_cate_adam3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_adam3.h5 /assets\n",
            "360/360 [==============================] - 62s 172ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.4183 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 0.9889\n",
            "Epoch 2: val_accuracy did not improve from 0.94444\n",
            "360/360 [==============================] - 28s 79ms/step - loss: 0.0306 - accuracy: 0.9889 - val_loss: 0.4389 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 1.0000\n",
            "Epoch 3: val_accuracy did not improve from 0.94444\n",
            "360/360 [==============================] - 28s 78ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4301 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 4: val_accuracy did not improve from 0.94444\n",
            "360/360 [==============================] - 28s 79ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.5213 - val_accuracy: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 5: val_accuracy did not improve from 0.94444\n",
            "360/360 [==============================] - 28s 78ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.4549 - val_accuracy: 0.9111 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy did not improve from 0.94444\n",
            "360/360 [==============================] - 28s 79ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4589 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 0.94444\n",
            "360/360 [==============================] - 28s 79ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4529 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9944\n",
            "Epoch 8: val_accuracy did not improve from 0.94444\n",
            "360/360 [==============================] - 28s 79ms/step - loss: 0.0235 - accuracy: 0.9944 - val_loss: 0.3769 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9972\n",
            "Epoch 9: val_accuracy did not improve from 0.94444\n",
            "360/360 [==============================] - 28s 79ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.4500 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9944\n",
            "Epoch 10: val_accuracy did not improve from 0.94444\n",
            "360/360 [==============================] - 28s 78ms/step - loss: 0.0108 - accuracy: 0.9944 - val_loss: 0.4331 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 0.94444\n",
            "360/360 [==============================] - 28s 79ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3913 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.94444\n",
            "360/360 [==============================] - 28s 79ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4262 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.94444\n",
            "360/360 [==============================] - 28s 79ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4100 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 0.94444\n",
            "360/360 [==============================] - 28s 79ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4265 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.94444\n",
            "360/360 [==============================] - 28s 79ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.94444\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4356 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.92      0.81      0.86        27\n",
            "      Normal       0.97      1.00      0.99        33\n",
            "Tuberculosis       0.88      0.93      0.90        30\n",
            "\n",
            "    accuracy                           0.92        90\n",
            "   macro avg       0.92      0.92      0.92        90\n",
            "weighted avg       0.92      0.92      0.92        90\n",
            "\n",
            "Fold #4\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 1: val_accuracy improved from -inf to 0.87778, saving model to  Kmodel1_soft_pre_cate_adam4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_adam4.h5 /assets\n",
            "360/360 [==============================] - 64s 177ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5282 - val_accuracy: 0.8778 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9972\n",
            "Epoch 2: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.5799 - val_accuracy: 0.8667 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9944\n",
            "Epoch 3: val_accuracy improved from 0.87778 to 0.88889, saving model to  Kmodel1_soft_pre_cate_adam4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_adam4.h5 /assets\n",
            "360/360 [==============================] - 63s 176ms/step - loss: 0.0158 - accuracy: 0.9944 - val_loss: 0.3829 - val_accuracy: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 4: val_accuracy did not improve from 0.88889\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3901 - val_accuracy: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9917\n",
            "Epoch 5: val_accuracy did not improve from 0.88889\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 0.0180 - accuracy: 0.9917 - val_loss: 0.5948 - val_accuracy: 0.8444 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy did not improve from 0.88889\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.5785 - val_accuracy: 0.8667 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 0.88889\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5854 - val_accuracy: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9972\n",
            "Epoch 8: val_accuracy did not improve from 0.88889\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 0.0043 - accuracy: 0.9972 - val_loss: 0.5805 - val_accuracy: 0.8667 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.9944\n",
            "Epoch 9: val_accuracy did not improve from 0.88889\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 0.0231 - accuracy: 0.9944 - val_loss: 0.5587 - val_accuracy: 0.8444 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 10: val_accuracy did not improve from 0.88889\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5296 - val_accuracy: 0.8667 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9972\n",
            "Epoch 11: val_accuracy did not improve from 0.88889\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.5571 - val_accuracy: 0.8667 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.88889\n",
            "360/360 [==============================] - 28s 79ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5512 - val_accuracy: 0.8778 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9972\n",
            "Epoch 13: val_accuracy did not improve from 0.88889\n",
            "360/360 [==============================] - 28s 79ms/step - loss: 0.0101 - accuracy: 0.9972 - val_loss: 0.5585 - val_accuracy: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 8.9857e-04 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy improved from 0.88889 to 0.90000, saving model to  Kmodel1_soft_pre_cate_adam4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_adam4.h5 /assets\n",
            "360/360 [==============================] - 64s 177ms/step - loss: 8.9857e-04 - accuracy: 1.0000 - val_loss: 0.5299 - val_accuracy: 0.9000 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9972\n",
            "Epoch 15: val_accuracy did not improve from 0.90000\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 0.0183 - accuracy: 0.9972 - val_loss: 0.5854 - val_accuracy: 0.8444 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.90000\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5595 - val_accuracy: 0.8778 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 0.90000\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6116 - val_accuracy: 0.8556 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 0.90000\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.5885 - val_accuracy: 0.8556 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 0.90000\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6082 - val_accuracy: 0.8556 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 9.5785e-04 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.90000\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 9.5785e-04 - accuracy: 1.0000 - val_loss: 0.5488 - val_accuracy: 0.8778 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 6.6992e-04 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 0.90000\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 6.6992e-04 - accuracy: 1.0000 - val_loss: 0.6091 - val_accuracy: 0.8222 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 5.8293e-04 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 0.90000\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 5.8293e-04 - accuracy: 1.0000 - val_loss: 0.5512 - val_accuracy: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 5.3730e-04 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.90000\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 5.3730e-04 - accuracy: 1.0000 - val_loss: 0.5770 - val_accuracy: 0.8667 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 4.7932e-04 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.90000\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 4.7932e-04 - accuracy: 1.0000 - val_loss: 0.5612 - val_accuracy: 0.8667 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 7.6593e-04 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 0.90000\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 7.6593e-04 - accuracy: 1.0000 - val_loss: 0.5642 - val_accuracy: 0.8556 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.90000\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6199 - val_accuracy: 0.8778 - lr: 1.0000e-05\n",
            "Epoch 27/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 4.8834e-04 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 0.90000\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 4.8834e-04 - accuracy: 1.0000 - val_loss: 0.6436 - val_accuracy: 0.8556 - lr: 1.0000e-05\n",
            "Epoch 28/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 4.4771e-04 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.90000\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 4.4771e-04 - accuracy: 1.0000 - val_loss: 0.5989 - val_accuracy: 0.8667 - lr: 1.0000e-05\n",
            "Epoch 29/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 3.5139e-04 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.90000\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 3.5139e-04 - accuracy: 1.0000 - val_loss: 0.5876 - val_accuracy: 0.8778 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.96      0.80      0.87        30\n",
            "      Normal       0.84      1.00      0.91        31\n",
            "Tuberculosis       0.86      0.83      0.84        29\n",
            "\n",
            "    accuracy                           0.88        90\n",
            "   macro avg       0.88      0.88      0.88        90\n",
            "weighted avg       0.88      0.88      0.88        90\n",
            "\n",
            "Fold #5\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 4.0702e-04 - accuracy: 1.0000\n",
            "Epoch 1: val_accuracy improved from -inf to 0.84444, saving model to  Kmodel1_soft_pre_cate_adam5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_adam5.h5 /assets\n",
            "360/360 [==============================] - 63s 176ms/step - loss: 4.0702e-04 - accuracy: 1.0000 - val_loss: 0.6640 - val_accuracy: 0.8444 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 0.9889\n",
            "Epoch 2: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 0.0430 - accuracy: 0.9889 - val_loss: 0.9742 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9972\n",
            "Epoch 3: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.8128 - val_accuracy: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 4: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8454 - val_accuracy: 0.8000 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 8.1874e-04 - accuracy: 1.0000\n",
            "Epoch 5: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 8.1874e-04 - accuracy: 1.0000 - val_loss: 0.9168 - val_accuracy: 0.8111 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 7.6837e-04 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 7.6837e-04 - accuracy: 1.0000 - val_loss: 0.8547 - val_accuracy: 0.8111 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9944\n",
            "Epoch 7: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 0.0148 - accuracy: 0.9944 - val_loss: 0.8788 - val_accuracy: 0.8222 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 5.0702e-04 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 5.0702e-04 - accuracy: 1.0000 - val_loss: 0.7677 - val_accuracy: 0.8333 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 6.1578e-04 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 0.84444\n",
            "360/360 [==============================] - 29s 81ms/step - loss: 6.1578e-04 - accuracy: 1.0000 - val_loss: 0.7944 - val_accuracy: 0.8111 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 10: val_accuracy improved from 0.84444 to 0.85556, saving model to  Kmodel1_soft_pre_cate_adam5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_adam5.h5 /assets\n",
            "360/360 [==============================] - 63s 176ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6242 - val_accuracy: 0.8556 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 5.1332e-04 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 0.85556\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 5.1332e-04 - accuracy: 1.0000 - val_loss: 0.7229 - val_accuracy: 0.8556 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 3.7554e-04 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.85556\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 3.7554e-04 - accuracy: 1.0000 - val_loss: 0.6999 - val_accuracy: 0.8556 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 3.5914e-04 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.85556\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 3.5914e-04 - accuracy: 1.0000 - val_loss: 0.7037 - val_accuracy: 0.8556 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 5.8368e-04 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 0.85556\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 5.8368e-04 - accuracy: 1.0000 - val_loss: 0.9567 - val_accuracy: 0.8111 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 3.8614e-04 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.85556\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 3.8614e-04 - accuracy: 1.0000 - val_loss: 0.8296 - val_accuracy: 0.8222 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 3.1833e-04 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.85556\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 3.1833e-04 - accuracy: 1.0000 - val_loss: 0.8243 - val_accuracy: 0.8333 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 2.8850e-04 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 0.85556\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 2.8850e-04 - accuracy: 1.0000 - val_loss: 0.6645 - val_accuracy: 0.8556 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 4.0729e-04 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 0.85556\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 4.0729e-04 - accuracy: 1.0000 - val_loss: 0.6217 - val_accuracy: 0.8444 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 2.4672e-04 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 0.85556\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 2.4672e-04 - accuracy: 1.0000 - val_loss: 0.6475 - val_accuracy: 0.8444 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 3.0269e-04 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.85556\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 3.0269e-04 - accuracy: 1.0000 - val_loss: 0.7080 - val_accuracy: 0.8333 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 2.3737e-04 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 0.85556\n",
            "360/360 [==============================] - 29s 79ms/step - loss: 2.3737e-04 - accuracy: 1.0000 - val_loss: 0.8563 - val_accuracy: 0.8222 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9972\n",
            "Epoch 22: val_accuracy did not improve from 0.85556\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 0.0218 - accuracy: 0.9972 - val_loss: 0.7665 - val_accuracy: 0.7778 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 4.0052e-04 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.85556\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 4.0052e-04 - accuracy: 1.0000 - val_loss: 0.7390 - val_accuracy: 0.8333 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 5.4929e-04 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy improved from 0.85556 to 0.87778, saving model to  Kmodel1_soft_pre_cate_adam5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_adam5.h5 /assets\n",
            "360/360 [==============================] - 62s 174ms/step - loss: 5.4929e-04 - accuracy: 1.0000 - val_loss: 0.6255 - val_accuracy: 0.8778 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4686 - val_accuracy: 0.7556 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9972\n",
            "Epoch 26: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 29s 81ms/step - loss: 0.0163 - accuracy: 0.9972 - val_loss: 0.5515 - val_accuracy: 0.8556 - lr: 1.0000e-05\n",
            "Epoch 27/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 4.2348e-04 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 4.2348e-04 - accuracy: 1.0000 - val_loss: 0.6005 - val_accuracy: 0.8556 - lr: 1.0000e-05\n",
            "Epoch 28/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 3.9380e-04 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 3.9380e-04 - accuracy: 1.0000 - val_loss: 0.7377 - val_accuracy: 0.8444 - lr: 1.0000e-05\n",
            "Epoch 29/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.9257e-04 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 29s 82ms/step - loss: 1.9257e-04 - accuracy: 1.0000 - val_loss: 0.7234 - val_accuracy: 0.8556 - lr: 1.0000e-05\n",
            "Epoch 30/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9944\n",
            "Epoch 30: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 29s 81ms/step - loss: 0.0219 - accuracy: 0.9944 - val_loss: 0.9189 - val_accuracy: 0.8333 - lr: 1.0000e-05\n",
            "Epoch 31/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9944\n",
            "Epoch 31: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 29s 81ms/step - loss: 0.0107 - accuracy: 0.9944 - val_loss: 1.1265 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
            "Epoch 32/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9944\n",
            "Epoch 32: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 29s 81ms/step - loss: 0.0083 - accuracy: 0.9944 - val_loss: 0.5902 - val_accuracy: 0.8778 - lr: 1.0000e-05\n",
            "Epoch 33/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 7.0212e-04 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 29s 81ms/step - loss: 7.0212e-04 - accuracy: 1.0000 - val_loss: 0.7131 - val_accuracy: 0.8556 - lr: 1.0000e-05\n",
            "Epoch 34/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 3.9520e-04 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 29s 81ms/step - loss: 3.9520e-04 - accuracy: 1.0000 - val_loss: 0.6893 - val_accuracy: 0.8556 - lr: 1.0000e-05\n",
            "Epoch 35/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9944\n",
            "Epoch 35: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 29s 81ms/step - loss: 0.0136 - accuracy: 0.9944 - val_loss: 0.9198 - val_accuracy: 0.7889 - lr: 1.0000e-05\n",
            "Epoch 36/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 4.4043e-04 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 29s 81ms/step - loss: 4.4043e-04 - accuracy: 1.0000 - val_loss: 0.8723 - val_accuracy: 0.8111 - lr: 1.0000e-05\n",
            "Epoch 37/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 0.9944\n",
            "Epoch 37: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 0.0224 - accuracy: 0.9944 - val_loss: 0.7134 - val_accuracy: 0.8333 - lr: 1.0000e-05\n",
            "Epoch 38/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 6.2903e-04 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 6.2903e-04 - accuracy: 1.0000 - val_loss: 0.7968 - val_accuracy: 0.8222 - lr: 1.0000e-05\n",
            "Epoch 39/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 5.3629e-04 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.87778\n",
            "360/360 [==============================] - 29s 80ms/step - loss: 5.3629e-04 - accuracy: 1.0000 - val_loss: 0.6164 - val_accuracy: 0.8667 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.68      0.81        31\n",
            "      Normal       0.93      0.96      0.95        28\n",
            "Tuberculosis       0.75      0.97      0.85        31\n",
            "\n",
            "    accuracy                           0.87        90\n",
            "   macro avg       0.89      0.87      0.87        90\n",
            "weighted avg       0.89      0.87      0.86        90\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.92      0.69      0.79       150\n",
            "      Normal       0.85      0.99      0.91       150\n",
            "Tuberculosis       0.77      0.83      0.80       150\n",
            "\n",
            "    accuracy                           0.84       450\n",
            "   macro avg       0.85      0.84      0.83       450\n",
            "weighted avg       0.85      0.84      0.83       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1 soft pre cate sgd\n"
      ],
      "metadata": {
        "id": "DKND6UpAStVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 1\n",
        "filepath = \"Kmodel1_soft_pre_cate_sgd.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "id": "x6PaOOyHStVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel1_soft_pre_cate_sgd{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "6HcHnNkAStVW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35d6afaa-0ac2-44dd-cfe7-dd754a5de988"
      },
      "execution_count": 20,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold #1\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.1100 - accuracy: 0.2861\n",
            "Epoch 1: val_accuracy improved from -inf to 0.31111, saving model to  Kmodel1_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_sgd1.h5 /assets\n",
            "360/360 [==============================] - 66s 168ms/step - loss: 1.1100 - accuracy: 0.2861 - val_loss: 1.1377 - val_accuracy: 0.3111 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.1011 - accuracy: 0.3528\n",
            "Epoch 2: val_accuracy did not improve from 0.31111\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.1011 - accuracy: 0.3528 - val_loss: 1.1321 - val_accuracy: 0.2778 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.1011 - accuracy: 0.3472\n",
            "Epoch 3: val_accuracy improved from 0.31111 to 0.32222, saving model to  Kmodel1_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_sgd1.h5 /assets\n",
            "360/360 [==============================] - 59s 164ms/step - loss: 1.1011 - accuracy: 0.3472 - val_loss: 1.1345 - val_accuracy: 0.3222 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.1024 - accuracy: 0.3472\n",
            "Epoch 4: val_accuracy improved from 0.32222 to 0.35556, saving model to  Kmodel1_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_sgd1.h5 /assets\n",
            "360/360 [==============================] - 59s 164ms/step - loss: 1.1024 - accuracy: 0.3472 - val_loss: 1.1312 - val_accuracy: 0.3556 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.1020 - accuracy: 0.3056\n",
            "Epoch 5: val_accuracy did not improve from 0.35556\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.1020 - accuracy: 0.3056 - val_loss: 1.1258 - val_accuracy: 0.3222 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.1024 - accuracy: 0.3306\n",
            "Epoch 6: val_accuracy did not improve from 0.35556\n",
            "360/360 [==============================] - 26s 73ms/step - loss: 1.1024 - accuracy: 0.3306 - val_loss: 1.1315 - val_accuracy: 0.3444 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.1019 - accuracy: 0.3278\n",
            "Epoch 7: val_accuracy did not improve from 0.35556\n",
            "360/360 [==============================] - 26s 73ms/step - loss: 1.1019 - accuracy: 0.3278 - val_loss: 1.1240 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.1000 - accuracy: 0.3389\n",
            "Epoch 8: val_accuracy improved from 0.35556 to 0.36667, saving model to  Kmodel1_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_sgd1.h5 /assets\n",
            "360/360 [==============================] - 59s 164ms/step - loss: 1.1000 - accuracy: 0.3389 - val_loss: 1.1157 - val_accuracy: 0.3667 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.1008 - accuracy: 0.3139\n",
            "Epoch 9: val_accuracy did not improve from 0.36667\n",
            "360/360 [==============================] - 26s 73ms/step - loss: 1.1008 - accuracy: 0.3139 - val_loss: 1.1233 - val_accuracy: 0.3000 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.1006 - accuracy: 0.3361\n",
            "Epoch 10: val_accuracy did not improve from 0.36667\n",
            "360/360 [==============================] - 26s 73ms/step - loss: 1.1006 - accuracy: 0.3361 - val_loss: 1.1268 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0999 - accuracy: 0.3556\n",
            "Epoch 11: val_accuracy did not improve from 0.36667\n",
            "360/360 [==============================] - 26s 73ms/step - loss: 1.0999 - accuracy: 0.3556 - val_loss: 1.1229 - val_accuracy: 0.3222 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0984 - accuracy: 0.3611\n",
            "Epoch 12: val_accuracy did not improve from 0.36667\n",
            "360/360 [==============================] - 26s 73ms/step - loss: 1.0984 - accuracy: 0.3611 - val_loss: 1.1286 - val_accuracy: 0.3444 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0998 - accuracy: 0.3250\n",
            "Epoch 13: val_accuracy improved from 0.36667 to 0.37778, saving model to  Kmodel1_soft_pre_cate_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_sgd1.h5 /assets\n",
            "360/360 [==============================] - 59s 163ms/step - loss: 1.0998 - accuracy: 0.3250 - val_loss: 1.1208 - val_accuracy: 0.3778 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0981 - accuracy: 0.3472\n",
            "Epoch 14: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 26s 73ms/step - loss: 1.0981 - accuracy: 0.3472 - val_loss: 1.1226 - val_accuracy: 0.3667 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0972 - accuracy: 0.3694\n",
            "Epoch 15: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 26s 73ms/step - loss: 1.0972 - accuracy: 0.3694 - val_loss: 1.1253 - val_accuracy: 0.3111 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.3222\n",
            "Epoch 16: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0986 - accuracy: 0.3222 - val_loss: 1.1171 - val_accuracy: 0.3667 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0957 - accuracy: 0.3889\n",
            "Epoch 17: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0957 - accuracy: 0.3889 - val_loss: 1.1238 - val_accuracy: 0.3444 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0960 - accuracy: 0.3361\n",
            "Epoch 18: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0960 - accuracy: 0.3361 - val_loss: 1.1253 - val_accuracy: 0.3222 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0966 - accuracy: 0.3250\n",
            "Epoch 19: val_accuracy did not improve from 0.37778\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0966 - accuracy: 0.3250 - val_loss: 1.1216 - val_accuracy: 0.3444 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0936 - accuracy: 0.3917\n",
            "Epoch 20: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 26s 73ms/step - loss: 1.0936 - accuracy: 0.3917 - val_loss: 1.1144 - val_accuracy: 0.3333 - lr: 5.0000e-05\n",
            "Epoch 21/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0922 - accuracy: 0.4028\n",
            "Epoch 21: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0922 - accuracy: 0.4028 - val_loss: 1.1105 - val_accuracy: 0.3667 - lr: 5.0000e-05\n",
            "Epoch 22/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0921 - accuracy: 0.3667\n",
            "Epoch 22: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 26s 73ms/step - loss: 1.0921 - accuracy: 0.3667 - val_loss: 1.1100 - val_accuracy: 0.3556 - lr: 5.0000e-05\n",
            "Epoch 23/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0927 - accuracy: 0.4222\n",
            "Epoch 23: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 26s 73ms/step - loss: 1.0927 - accuracy: 0.4222 - val_loss: 1.1149 - val_accuracy: 0.3333 - lr: 5.0000e-05\n",
            "Epoch 24/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0929 - accuracy: 0.3806\n",
            "Epoch 24: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0929 - accuracy: 0.3806 - val_loss: 1.1067 - val_accuracy: 0.3556 - lr: 5.0000e-05\n",
            "Epoch 25/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0932 - accuracy: 0.3944\n",
            "Epoch 25: val_accuracy did not improve from 0.37778\n",
            "\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "360/360 [==============================] - 26s 73ms/step - loss: 1.0932 - accuracy: 0.3944 - val_loss: 1.1108 - val_accuracy: 0.3667 - lr: 5.0000e-05\n",
            "Epoch 26/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0909 - accuracy: 0.4500\n",
            "Epoch 26: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0909 - accuracy: 0.4500 - val_loss: 1.1185 - val_accuracy: 0.3667 - lr: 2.5000e-05\n",
            "Epoch 27/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0902 - accuracy: 0.4278\n",
            "Epoch 27: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 26s 73ms/step - loss: 1.0902 - accuracy: 0.4278 - val_loss: 1.1100 - val_accuracy: 0.3333 - lr: 2.5000e-05\n",
            "Epoch 28/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0888 - accuracy: 0.3944\n",
            "Epoch 28: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 26s 73ms/step - loss: 1.0888 - accuracy: 0.3944 - val_loss: 1.1116 - val_accuracy: 0.3444 - lr: 2.5000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.35      0.21      0.27        28\n",
            "      Normal       0.30      0.19      0.24        31\n",
            "Tuberculosis       0.36      0.61      0.45        31\n",
            "\n",
            "    accuracy                           0.34        90\n",
            "   macro avg       0.34      0.34      0.32        90\n",
            "weighted avg       0.34      0.34      0.32        90\n",
            "\n",
            "Fold #2\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0899 - accuracy: 0.4417\n",
            "Epoch 1: val_accuracy improved from -inf to 0.36667, saving model to  Kmodel1_soft_pre_cate_sgd2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_sgd2.h5 /assets\n",
            "360/360 [==============================] - 59s 165ms/step - loss: 1.0899 - accuracy: 0.4417 - val_loss: 1.1030 - val_accuracy: 0.3667 - lr: 2.5000e-05\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0887 - accuracy: 0.4889\n",
            "Epoch 2: val_accuracy did not improve from 0.36667\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0887 - accuracy: 0.4889 - val_loss: 1.1019 - val_accuracy: 0.3667 - lr: 2.5000e-05\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0868 - accuracy: 0.4722\n",
            "Epoch 3: val_accuracy did not improve from 0.36667\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0868 - accuracy: 0.4722 - val_loss: 1.1037 - val_accuracy: 0.3444 - lr: 2.5000e-05\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0887 - accuracy: 0.4417\n",
            "Epoch 4: val_accuracy did not improve from 0.36667\n",
            "360/360 [==============================] - 26s 73ms/step - loss: 1.0887 - accuracy: 0.4417 - val_loss: 1.0992 - val_accuracy: 0.3556 - lr: 2.5000e-05\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0904 - accuracy: 0.4250\n",
            "Epoch 5: val_accuracy did not improve from 0.36667\n",
            "360/360 [==============================] - 26s 73ms/step - loss: 1.0904 - accuracy: 0.4250 - val_loss: 1.1062 - val_accuracy: 0.3667 - lr: 2.5000e-05\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0871 - accuracy: 0.4667\n",
            "Epoch 6: val_accuracy did not improve from 0.36667\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0871 - accuracy: 0.4667 - val_loss: 1.1083 - val_accuracy: 0.3444 - lr: 2.5000e-05\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0884 - accuracy: 0.4167\n",
            "Epoch 7: val_accuracy did not improve from 0.36667\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "360/360 [==============================] - 26s 73ms/step - loss: 1.0884 - accuracy: 0.4167 - val_loss: 1.0994 - val_accuracy: 0.3444 - lr: 2.5000e-05\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0856 - accuracy: 0.4806\n",
            "Epoch 8: val_accuracy did not improve from 0.36667\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0856 - accuracy: 0.4806 - val_loss: 1.0989 - val_accuracy: 0.3556 - lr: 1.2500e-05\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0893 - accuracy: 0.4278\n",
            "Epoch 9: val_accuracy did not improve from 0.36667\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0893 - accuracy: 0.4278 - val_loss: 1.1088 - val_accuracy: 0.3333 - lr: 1.2500e-05\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0897 - accuracy: 0.4139\n",
            "Epoch 10: val_accuracy did not improve from 0.36667\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0897 - accuracy: 0.4139 - val_loss: 1.0988 - val_accuracy: 0.3556 - lr: 1.2500e-05\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0907 - accuracy: 0.4139\n",
            "Epoch 11: val_accuracy did not improve from 0.36667\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0907 - accuracy: 0.4139 - val_loss: 1.1018 - val_accuracy: 0.3556 - lr: 1.2500e-05\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0888 - accuracy: 0.4194\n",
            "Epoch 12: val_accuracy did not improve from 0.36667\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0888 - accuracy: 0.4194 - val_loss: 1.1039 - val_accuracy: 0.3222 - lr: 1.2500e-05\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0870 - accuracy: 0.4472\n",
            "Epoch 13: val_accuracy improved from 0.36667 to 0.37778, saving model to  Kmodel1_soft_pre_cate_sgd2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_sgd2.h5 /assets\n",
            "360/360 [==============================] - 59s 164ms/step - loss: 1.0870 - accuracy: 0.4472 - val_loss: 1.0939 - val_accuracy: 0.3778 - lr: 1.2500e-05\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0863 - accuracy: 0.4472\n",
            "Epoch 14: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0863 - accuracy: 0.4472 - val_loss: 1.0935 - val_accuracy: 0.3667 - lr: 1.2500e-05\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0889 - accuracy: 0.4472\n",
            "Epoch 15: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0889 - accuracy: 0.4472 - val_loss: 1.1023 - val_accuracy: 0.3333 - lr: 1.2500e-05\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0864 - accuracy: 0.4833\n",
            "Epoch 16: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0864 - accuracy: 0.4833 - val_loss: 1.0986 - val_accuracy: 0.3444 - lr: 1.2500e-05\n",
            "Epoch 17/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0907 - accuracy: 0.4500\n",
            "Epoch 17: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0907 - accuracy: 0.4500 - val_loss: 1.0992 - val_accuracy: 0.3667 - lr: 1.2500e-05\n",
            "Epoch 18/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0893 - accuracy: 0.4611\n",
            "Epoch 18: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 1.0893 - accuracy: 0.4611 - val_loss: 1.1088 - val_accuracy: 0.3444 - lr: 1.2500e-05\n",
            "Epoch 19/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0869 - accuracy: 0.4778\n",
            "Epoch 19: val_accuracy did not improve from 0.37778\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0869 - accuracy: 0.4778 - val_loss: 1.1020 - val_accuracy: 0.3333 - lr: 1.2500e-05\n",
            "Epoch 20/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0862 - accuracy: 0.4583\n",
            "Epoch 20: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0862 - accuracy: 0.4583 - val_loss: 1.1016 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0882 - accuracy: 0.4417\n",
            "Epoch 21: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0882 - accuracy: 0.4417 - val_loss: 1.0978 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0860 - accuracy: 0.4472\n",
            "Epoch 22: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0860 - accuracy: 0.4472 - val_loss: 1.1081 - val_accuracy: 0.3111 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0874 - accuracy: 0.4444\n",
            "Epoch 23: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0874 - accuracy: 0.4444 - val_loss: 1.1059 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0875 - accuracy: 0.4639\n",
            "Epoch 24: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0875 - accuracy: 0.4639 - val_loss: 1.1086 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0856 - accuracy: 0.4333\n",
            "Epoch 25: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0856 - accuracy: 0.4333 - val_loss: 1.1005 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0875 - accuracy: 0.4417\n",
            "Epoch 26: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0875 - accuracy: 0.4417 - val_loss: 1.1067 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "Epoch 27/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0859 - accuracy: 0.4667\n",
            "Epoch 27: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 1.0859 - accuracy: 0.4667 - val_loss: 1.1000 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "Epoch 28/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0846 - accuracy: 0.4750\n",
            "Epoch 28: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0846 - accuracy: 0.4750 - val_loss: 1.1054 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.75      0.35      0.48        34\n",
            "      Normal       0.12      0.11      0.12        27\n",
            "Tuberculosis       0.32      0.55      0.41        29\n",
            "\n",
            "    accuracy                           0.34        90\n",
            "   macro avg       0.40      0.34      0.33        90\n",
            "weighted avg       0.42      0.34      0.35        90\n",
            "\n",
            "Fold #3\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0871 - accuracy: 0.4611\n",
            "Epoch 1: val_accuracy improved from -inf to 0.40000, saving model to  Kmodel1_soft_pre_cate_sgd3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_sgd3.h5 /assets\n",
            "360/360 [==============================] - 59s 164ms/step - loss: 1.0871 - accuracy: 0.4611 - val_loss: 1.1041 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0865 - accuracy: 0.4944\n",
            "Epoch 2: val_accuracy did not improve from 0.40000\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 1.0865 - accuracy: 0.4944 - val_loss: 1.0987 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0864 - accuracy: 0.5389\n",
            "Epoch 3: val_accuracy did not improve from 0.40000\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0864 - accuracy: 0.5389 - val_loss: 1.0954 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0867 - accuracy: 0.4750\n",
            "Epoch 4: val_accuracy improved from 0.40000 to 0.45556, saving model to  Kmodel1_soft_pre_cate_sgd3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_sgd3.h5 /assets\n",
            "360/360 [==============================] - 59s 165ms/step - loss: 1.0867 - accuracy: 0.4750 - val_loss: 1.0963 - val_accuracy: 0.4556 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0870 - accuracy: 0.4750\n",
            "Epoch 5: val_accuracy did not improve from 0.45556\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 1.0870 - accuracy: 0.4750 - val_loss: 1.1022 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0889 - accuracy: 0.4278\n",
            "Epoch 6: val_accuracy did not improve from 0.45556\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 1.0889 - accuracy: 0.4278 - val_loss: 1.1043 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0862 - accuracy: 0.4667\n",
            "Epoch 7: val_accuracy did not improve from 0.45556\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 1.0862 - accuracy: 0.4667 - val_loss: 1.1032 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0882 - accuracy: 0.4389\n",
            "Epoch 8: val_accuracy did not improve from 0.45556\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0882 - accuracy: 0.4389 - val_loss: 1.0993 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0871 - accuracy: 0.4500\n",
            "Epoch 9: val_accuracy did not improve from 0.45556\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0871 - accuracy: 0.4500 - val_loss: 1.0999 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0863 - accuracy: 0.4972\n",
            "Epoch 10: val_accuracy did not improve from 0.45556\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 1.0863 - accuracy: 0.4972 - val_loss: 1.1022 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0881 - accuracy: 0.4167\n",
            "Epoch 11: val_accuracy did not improve from 0.45556\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0881 - accuracy: 0.4167 - val_loss: 1.0986 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0874 - accuracy: 0.3972\n",
            "Epoch 12: val_accuracy did not improve from 0.45556\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0874 - accuracy: 0.3972 - val_loss: 1.0980 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0864 - accuracy: 0.4417\n",
            "Epoch 13: val_accuracy did not improve from 0.45556\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0864 - accuracy: 0.4417 - val_loss: 1.0948 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0880 - accuracy: 0.4472\n",
            "Epoch 14: val_accuracy did not improve from 0.45556\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0880 - accuracy: 0.4472 - val_loss: 1.0945 - val_accuracy: 0.4222 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0863 - accuracy: 0.4444\n",
            "Epoch 15: val_accuracy did not improve from 0.45556\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 1.0863 - accuracy: 0.4444 - val_loss: 1.1079 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0851 - accuracy: 0.4972\n",
            "Epoch 16: val_accuracy did not improve from 0.45556\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0851 - accuracy: 0.4972 - val_loss: 1.0971 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0873 - accuracy: 0.4333\n",
            "Epoch 17: val_accuracy did not improve from 0.45556\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0873 - accuracy: 0.4333 - val_loss: 1.0929 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0874 - accuracy: 0.4222\n",
            "Epoch 18: val_accuracy did not improve from 0.45556\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 1.0874 - accuracy: 0.4222 - val_loss: 1.0988 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0864 - accuracy: 0.4556\n",
            "Epoch 19: val_accuracy did not improve from 0.45556\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0864 - accuracy: 0.4556 - val_loss: 1.1046 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.38      0.22      0.28        27\n",
            "      Normal       0.31      0.27      0.29        33\n",
            "Tuberculosis       0.44      0.67      0.53        30\n",
            "\n",
            "    accuracy                           0.39        90\n",
            "   macro avg       0.38      0.39      0.37        90\n",
            "weighted avg       0.37      0.39      0.37        90\n",
            "\n",
            "Fold #4\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0859 - accuracy: 0.4750\n",
            "Epoch 1: val_accuracy improved from -inf to 0.34444, saving model to  Kmodel1_soft_pre_cate_sgd4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_sgd4.h5 /assets\n",
            "360/360 [==============================] - 59s 164ms/step - loss: 1.0859 - accuracy: 0.4750 - val_loss: 1.1023 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0848 - accuracy: 0.4861\n",
            "Epoch 2: val_accuracy did not improve from 0.34444\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0848 - accuracy: 0.4861 - val_loss: 1.1144 - val_accuracy: 0.3111 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0843 - accuracy: 0.4639\n",
            "Epoch 3: val_accuracy did not improve from 0.34444\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0843 - accuracy: 0.4639 - val_loss: 1.1101 - val_accuracy: 0.3222 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0866 - accuracy: 0.4556\n",
            "Epoch 4: val_accuracy did not improve from 0.34444\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0866 - accuracy: 0.4556 - val_loss: 1.1063 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0866 - accuracy: 0.5056\n",
            "Epoch 5: val_accuracy did not improve from 0.34444\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0866 - accuracy: 0.5056 - val_loss: 1.1167 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0844 - accuracy: 0.5222\n",
            "Epoch 6: val_accuracy did not improve from 0.34444\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0844 - accuracy: 0.5222 - val_loss: 1.1058 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0884 - accuracy: 0.4472\n",
            "Epoch 7: val_accuracy did not improve from 0.34444\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0884 - accuracy: 0.4472 - val_loss: 1.1077 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0858 - accuracy: 0.4778\n",
            "Epoch 8: val_accuracy did not improve from 0.34444\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0858 - accuracy: 0.4778 - val_loss: 1.1141 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0841 - accuracy: 0.5028\n",
            "Epoch 9: val_accuracy did not improve from 0.34444\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0841 - accuracy: 0.5028 - val_loss: 1.1114 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0849 - accuracy: 0.5278\n",
            "Epoch 10: val_accuracy improved from 0.34444 to 0.35556, saving model to  Kmodel1_soft_pre_cate_sgd4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_sgd4.h5 /assets\n",
            "360/360 [==============================] - 59s 163ms/step - loss: 1.0849 - accuracy: 0.5278 - val_loss: 1.1066 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0852 - accuracy: 0.4944\n",
            "Epoch 11: val_accuracy did not improve from 0.35556\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0852 - accuracy: 0.4944 - val_loss: 1.1083 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0848 - accuracy: 0.5278\n",
            "Epoch 12: val_accuracy did not improve from 0.35556\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0848 - accuracy: 0.5278 - val_loss: 1.1100 - val_accuracy: 0.3000 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0872 - accuracy: 0.4806\n",
            "Epoch 13: val_accuracy did not improve from 0.35556\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0872 - accuracy: 0.4806 - val_loss: 1.1080 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0826 - accuracy: 0.5028\n",
            "Epoch 14: val_accuracy improved from 0.35556 to 0.37778, saving model to  Kmodel1_soft_pre_cate_sgd4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_sgd4.h5 /assets\n",
            "360/360 [==============================] - 58s 162ms/step - loss: 1.0826 - accuracy: 0.5028 - val_loss: 1.1069 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0853 - accuracy: 0.4667\n",
            "Epoch 15: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0853 - accuracy: 0.4667 - val_loss: 1.1085 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0842 - accuracy: 0.4972\n",
            "Epoch 16: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0842 - accuracy: 0.4972 - val_loss: 1.1039 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0826 - accuracy: 0.5194\n",
            "Epoch 17: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0826 - accuracy: 0.5194 - val_loss: 1.1092 - val_accuracy: 0.3222 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0859 - accuracy: 0.4833\n",
            "Epoch 18: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0859 - accuracy: 0.4833 - val_loss: 1.1052 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0843 - accuracy: 0.4778\n",
            "Epoch 19: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0843 - accuracy: 0.4778 - val_loss: 1.1047 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0838 - accuracy: 0.5194\n",
            "Epoch 20: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0838 - accuracy: 0.5194 - val_loss: 1.1063 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0816 - accuracy: 0.5444\n",
            "Epoch 21: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0816 - accuracy: 0.5444 - val_loss: 1.1121 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0831 - accuracy: 0.5083\n",
            "Epoch 22: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0831 - accuracy: 0.5083 - val_loss: 1.1059 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0844 - accuracy: 0.5056\n",
            "Epoch 23: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 1.0844 - accuracy: 0.5056 - val_loss: 1.1061 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0830 - accuracy: 0.5194\n",
            "Epoch 24: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 1.0830 - accuracy: 0.5194 - val_loss: 1.0988 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0829 - accuracy: 0.5167\n",
            "Epoch 25: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0829 - accuracy: 0.5167 - val_loss: 1.1099 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0820 - accuracy: 0.5111\n",
            "Epoch 26: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 74ms/step - loss: 1.0820 - accuracy: 0.5111 - val_loss: 1.1047 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
            "Epoch 27/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0841 - accuracy: 0.5111\n",
            "Epoch 27: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 1.0841 - accuracy: 0.5111 - val_loss: 1.1054 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 28/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0823 - accuracy: 0.5167\n",
            "Epoch 28: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 1.0823 - accuracy: 0.5167 - val_loss: 1.1057 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
            "Epoch 29/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0848 - accuracy: 0.4833\n",
            "Epoch 29: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 1.0848 - accuracy: 0.4833 - val_loss: 1.1127 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.53      0.30      0.38        30\n",
            "      Normal       0.31      0.35      0.33        31\n",
            "Tuberculosis       0.29      0.38      0.33        29\n",
            "\n",
            "    accuracy                           0.34        90\n",
            "   macro avg       0.38      0.34      0.35        90\n",
            "weighted avg       0.38      0.34      0.35        90\n",
            "\n",
            "Fold #5\n",
            "Epoch 1/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0841 - accuracy: 0.4972\n",
            "Epoch 1: val_accuracy improved from -inf to 0.33333, saving model to  Kmodel1_soft_pre_cate_sgd5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_sgd5.h5 /assets\n",
            "360/360 [==============================] - 59s 164ms/step - loss: 1.0841 - accuracy: 0.4972 - val_loss: 1.1234 - val_accuracy: 0.3333 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0801 - accuracy: 0.5722\n",
            "Epoch 2: val_accuracy improved from 0.33333 to 0.34444, saving model to  Kmodel1_soft_pre_cate_sgd5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_sgd5.h5 /assets\n",
            "360/360 [==============================] - 59s 164ms/step - loss: 1.0801 - accuracy: 0.5722 - val_loss: 1.1186 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0839 - accuracy: 0.5139\n",
            "Epoch 3: val_accuracy improved from 0.34444 to 0.35556, saving model to  Kmodel1_soft_pre_cate_sgd5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_sgd5.h5 /assets\n",
            "360/360 [==============================] - 59s 163ms/step - loss: 1.0839 - accuracy: 0.5139 - val_loss: 1.1146 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0829 - accuracy: 0.5139\n",
            "Epoch 4: val_accuracy did not improve from 0.35556\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 1.0829 - accuracy: 0.5139 - val_loss: 1.1161 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0855 - accuracy: 0.4889\n",
            "Epoch 5: val_accuracy did not improve from 0.35556\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 1.0855 - accuracy: 0.4889 - val_loss: 1.1199 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0821 - accuracy: 0.4750\n",
            "Epoch 6: val_accuracy improved from 0.35556 to 0.36667, saving model to  Kmodel1_soft_pre_cate_sgd5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_sgd5.h5 /assets\n",
            "360/360 [==============================] - 59s 163ms/step - loss: 1.0821 - accuracy: 0.4750 - val_loss: 1.1122 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0833 - accuracy: 0.5056\n",
            "Epoch 7: val_accuracy did not improve from 0.36667\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 1.0833 - accuracy: 0.5056 - val_loss: 1.1151 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0826 - accuracy: 0.5194\n",
            "Epoch 8: val_accuracy did not improve from 0.36667\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 1.0826 - accuracy: 0.5194 - val_loss: 1.1139 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0811 - accuracy: 0.5278\n",
            "Epoch 9: val_accuracy did not improve from 0.36667\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 1.0811 - accuracy: 0.5278 - val_loss: 1.1192 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0849 - accuracy: 0.4917\n",
            "Epoch 10: val_accuracy did not improve from 0.36667\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 1.0849 - accuracy: 0.4917 - val_loss: 1.1185 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0829 - accuracy: 0.4778\n",
            "Epoch 11: val_accuracy did not improve from 0.36667\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 1.0829 - accuracy: 0.4778 - val_loss: 1.1123 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0827 - accuracy: 0.4806\n",
            "Epoch 12: val_accuracy did not improve from 0.36667\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 1.0827 - accuracy: 0.4806 - val_loss: 1.1148 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0820 - accuracy: 0.4861\n",
            "Epoch 13: val_accuracy did not improve from 0.36667\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 1.0820 - accuracy: 0.4861 - val_loss: 1.1163 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0830 - accuracy: 0.4861\n",
            "Epoch 14: val_accuracy did not improve from 0.36667\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 1.0830 - accuracy: 0.4861 - val_loss: 1.1069 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0805 - accuracy: 0.5417\n",
            "Epoch 15: val_accuracy did not improve from 0.36667\n",
            "360/360 [==============================] - 27s 75ms/step - loss: 1.0805 - accuracy: 0.5417 - val_loss: 1.1111 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0848 - accuracy: 0.4833\n",
            "Epoch 16: val_accuracy improved from 0.36667 to 0.37778, saving model to  Kmodel1_soft_pre_cate_sgd5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel1_soft_pre_cate_sgd5.h5 /assets\n",
            "360/360 [==============================] - 60s 167ms/step - loss: 1.0848 - accuracy: 0.4833 - val_loss: 1.1107 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0813 - accuracy: 0.5111\n",
            "Epoch 17: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 28s 77ms/step - loss: 1.0813 - accuracy: 0.5111 - val_loss: 1.1116 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0811 - accuracy: 0.5167\n",
            "Epoch 18: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 28s 77ms/step - loss: 1.0811 - accuracy: 0.5167 - val_loss: 1.1122 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0839 - accuracy: 0.4972\n",
            "Epoch 19: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 28s 77ms/step - loss: 1.0839 - accuracy: 0.4972 - val_loss: 1.1108 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0810 - accuracy: 0.4861\n",
            "Epoch 20: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 28s 77ms/step - loss: 1.0810 - accuracy: 0.4861 - val_loss: 1.1051 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0834 - accuracy: 0.4472\n",
            "Epoch 21: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 28s 77ms/step - loss: 1.0834 - accuracy: 0.4472 - val_loss: 1.1141 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0821 - accuracy: 0.5083\n",
            "Epoch 22: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 1.0821 - accuracy: 0.5083 - val_loss: 1.1140 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0798 - accuracy: 0.5278\n",
            "Epoch 23: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 1.0798 - accuracy: 0.5278 - val_loss: 1.1222 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0838 - accuracy: 0.4667\n",
            "Epoch 24: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 27s 76ms/step - loss: 1.0838 - accuracy: 0.4667 - val_loss: 1.1179 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0811 - accuracy: 0.5222\n",
            "Epoch 25: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 28s 78ms/step - loss: 1.0811 - accuracy: 0.5222 - val_loss: 1.1163 - val_accuracy: 0.3444 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0796 - accuracy: 0.5278\n",
            "Epoch 26: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 28s 78ms/step - loss: 1.0796 - accuracy: 0.5278 - val_loss: 1.1177 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 27/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0811 - accuracy: 0.5333\n",
            "Epoch 27: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 28s 78ms/step - loss: 1.0811 - accuracy: 0.5333 - val_loss: 1.1176 - val_accuracy: 0.3667 - lr: 1.0000e-05\n",
            "Epoch 28/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0822 - accuracy: 0.5111\n",
            "Epoch 28: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 28s 78ms/step - loss: 1.0822 - accuracy: 0.5111 - val_loss: 1.1078 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "Epoch 29/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0797 - accuracy: 0.5472\n",
            "Epoch 29: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 28s 78ms/step - loss: 1.0797 - accuracy: 0.5472 - val_loss: 1.1140 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 30/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0831 - accuracy: 0.4889\n",
            "Epoch 30: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 28s 79ms/step - loss: 1.0831 - accuracy: 0.4889 - val_loss: 1.1079 - val_accuracy: 0.3556 - lr: 1.0000e-05\n",
            "Epoch 31/100\n",
            "360/360 [==============================] - ETA: 0s - loss: 1.0806 - accuracy: 0.5306\n",
            "Epoch 31: val_accuracy did not improve from 0.37778\n",
            "360/360 [==============================] - 28s 78ms/step - loss: 1.0806 - accuracy: 0.5306 - val_loss: 1.1041 - val_accuracy: 0.3778 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.40      0.19      0.26        31\n",
            "      Normal       0.45      0.50      0.47        28\n",
            "Tuberculosis       0.32      0.45      0.37        31\n",
            "\n",
            "    accuracy                           0.38        90\n",
            "   macro avg       0.39      0.38      0.37        90\n",
            "weighted avg       0.39      0.38      0.37        90\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.48      0.26      0.34       150\n",
            "      Normal       0.31      0.29      0.30       150\n",
            "Tuberculosis       0.35      0.53      0.42       150\n",
            "\n",
            "    accuracy                           0.36       450\n",
            "   macro avg       0.38      0.36      0.35       450\n",
            "weighted avg       0.38      0.36      0.35       450\n",
            "\n"
          ]
        }
      ]
    }
  ]
}