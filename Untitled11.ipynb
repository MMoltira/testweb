{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO3Hku2ofJt4wbXXeOlXh9o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MMoltira/Chest-X-Ray-classification/blob/main/Untitled11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yd3FXdo0GGGo"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### import"
      ],
      "metadata": {
        "id": "Kpnf_sft9x4-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Psng6eJUdzUG"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torchsummary import summary\n",
        "from skimage.io import imread, imsave\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model\n",
        "from imutils import paths\n",
        "import argparse\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import metrics\n",
        "from scipy.stats import zscore\n",
        "\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import savefig\n",
        "\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels"
      ],
      "metadata": {
        "id": "6f-PDKiLl2iC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import joblib"
      ],
      "metadata": {
        "id": "KywT8U_h4Bmb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Load data // KKUmail"
      ],
      "metadata": {
        "id": "udl0zY8hAONG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d132a336-49cf-4f28-a45b-6879d3be0513",
        "id": "CZD0IvKyAONH"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTByVBBEAONI"
      },
      "source": [
        "data_dir = '/content/drive/My Drive/Senior Project/CXR Image3class/Image'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train 3 class"
      ],
      "metadata": {
        "id": "ySK4zn_OAONI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Normal151_dir = os.path.join(data_dir,'Normal151')\n",
        "TB150_dir = os.path.join(data_dir,'TB150')\n",
        "CA150_dir = os.path.join(data_dir,'CA150')\n",
        "\n",
        "All_3class_dir = os.path.join(data_dir,'All_3class')"
      ],
      "metadata": {
        "id": "yWVr9yKtAONI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Load data // Gmail"
      ],
      "metadata": {
        "id": "DVAihFMCTxcI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1c51f82-8e96-47b9-ed1d-8e3863b8faf4",
        "id": "y1ciXCtjTxcJ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q_4EnTuTxcM"
      },
      "source": [
        "data_dir = '/content/drive/My Drive/Senior Project/CXR Image3class/Image'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train 3 class"
      ],
      "metadata": {
        "id": "M0cxoTbeTxcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Normal151_dir = os.path.join(data_dir,'Normal151')\n",
        "TB150_dir = os.path.join(data_dir,'TB150')\n",
        "CA150_dir = os.path.join(data_dir,'CA150')\n",
        "\n",
        "All_3class_dir = os.path.join(data_dir,'All_3class')"
      ],
      "metadata": {
        "id": "xMhNdbHoTxcN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### train 3 class  \n",
        "ข้อมูลใน All_3class_dir รวมภาพทั้ง 3 คลาส รวม 450 ภาพ TB150, Normal151 (เอามาแค่150) และ CA150 (CA คือ lungcancer)"
      ],
      "metadata": {
        "id": "YFVxlpQZf5pU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Normal151_dir = os.path.join(data_dir,'Normal151')\n",
        "TB150_dir = os.path.join(data_dir,'TB150')\n",
        "CA150_dir = os.path.join(data_dir,'CA150')\n",
        "\n",
        "All_3class_dir = os.path.join(data_dir,'All_3class')"
      ],
      "metadata": {
        "id": "8BHyN8YKpwx9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal = []\n",
        "for i in range(len(os.listdir(Normal151_dir))):\n",
        "    img = os.listdir(Normal151_dir)[i]\n",
        "    normal.append(img)\n",
        "    \n",
        "tnormal = pd.DataFrame({'ImageName':[normal][0],\n",
        "                                       'NameType': \"Normal\" ,\n",
        "                                       'NumberType': 0                      })"
      ],
      "metadata": {
        "id": "mT0QF8IgrfVm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuberculosis = []\n",
        "for i in range(len(os.listdir(TB150_dir))):\n",
        "    img = os.listdir(TB150_dir)[i]\n",
        "    tuberculosis.append(img)\n",
        "\n",
        "ttuberculosis = pd.DataFrame({'ImageName':[tuberculosis][0],\n",
        "                                       'NameType': \"Tuberculosis\" ,\n",
        "                                       'NumberType': 1                        })"
      ],
      "metadata": {
        "id": "VtNPg0jwf5pW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lungcancer = []\n",
        "for i in range(len(os.listdir(CA150_dir))):\n",
        "    img = os.listdir(CA150_dir)[i]\n",
        "    lungcancer.append(img)\n",
        "\n",
        "tlungcancer = pd.DataFrame({'ImageName':[lungcancer][0],\n",
        "                                       'NameType': \"Lungcancer\" ,\n",
        "                                       'NumberType': 2                        })"
      ],
      "metadata": {
        "id": "X5pyCUl5mJGV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train3 = pd.concat([tnormal[:-1], ttuberculosis, tlungcancer])\n",
        "data_train3[-3:]"
      ],
      "metadata": {
        "id": "bgArCw5jnwg2",
        "outputId": "438d7df0-4425-47d5-f5b6-ddee303b9a2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     ImageName    NameType  NumberType\n",
              "147   ca96.jpg  Lungcancer           2\n",
              "148  ca108.jpg  Lungcancer           2\n",
              "149   ca74.jpg  Lungcancer           2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6b8088fa-3431-4498-b815-c2fca6fe700b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageName</th>\n",
              "      <th>NameType</th>\n",
              "      <th>NumberType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>ca96.jpg</td>\n",
              "      <td>Lungcancer</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>ca108.jpg</td>\n",
              "      <td>Lungcancer</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>ca74.jpg</td>\n",
              "      <td>Lungcancer</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b8088fa-3431-4498-b815-c2fca6fe700b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6b8088fa-3431-4498-b815-c2fca6fe700b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6b8088fa-3431-4498-b815-c2fca6fe700b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-fold 0-100\n",
        "แก้เป็น k-fold หมดแล้ว \n",
        "เหลือลองรันว่าจะเจ้งมั้ย\n",
        "- 311 layer\n",
        "-   filepath มี .h5 ทุกอัน"
      ],
      "metadata": {
        "id": "4qDyqEDCHxA0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8 \n"
      ],
      "metadata": {
        "id": "lT_PlZpRHxA0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8  soft pre bi\n"
      ],
      "metadata": {
        "id": "4tHlmnjHHxA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 8\n",
        "filepath = \"Kmodel8_soft_pre_bi.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "id": "EAgEARpiKDL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1afaa227-0f17-4a25-99af-04525d8cb0c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:09<00:00, 49.89it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel8_soft_pre_bi{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "S_Bu_V7SKDDf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30a9ecc4-5488-4250-ccd1-60118f83f13f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold #1\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.4859 - accuracy: 0.6361\n",
            "Epoch 1: val_accuracy improved from -inf to 0.55556, saving model to  Kmodel8_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi1.h5 /assets\n",
            "45/45 [==============================] - 99s 2s/step - loss: 0.4859 - accuracy: 0.6361 - val_loss: 0.5577 - val_accuracy: 0.5556 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.3325 - accuracy: 0.7972\n",
            "Epoch 2: val_accuracy did not improve from 0.55556\n",
            "45/45 [==============================] - 13s 284ms/step - loss: 0.3325 - accuracy: 0.7972 - val_loss: 0.6807 - val_accuracy: 0.5444 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2386 - accuracy: 0.8639\n",
            "Epoch 3: val_accuracy improved from 0.55556 to 0.63333, saving model to  Kmodel8_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi1.h5 /assets\n",
            "45/45 [==============================] - 49s 1s/step - loss: 0.2386 - accuracy: 0.8639 - val_loss: 0.8253 - val_accuracy: 0.6333 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2486 - accuracy: 0.8472\n",
            "Epoch 4: val_accuracy improved from 0.63333 to 0.67778, saving model to  Kmodel8_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi1.h5 /assets\n",
            "45/45 [==============================] - 50s 1s/step - loss: 0.2486 - accuracy: 0.8472 - val_loss: 0.7728 - val_accuracy: 0.6778 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1996 - accuracy: 0.8861\n",
            "Epoch 5: val_accuracy improved from 0.67778 to 0.74444, saving model to  Kmodel8_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi1.h5 /assets\n",
            "45/45 [==============================] - 49s 1s/step - loss: 0.1996 - accuracy: 0.8861 - val_loss: 0.7053 - val_accuracy: 0.7444 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1664 - accuracy: 0.9000\n",
            "Epoch 6: val_accuracy improved from 0.74444 to 0.76667, saving model to  Kmodel8_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi1.h5 /assets\n",
            "45/45 [==============================] - 49s 1s/step - loss: 0.1664 - accuracy: 0.9000 - val_loss: 0.7265 - val_accuracy: 0.7667 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1329 - accuracy: 0.9250\n",
            "Epoch 7: val_accuracy improved from 0.76667 to 0.83333, saving model to  Kmodel8_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi1.h5 /assets\n",
            "45/45 [==============================] - 49s 1s/step - loss: 0.1329 - accuracy: 0.9250 - val_loss: 0.5359 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 0.9583\n",
            "Epoch 8: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.1159 - accuracy: 0.9583 - val_loss: 0.6339 - val_accuracy: 0.7778 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9278\n",
            "Epoch 9: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.1303 - accuracy: 0.9278 - val_loss: 0.9281 - val_accuracy: 0.7889 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1256 - accuracy: 0.9361\n",
            "Epoch 10: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 13s 279ms/step - loss: 0.1256 - accuracy: 0.9361 - val_loss: 0.8530 - val_accuracy: 0.7444 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1014 - accuracy: 0.9500\n",
            "Epoch 11: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 13s 280ms/step - loss: 0.1014 - accuracy: 0.9500 - val_loss: 1.9834 - val_accuracy: 0.4667 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.9556\n",
            "Epoch 12: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 12s 273ms/step - loss: 0.1097 - accuracy: 0.9556 - val_loss: 0.7823 - val_accuracy: 0.8111 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9583\n",
            "Epoch 13: val_accuracy did not improve from 0.83333\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "45/45 [==============================] - 13s 288ms/step - loss: 0.0860 - accuracy: 0.9583 - val_loss: 1.7207 - val_accuracy: 0.6889 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0734 - accuracy: 0.9722\n",
            "Epoch 14: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 13s 289ms/step - loss: 0.0734 - accuracy: 0.9722 - val_loss: 1.4784 - val_accuracy: 0.7000 - lr: 5.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.9500\n",
            "Epoch 15: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 13s 280ms/step - loss: 0.0796 - accuracy: 0.9500 - val_loss: 1.2922 - val_accuracy: 0.6667 - lr: 5.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9833\n",
            "Epoch 16: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 13s 278ms/step - loss: 0.0540 - accuracy: 0.9833 - val_loss: 0.9621 - val_accuracy: 0.6889 - lr: 5.0000e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9833\n",
            "Epoch 17: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 12s 274ms/step - loss: 0.0346 - accuracy: 0.9833 - val_loss: 1.2088 - val_accuracy: 0.6111 - lr: 5.0000e-05\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.9694\n",
            "Epoch 18: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 12s 272ms/step - loss: 0.0808 - accuracy: 0.9694 - val_loss: 1.0151 - val_accuracy: 0.6556 - lr: 5.0000e-05\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9861\n",
            "Epoch 19: val_accuracy did not improve from 0.83333\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "45/45 [==============================] - 13s 276ms/step - loss: 0.0359 - accuracy: 0.9861 - val_loss: 0.8619 - val_accuracy: 0.7333 - lr: 5.0000e-05\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.9861\n",
            "Epoch 20: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 13s 278ms/step - loss: 0.0354 - accuracy: 0.9861 - val_loss: 0.8847 - val_accuracy: 0.7000 - lr: 2.5000e-05\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.9778\n",
            "Epoch 21: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 13s 277ms/step - loss: 0.0785 - accuracy: 0.9778 - val_loss: 0.8072 - val_accuracy: 0.7111 - lr: 2.5000e-05\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 0.9861\n",
            "Epoch 22: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 13s 286ms/step - loss: 0.0299 - accuracy: 0.9861 - val_loss: 0.5885 - val_accuracy: 0.7556 - lr: 2.5000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.83      0.68      0.75        28\n",
            "      Normal       0.95      0.68      0.79        31\n",
            "Tuberculosis       0.62      0.90      0.74        31\n",
            "\n",
            "    accuracy                           0.76        90\n",
            "   macro avg       0.80      0.75      0.76        90\n",
            "weighted avg       0.80      0.76      0.76        90\n",
            "\n",
            "Fold #2\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1452 - accuracy: 0.9361\n",
            "Epoch 1: val_accuracy improved from -inf to 1.00000, saving model to  Kmodel8_soft_pre_bi2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi2.h5 /assets\n",
            "45/45 [==============================] - 49s 1s/step - loss: 0.1452 - accuracy: 0.9361 - val_loss: 0.0220 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 0.9500\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 13s 282ms/step - loss: 0.1095 - accuracy: 0.9500 - val_loss: 0.0257 - val_accuracy: 0.9889 - lr: 2.5000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0522 - accuracy: 0.9722\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 13s 281ms/step - loss: 0.0522 - accuracy: 0.9722 - val_loss: 0.0664 - val_accuracy: 0.9778 - lr: 2.5000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9722\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 13s 281ms/step - loss: 0.0577 - accuracy: 0.9722 - val_loss: 0.1403 - val_accuracy: 0.9111 - lr: 2.5000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0717 - accuracy: 0.9694\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0717 - accuracy: 0.9694 - val_loss: 0.0496 - val_accuracy: 0.9778 - lr: 2.5000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9750\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0674 - accuracy: 0.9750 - val_loss: 0.0713 - val_accuracy: 0.9556 - lr: 2.5000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0490 - accuracy: 0.9750\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0490 - accuracy: 0.9750 - val_loss: 0.1024 - val_accuracy: 0.9222 - lr: 2.5000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.9778\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0446 - accuracy: 0.9778 - val_loss: 0.0879 - val_accuracy: 0.9333 - lr: 1.2500e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0562 - accuracy: 0.9694\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 13s 276ms/step - loss: 0.0562 - accuracy: 0.9694 - val_loss: 0.0671 - val_accuracy: 0.9556 - lr: 1.2500e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.9833\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 13s 275ms/step - loss: 0.0473 - accuracy: 0.9833 - val_loss: 0.0821 - val_accuracy: 0.9333 - lr: 1.2500e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9722\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.0487 - accuracy: 0.9722 - val_loss: 0.1469 - val_accuracy: 0.8778 - lr: 1.2500e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 0.9833\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0410 - accuracy: 0.9833 - val_loss: 0.1154 - val_accuracy: 0.9000 - lr: 1.2500e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9861\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "45/45 [==============================] - 13s 276ms/step - loss: 0.0269 - accuracy: 0.9861 - val_loss: 0.1358 - val_accuracy: 0.9000 - lr: 1.2500e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9833\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0334 - accuracy: 0.9833 - val_loss: 0.1713 - val_accuracy: 0.8778 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9806\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 13s 276ms/step - loss: 0.0397 - accuracy: 0.9806 - val_loss: 0.1972 - val_accuracy: 0.8667 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 0.9778\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 13s 276ms/step - loss: 0.0435 - accuracy: 0.9778 - val_loss: 0.1256 - val_accuracy: 0.8889 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.74      0.85        34\n",
            "      Normal       1.00      0.96      0.98        27\n",
            "Tuberculosis       0.74      1.00      0.85        29\n",
            "\n",
            "    accuracy                           0.89        90\n",
            "   macro avg       0.91      0.90      0.89        90\n",
            "weighted avg       0.92      0.89      0.89        90\n",
            "\n",
            "Fold #3\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.9944\n",
            "Epoch 1: val_accuracy improved from -inf to 0.96667, saving model to  Kmodel8_soft_pre_bi3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi3.h5 /assets\n",
            "45/45 [==============================] - 49s 1s/step - loss: 0.0265 - accuracy: 0.9944 - val_loss: 0.0778 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9889\n",
            "Epoch 2: val_accuracy did not improve from 0.96667\n",
            "45/45 [==============================] - 13s 277ms/step - loss: 0.0262 - accuracy: 0.9889 - val_loss: 0.1421 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9944\n",
            "Epoch 3: val_accuracy did not improve from 0.96667\n",
            "45/45 [==============================] - 13s 279ms/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 0.1183 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9833\n",
            "Epoch 4: val_accuracy improved from 0.96667 to 0.97778, saving model to  Kmodel8_soft_pre_bi3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi3.h5 /assets\n",
            "45/45 [==============================] - 49s 1s/step - loss: 0.0404 - accuracy: 0.9833 - val_loss: 0.0682 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9917\n",
            "Epoch 5: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0311 - accuracy: 0.9917 - val_loss: 0.1142 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 0.9917\n",
            "Epoch 6: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0282 - accuracy: 0.9917 - val_loss: 0.0489 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.9722\n",
            "Epoch 7: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 13s 278ms/step - loss: 0.0531 - accuracy: 0.9722 - val_loss: 0.0636 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9833\n",
            "Epoch 8: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 13s 286ms/step - loss: 0.0256 - accuracy: 0.9833 - val_loss: 0.0723 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 0.9944\n",
            "Epoch 9: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 13s 289ms/step - loss: 0.0205 - accuracy: 0.9944 - val_loss: 0.1298 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9972\n",
            "Epoch 10: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 12s 273ms/step - loss: 0.0144 - accuracy: 0.9972 - val_loss: 0.0694 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9889\n",
            "Epoch 11: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 13s 281ms/step - loss: 0.0294 - accuracy: 0.9889 - val_loss: 0.1260 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9972\n",
            "Epoch 12: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 13s 279ms/step - loss: 0.0148 - accuracy: 0.9972 - val_loss: 0.1116 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9861\n",
            "Epoch 13: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 13s 287ms/step - loss: 0.0248 - accuracy: 0.9861 - val_loss: 0.0756 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9944\n",
            "Epoch 14: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 13s 276ms/step - loss: 0.0157 - accuracy: 0.9944 - val_loss: 0.0697 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9944\n",
            "Epoch 15: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 13s 283ms/step - loss: 0.0157 - accuracy: 0.9944 - val_loss: 0.0592 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9944\n",
            "Epoch 16: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 13s 277ms/step - loss: 0.0147 - accuracy: 0.9944 - val_loss: 0.0652 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 13s 281ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9889\n",
            "Epoch 18: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 13s 279ms/step - loss: 0.0289 - accuracy: 0.9889 - val_loss: 0.0989 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9833\n",
            "Epoch 19: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 13s 285ms/step - loss: 0.0235 - accuracy: 0.9833 - val_loss: 0.1341 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.89      0.94        27\n",
            "      Normal       1.00      0.97      0.98        33\n",
            "Tuberculosis       0.88      1.00      0.94        30\n",
            "\n",
            "    accuracy                           0.96        90\n",
            "   macro avg       0.96      0.95      0.95        90\n",
            "weighted avg       0.96      0.96      0.96        90\n",
            "\n",
            "Fold #4\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9972\n",
            "Epoch 1: val_accuracy improved from -inf to 0.96667, saving model to  Kmodel8_soft_pre_bi4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi4.h5 /assets\n",
            "45/45 [==============================] - 50s 1s/step - loss: 0.0166 - accuracy: 0.9972 - val_loss: 0.1123 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9972\n",
            "Epoch 2: val_accuracy did not improve from 0.96667\n",
            "45/45 [==============================] - 13s 285ms/step - loss: 0.0110 - accuracy: 0.9972 - val_loss: 0.1409 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9889\n",
            "Epoch 3: val_accuracy did not improve from 0.96667\n",
            "45/45 [==============================] - 13s 284ms/step - loss: 0.0180 - accuracy: 0.9889 - val_loss: 0.0754 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9861\n",
            "Epoch 4: val_accuracy did not improve from 0.96667\n",
            "45/45 [==============================] - 13s 281ms/step - loss: 0.0240 - accuracy: 0.9861 - val_loss: 0.0837 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.9972\n",
            "Epoch 5: val_accuracy improved from 0.96667 to 0.97778, saving model to  Kmodel8_soft_pre_bi4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi4.h5 /assets\n",
            "45/45 [==============================] - 48s 1s/step - loss: 0.0130 - accuracy: 0.9972 - val_loss: 0.0779 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy improved from 0.97778 to 0.98889, saving model to  Kmodel8_soft_pre_bi4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi4.h5 /assets\n",
            "45/45 [==============================] - 48s 1s/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.9944\n",
            "Epoch 8: val_accuracy improved from 0.98889 to 1.00000, saving model to  Kmodel8_soft_pre_bi4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi4.h5 /assets\n",
            "45/45 [==============================] - 47s 1s/step - loss: 0.0215 - accuracy: 0.9944 - val_loss: 0.0303 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 0.9806\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0360 - accuracy: 0.9806 - val_loss: 0.0309 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9972\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0133 - accuracy: 0.9972 - val_loss: 0.0362 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9917\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.0153 - accuracy: 0.9917 - val_loss: 0.0853 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9944\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0108 - accuracy: 0.9944 - val_loss: 0.0778 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9917\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.0204 - accuracy: 0.9917 - val_loss: 0.0501 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 272ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9972\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.0076 - accuracy: 0.9972 - val_loss: 0.0451 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0573 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9944\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0209 - accuracy: 0.9944 - val_loss: 0.0898 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9889\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0230 - accuracy: 0.9889 - val_loss: 0.0858 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9972\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.0946 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0831 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.9944\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0128 - accuracy: 0.9944 - val_loss: 0.1053 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.83      0.91        30\n",
            "      Normal       1.00      0.97      0.98        31\n",
            "Tuberculosis       0.83      1.00      0.91        29\n",
            "\n",
            "    accuracy                           0.93        90\n",
            "   macro avg       0.94      0.93      0.93        90\n",
            "weighted avg       0.94      0.93      0.93        90\n",
            "\n",
            "Fold #5\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 1: val_accuracy improved from -inf to 0.98889, saving model to  Kmodel8_soft_pre_bi5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi5.h5 /assets\n",
            "45/45 [==============================] - 48s 1s/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 2: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 3: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 270ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9944\n",
            "Epoch 4: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 271ms/step - loss: 0.0106 - accuracy: 0.9944 - val_loss: 0.0174 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 5: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9972\n",
            "Epoch 6: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.0098 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9944\n",
            "Epoch 7: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0123 - accuracy: 0.9944 - val_loss: 0.0144 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9944\n",
            "Epoch 8: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0154 - accuracy: 0.9944 - val_loss: 0.0278 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9972\n",
            "Epoch 10: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 270ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.0314 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9972\n",
            "Epoch 11: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 270ms/step - loss: 0.0056 - accuracy: 0.9972 - val_loss: 0.0376 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9917\n",
            "Epoch 12: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 272ms/step - loss: 0.0161 - accuracy: 0.9917 - val_loss: 0.0516 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 273ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0563 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9972\n",
            "Epoch 14: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.0554 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9972\n",
            "Epoch 16: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0237 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.97      0.98        31\n",
            "      Normal       1.00      1.00      1.00        28\n",
            "Tuberculosis       0.97      1.00      0.98        31\n",
            "\n",
            "    accuracy                           0.99        90\n",
            "   macro avg       0.99      0.99      0.99        90\n",
            "weighted avg       0.99      0.99      0.99        90\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.97      0.82      0.89       150\n",
            "      Normal       0.99      0.91      0.95       150\n",
            "Tuberculosis       0.79      0.98      0.88       150\n",
            "\n",
            "    accuracy                           0.90       450\n",
            "   macro avg       0.92      0.90      0.91       450\n",
            "weighted avg       0.92      0.90      0.91       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "H_Incep.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7gTdnI-0VqX",
        "outputId": "a7099b4a-6b54-4e85-b962-042098cedca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy', 'lr'])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = H_Incep.history['lr']\n",
        "\n",
        "plt.figure(figsize=(20,15))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(lr, label = \" Learning rate\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZdFZUZc0dEI",
        "outputId": "562df815-f22f-4aab-af1a-d13480c460b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7efd69e456d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8 soft pre bi adam  \n"
      ],
      "metadata": {
        "id": "XhGoWt8CHxA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 8\n",
        "filepath = \"Kmodel8_soft_pre_bi_adam.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k5-3GpI6epe",
        "outputId": "23c8e8f4-35fe-499d-d7db-428e9f957220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:05<00:00, 87.26it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel8_soft_pre_bi_adam{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "qTbqFtDF6cwy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "593ca483-aa81-4019-dfd7-bf0fc35aec9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold #1\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.5132 - accuracy: 0.5972\n",
            "Epoch 1: val_accuracy improved from -inf to 0.52222, saving model to  Kmodel8_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_adam1.h5 /assets\n",
            "45/45 [==============================] - 78s 2s/step - loss: 0.5132 - accuracy: 0.5972 - val_loss: 0.6663 - val_accuracy: 0.5222 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.3175 - accuracy: 0.8083\n",
            "Epoch 2: val_accuracy improved from 0.52222 to 0.72222, saving model to  Kmodel8_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_adam1.h5 /assets\n",
            "45/45 [==============================] - 49s 1s/step - loss: 0.3175 - accuracy: 0.8083 - val_loss: 0.3642 - val_accuracy: 0.7222 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2747 - accuracy: 0.8417\n",
            "Epoch 3: val_accuracy improved from 0.72222 to 0.74444, saving model to  Kmodel8_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_adam1.h5 /assets\n",
            "45/45 [==============================] - 49s 1s/step - loss: 0.2747 - accuracy: 0.8417 - val_loss: 0.3847 - val_accuracy: 0.7444 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2252 - accuracy: 0.8611\n",
            "Epoch 4: val_accuracy improved from 0.74444 to 0.76667, saving model to  Kmodel8_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_adam1.h5 /assets\n",
            "45/45 [==============================] - 49s 1s/step - loss: 0.2252 - accuracy: 0.8611 - val_loss: 0.4821 - val_accuracy: 0.7667 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2298 - accuracy: 0.8611\n",
            "Epoch 5: val_accuracy did not improve from 0.76667\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.2298 - accuracy: 0.8611 - val_loss: 0.4175 - val_accuracy: 0.7667 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1609 - accuracy: 0.9167\n",
            "Epoch 6: val_accuracy did not improve from 0.76667\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.1609 - accuracy: 0.9167 - val_loss: 0.6214 - val_accuracy: 0.7444 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1184 - accuracy: 0.9444\n",
            "Epoch 7: val_accuracy did not improve from 0.76667\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.1184 - accuracy: 0.9444 - val_loss: 0.5268 - val_accuracy: 0.7556 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1325 - accuracy: 0.9333\n",
            "Epoch 8: val_accuracy did not improve from 0.76667\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.1325 - accuracy: 0.9333 - val_loss: 0.9235 - val_accuracy: 0.6778 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1442 - accuracy: 0.9333\n",
            "Epoch 9: val_accuracy improved from 0.76667 to 0.82222, saving model to  Kmodel8_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_adam1.h5 /assets\n",
            "45/45 [==============================] - 48s 1s/step - loss: 0.1442 - accuracy: 0.9333 - val_loss: 0.3693 - val_accuracy: 0.8222 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1026 - accuracy: 0.9472\n",
            "Epoch 10: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.1026 - accuracy: 0.9472 - val_loss: 0.9582 - val_accuracy: 0.5889 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1202 - accuracy: 0.9333\n",
            "Epoch 11: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.1202 - accuracy: 0.9333 - val_loss: 0.4999 - val_accuracy: 0.7556 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9694\n",
            "Epoch 12: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.0836 - accuracy: 0.9694 - val_loss: 0.4232 - val_accuracy: 0.8222 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9694\n",
            "Epoch 13: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.0525 - accuracy: 0.9694 - val_loss: 0.4989 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 0.9472\n",
            "Epoch 14: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.1018 - accuracy: 0.9472 - val_loss: 1.4822 - val_accuracy: 0.6333 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9472\n",
            "Epoch 15: val_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.1060 - accuracy: 0.9472 - val_loss: 0.5934 - val_accuracy: 0.7778 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0720 - accuracy: 0.9778\n",
            "Epoch 16: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.0720 - accuracy: 0.9778 - val_loss: 0.5113 - val_accuracy: 0.7889 - lr: 5.0000e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9972\n",
            "Epoch 17: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.0246 - accuracy: 0.9972 - val_loss: 0.7061 - val_accuracy: 0.7556 - lr: 5.0000e-05\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0463 - accuracy: 0.9806\n",
            "Epoch 18: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.0463 - accuracy: 0.9806 - val_loss: 0.6795 - val_accuracy: 0.7667 - lr: 5.0000e-05\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.9778\n",
            "Epoch 19: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.0399 - accuracy: 0.9778 - val_loss: 0.6775 - val_accuracy: 0.7778 - lr: 5.0000e-05\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.9861\n",
            "Epoch 20: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0433 - accuracy: 0.9861 - val_loss: 0.4554 - val_accuracy: 0.8222 - lr: 5.0000e-05\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0490 - accuracy: 0.9694\n",
            "Epoch 21: val_accuracy did not improve from 0.82222\n",
            "\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.0490 - accuracy: 0.9694 - val_loss: 0.6164 - val_accuracy: 0.7333 - lr: 5.0000e-05\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9917\n",
            "Epoch 22: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0331 - accuracy: 0.9917 - val_loss: 0.5481 - val_accuracy: 0.7889 - lr: 2.5000e-05\n",
            "Epoch 23/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9917\n",
            "Epoch 23: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0338 - accuracy: 0.9917 - val_loss: 0.4764 - val_accuracy: 0.8000 - lr: 2.5000e-05\n",
            "Epoch 24/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 0.9861\n",
            "Epoch 24: val_accuracy did not improve from 0.82222\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0402 - accuracy: 0.9861 - val_loss: 0.7190 - val_accuracy: 0.7556 - lr: 2.5000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.93      0.50      0.65        28\n",
            "      Normal       0.93      0.81      0.86        31\n",
            "Tuberculosis       0.60      0.94      0.73        31\n",
            "\n",
            "    accuracy                           0.76        90\n",
            "   macro avg       0.82      0.75      0.75        90\n",
            "weighted avg       0.82      0.76      0.75        90\n",
            "\n",
            "Fold #2\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1414 - accuracy: 0.9472\n",
            "Epoch 1: val_accuracy improved from -inf to 0.98889, saving model to  Kmodel8_soft_pre_bi_adam2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_adam2.h5 /assets\n",
            "45/45 [==============================] - 50s 1s/step - loss: 0.1414 - accuracy: 0.9472 - val_loss: 0.0297 - val_accuracy: 0.9889 - lr: 2.5000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9667\n",
            "Epoch 2: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.0680 - accuracy: 0.9667 - val_loss: 0.0686 - val_accuracy: 0.9667 - lr: 2.5000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.9667\n",
            "Epoch 3: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0698 - accuracy: 0.9667 - val_loss: 0.1303 - val_accuracy: 0.9222 - lr: 2.5000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9722\n",
            "Epoch 4: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.0581 - accuracy: 0.9722 - val_loss: 0.1006 - val_accuracy: 0.9333 - lr: 2.5000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0484 - accuracy: 0.9806\n",
            "Epoch 5: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0484 - accuracy: 0.9806 - val_loss: 0.1063 - val_accuracy: 0.9333 - lr: 2.5000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 0.9889\n",
            "Epoch 6: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0357 - accuracy: 0.9889 - val_loss: 0.1682 - val_accuracy: 0.9111 - lr: 2.5000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.9750\n",
            "Epoch 7: val_accuracy did not improve from 0.98889\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0505 - accuracy: 0.9750 - val_loss: 0.2024 - val_accuracy: 0.8778 - lr: 2.5000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9778\n",
            "Epoch 8: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0481 - accuracy: 0.9778 - val_loss: 0.1038 - val_accuracy: 0.9444 - lr: 1.2500e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 0.9778\n",
            "Epoch 9: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0499 - accuracy: 0.9778 - val_loss: 0.0962 - val_accuracy: 0.9444 - lr: 1.2500e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9917\n",
            "Epoch 10: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.0260 - accuracy: 0.9917 - val_loss: 0.1499 - val_accuracy: 0.9111 - lr: 1.2500e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9861\n",
            "Epoch 11: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0474 - accuracy: 0.9861 - val_loss: 0.1716 - val_accuracy: 0.9111 - lr: 1.2500e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9917\n",
            "Epoch 12: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0268 - accuracy: 0.9917 - val_loss: 0.1825 - val_accuracy: 0.8889 - lr: 1.2500e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9917\n",
            "Epoch 13: val_accuracy did not improve from 0.98889\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0322 - accuracy: 0.9917 - val_loss: 0.1715 - val_accuracy: 0.8889 - lr: 1.2500e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9889\n",
            "Epoch 14: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.0220 - accuracy: 0.9889 - val_loss: 0.1496 - val_accuracy: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9861\n",
            "Epoch 15: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0311 - accuracy: 0.9861 - val_loss: 0.1543 - val_accuracy: 0.8889 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9889\n",
            "Epoch 16: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0365 - accuracy: 0.9889 - val_loss: 0.1368 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.79      0.89        34\n",
            "      Normal       1.00      1.00      1.00        27\n",
            "Tuberculosis       0.81      1.00      0.89        29\n",
            "\n",
            "    accuracy                           0.92        90\n",
            "   macro avg       0.94      0.93      0.93        90\n",
            "weighted avg       0.94      0.92      0.92        90\n",
            "\n",
            "Fold #3\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9917\n",
            "Epoch 1: val_accuracy improved from -inf to 0.98889, saving model to  Kmodel8_soft_pre_bi_adam3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_adam3.h5 /assets\n",
            "45/45 [==============================] - 50s 1s/step - loss: 0.0274 - accuracy: 0.9917 - val_loss: 0.0542 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9917\n",
            "Epoch 2: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.0327 - accuracy: 0.9917 - val_loss: 0.0366 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9889\n",
            "Epoch 3: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.0234 - accuracy: 0.9889 - val_loss: 0.0295 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9944\n",
            "Epoch 4: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0222 - accuracy: 0.9944 - val_loss: 0.0335 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9861\n",
            "Epoch 5: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0211 - accuracy: 0.9861 - val_loss: 0.0485 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9917\n",
            "Epoch 6: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0290 - accuracy: 0.9917 - val_loss: 0.0321 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 0.9917\n",
            "Epoch 7: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0192 - accuracy: 0.9917 - val_loss: 0.0273 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.9889\n",
            "Epoch 9: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0285 - accuracy: 0.9889 - val_loss: 0.0624 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9972\n",
            "Epoch 10: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0219 - accuracy: 0.9972 - val_loss: 0.0611 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9917\n",
            "Epoch 11: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0238 - accuracy: 0.9917 - val_loss: 0.0500 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0229 - accuracy: 0.9944\n",
            "Epoch 12: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0229 - accuracy: 0.9944 - val_loss: 0.0700 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9972\n",
            "Epoch 13: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 13s 276ms/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.0421 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9944\n",
            "Epoch 14: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0160 - accuracy: 0.9944 - val_loss: 0.0395 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9944\n",
            "Epoch 15: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.0186 - accuracy: 0.9944 - val_loss: 0.0431 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0312 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.96      0.98        27\n",
            "      Normal       1.00      1.00      1.00        33\n",
            "Tuberculosis       0.97      1.00      0.98        30\n",
            "\n",
            "    accuracy                           0.99        90\n",
            "   macro avg       0.99      0.99      0.99        90\n",
            "weighted avg       0.99      0.99      0.99        90\n",
            "\n",
            "Fold #4\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9972\n",
            "Epoch 1: val_accuracy improved from -inf to 1.00000, saving model to  Kmodel8_soft_pre_bi_adam4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_adam4.h5 /assets\n",
            "45/45 [==============================] - 50s 1s/step - loss: 0.0131 - accuracy: 0.9972 - val_loss: 0.0233 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9889\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0257 - accuracy: 0.9889 - val_loss: 0.0510 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9917\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.0188 - accuracy: 0.9917 - val_loss: 0.0439 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9944\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.0134 - accuracy: 0.9944 - val_loss: 0.0413 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9889\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0383 - accuracy: 0.9889 - val_loss: 0.0398 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9972\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0150 - accuracy: 0.9972 - val_loss: 0.0351 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.0302 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9972\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0176 - accuracy: 0.9972 - val_loss: 0.0323 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9806\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0401 - accuracy: 0.9806 - val_loss: 0.0278 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9917\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0211 - accuracy: 0.9917 - val_loss: 0.0458 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9972\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0153 - accuracy: 0.9972 - val_loss: 0.0453 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9917\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.0172 - accuracy: 0.9917 - val_loss: 0.0626 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0575 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.97      0.98        30\n",
            "      Normal       1.00      0.94      0.97        31\n",
            "Tuberculosis       0.91      1.00      0.95        29\n",
            "\n",
            "    accuracy                           0.97        90\n",
            "   macro avg       0.97      0.97      0.97        90\n",
            "weighted avg       0.97      0.97      0.97        90\n",
            "\n",
            "Fold #5\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9972\n",
            "Epoch 1: val_accuracy improved from -inf to 0.98889, saving model to  Kmodel8_soft_pre_bi_adam5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_adam5.h5 /assets\n",
            "45/45 [==============================] - 49s 1s/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.0263 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9972\n",
            "Epoch 2: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.0125 - accuracy: 0.9972 - val_loss: 0.0361 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 1.0000\n",
            "Epoch 3: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 0.9917\n",
            "Epoch 4: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.0282 - accuracy: 0.9917 - val_loss: 0.0272 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 1.0000\n",
            "Epoch 5: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9972\n",
            "Epoch 6: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.0118 - accuracy: 0.9972 - val_loss: 0.0276 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9944\n",
            "Epoch 8: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0165 - accuracy: 0.9944 - val_loss: 0.0167 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9972\n",
            "Epoch 9: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0237 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9972\n",
            "Epoch 10: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0172 - accuracy: 0.9972 - val_loss: 0.0234 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.9944\n",
            "Epoch 11: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0132 - accuracy: 0.9944 - val_loss: 0.0319 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9889\n",
            "Epoch 12: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0235 - accuracy: 0.9889 - val_loss: 0.0358 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9972\n",
            "Epoch 13: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0113 - accuracy: 0.9972 - val_loss: 0.0455 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9944\n",
            "Epoch 14: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0139 - accuracy: 0.9944 - val_loss: 0.0365 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9917\n",
            "Epoch 15: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0133 - accuracy: 0.9917 - val_loss: 0.0447 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.97      0.98        31\n",
            "      Normal       1.00      1.00      1.00        28\n",
            "Tuberculosis       0.97      1.00      0.98        31\n",
            "\n",
            "    accuracy                           0.99        90\n",
            "   macro avg       0.99      0.99      0.99        90\n",
            "weighted avg       0.99      0.99      0.99        90\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.99      0.84      0.91       150\n",
            "      Normal       0.99      0.95      0.97       150\n",
            "Tuberculosis       0.83      0.99      0.90       150\n",
            "\n",
            "    accuracy                           0.92       450\n",
            "   macro avg       0.94      0.92      0.93       450\n",
            "weighted avg       0.94      0.92      0.93       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8 soft pre bi sgd  \n"
      ],
      "metadata": {
        "id": "4CfquesGP-rZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 8\n",
        "filepath = \"Kmodel8_soft_pre_bi_sgd.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee99b589-85fb-439e-fff3-1e46200ff5e8",
        "id": "gdxYY4UjP-ra"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:05<00:00, 86.61it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel8_soft_pre_bi_sgd{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "uqOS1R8QP-ra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eda714ad-df3c-4c06-9181-6d0652aeb5c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold #1\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7086 - accuracy: 0.3083\n",
            "Epoch 1: val_accuracy improved from -inf to 0.34444, saving model to  Kmodel8_soft_pre_bi_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd1.h5 /assets\n",
            "45/45 [==============================] - 93s 1s/step - loss: 0.7086 - accuracy: 0.3083 - val_loss: 0.7040 - val_accuracy: 0.3444 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6998 - accuracy: 0.3500\n",
            "Epoch 2: val_accuracy did not improve from 0.34444\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.6998 - accuracy: 0.3500 - val_loss: 0.7079 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6975 - accuracy: 0.2889\n",
            "Epoch 3: val_accuracy improved from 0.34444 to 0.37778, saving model to  Kmodel8_soft_pre_bi_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd1.h5 /assets\n",
            "45/45 [==============================] - 47s 1s/step - loss: 0.6975 - accuracy: 0.2889 - val_loss: 0.7001 - val_accuracy: 0.3778 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6811 - accuracy: 0.3556\n",
            "Epoch 4: val_accuracy improved from 0.37778 to 0.41111, saving model to  Kmodel8_soft_pre_bi_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd1.h5 /assets\n",
            "45/45 [==============================] - 47s 1s/step - loss: 0.6811 - accuracy: 0.3556 - val_loss: 0.6875 - val_accuracy: 0.4111 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6799 - accuracy: 0.3389\n",
            "Epoch 5: val_accuracy improved from 0.41111 to 0.43333, saving model to  Kmodel8_soft_pre_bi_sgd1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd1.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.6799 - accuracy: 0.3389 - val_loss: 0.6771 - val_accuracy: 0.4333 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6726 - accuracy: 0.3306\n",
            "Epoch 6: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.6726 - accuracy: 0.3306 - val_loss: 0.6706 - val_accuracy: 0.4222 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6683 - accuracy: 0.3611\n",
            "Epoch 7: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.6683 - accuracy: 0.3611 - val_loss: 0.6659 - val_accuracy: 0.4000 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6610 - accuracy: 0.3667\n",
            "Epoch 8: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.6610 - accuracy: 0.3667 - val_loss: 0.6613 - val_accuracy: 0.3778 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6614 - accuracy: 0.3417\n",
            "Epoch 9: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.6614 - accuracy: 0.3417 - val_loss: 0.6578 - val_accuracy: 0.3778 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6540 - accuracy: 0.3694\n",
            "Epoch 10: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6540 - accuracy: 0.3694 - val_loss: 0.6541 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6589 - accuracy: 0.3528\n",
            "Epoch 11: val_accuracy did not improve from 0.43333\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6589 - accuracy: 0.3528 - val_loss: 0.6510 - val_accuracy: 0.3889 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6456 - accuracy: 0.4000\n",
            "Epoch 12: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.6456 - accuracy: 0.4000 - val_loss: 0.6496 - val_accuracy: 0.3889 - lr: 5.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6447 - accuracy: 0.4139\n",
            "Epoch 13: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6447 - accuracy: 0.4139 - val_loss: 0.6474 - val_accuracy: 0.3889 - lr: 5.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6434 - accuracy: 0.4167\n",
            "Epoch 14: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6434 - accuracy: 0.4167 - val_loss: 0.6463 - val_accuracy: 0.3889 - lr: 5.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6431 - accuracy: 0.3972\n",
            "Epoch 15: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.6431 - accuracy: 0.3972 - val_loss: 0.6451 - val_accuracy: 0.3889 - lr: 5.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6412 - accuracy: 0.4500\n",
            "Epoch 16: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6412 - accuracy: 0.4500 - val_loss: 0.6440 - val_accuracy: 0.3778 - lr: 5.0000e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6448 - accuracy: 0.3861\n",
            "Epoch 17: val_accuracy did not improve from 0.43333\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6448 - accuracy: 0.3861 - val_loss: 0.6425 - val_accuracy: 0.3889 - lr: 5.0000e-05\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6382 - accuracy: 0.4111\n",
            "Epoch 18: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6382 - accuracy: 0.4111 - val_loss: 0.6420 - val_accuracy: 0.3889 - lr: 2.5000e-05\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6458 - accuracy: 0.3694\n",
            "Epoch 19: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6458 - accuracy: 0.3694 - val_loss: 0.6408 - val_accuracy: 0.3889 - lr: 2.5000e-05\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6378 - accuracy: 0.3944\n",
            "Epoch 20: val_accuracy did not improve from 0.43333\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.6378 - accuracy: 0.3944 - val_loss: 0.6402 - val_accuracy: 0.3889 - lr: 2.5000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.33      0.32      0.33        28\n",
            "      Normal       0.51      0.65      0.57        31\n",
            "Tuberculosis       0.25      0.19      0.22        31\n",
            "\n",
            "    accuracy                           0.39        90\n",
            "   macro avg       0.37      0.39      0.37        90\n",
            "weighted avg       0.37      0.39      0.37        90\n",
            "\n",
            "Fold #2\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6356 - accuracy: 0.4028\n",
            "Epoch 1: val_accuracy improved from -inf to 0.46667, saving model to  Kmodel8_soft_pre_bi_sgd2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd2.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.6356 - accuracy: 0.4028 - val_loss: 0.6351 - val_accuracy: 0.4667 - lr: 2.5000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6406 - accuracy: 0.4139\n",
            "Epoch 2: val_accuracy did not improve from 0.46667\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6406 - accuracy: 0.4139 - val_loss: 0.6342 - val_accuracy: 0.4667 - lr: 2.5000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6358 - accuracy: 0.4250\n",
            "Epoch 3: val_accuracy improved from 0.46667 to 0.51111, saving model to  Kmodel8_soft_pre_bi_sgd2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd2.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.6358 - accuracy: 0.4250 - val_loss: 0.6339 - val_accuracy: 0.5111 - lr: 2.5000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6358 - accuracy: 0.4083\n",
            "Epoch 4: val_accuracy did not improve from 0.51111\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6358 - accuracy: 0.4083 - val_loss: 0.6335 - val_accuracy: 0.5000 - lr: 2.5000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6347 - accuracy: 0.4389\n",
            "Epoch 5: val_accuracy did not improve from 0.51111\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6347 - accuracy: 0.4389 - val_loss: 0.6330 - val_accuracy: 0.5000 - lr: 2.5000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6351 - accuracy: 0.4111\n",
            "Epoch 6: val_accuracy did not improve from 0.51111\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.6351 - accuracy: 0.4111 - val_loss: 0.6323 - val_accuracy: 0.5000 - lr: 2.5000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6369 - accuracy: 0.4056\n",
            "Epoch 7: val_accuracy did not improve from 0.51111\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6369 - accuracy: 0.4056 - val_loss: 0.6317 - val_accuracy: 0.5000 - lr: 2.5000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6360 - accuracy: 0.3889\n",
            "Epoch 8: val_accuracy did not improve from 0.51111\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6360 - accuracy: 0.3889 - val_loss: 0.6302 - val_accuracy: 0.4889 - lr: 2.5000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6371 - accuracy: 0.4222\n",
            "Epoch 9: val_accuracy did not improve from 0.51111\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.6371 - accuracy: 0.4222 - val_loss: 0.6299 - val_accuracy: 0.4889 - lr: 2.5000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6354 - accuracy: 0.4389\n",
            "Epoch 10: val_accuracy did not improve from 0.51111\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6354 - accuracy: 0.4389 - val_loss: 0.6303 - val_accuracy: 0.4889 - lr: 1.2500e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6333 - accuracy: 0.4250\n",
            "Epoch 11: val_accuracy did not improve from 0.51111\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6333 - accuracy: 0.4250 - val_loss: 0.6313 - val_accuracy: 0.4667 - lr: 1.2500e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6349 - accuracy: 0.4167\n",
            "Epoch 12: val_accuracy did not improve from 0.51111\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6349 - accuracy: 0.4167 - val_loss: 0.6308 - val_accuracy: 0.4889 - lr: 1.2500e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6380 - accuracy: 0.4139\n",
            "Epoch 13: val_accuracy improved from 0.51111 to 0.52222, saving model to  Kmodel8_soft_pre_bi_sgd2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd2.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.6380 - accuracy: 0.4139 - val_loss: 0.6303 - val_accuracy: 0.5222 - lr: 1.2500e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6370 - accuracy: 0.4306\n",
            "Epoch 14: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6370 - accuracy: 0.4306 - val_loss: 0.6297 - val_accuracy: 0.5222 - lr: 1.2500e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6336 - accuracy: 0.4500\n",
            "Epoch 15: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6336 - accuracy: 0.4500 - val_loss: 0.6297 - val_accuracy: 0.5222 - lr: 1.2500e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6352 - accuracy: 0.3750\n",
            "Epoch 16: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6352 - accuracy: 0.3750 - val_loss: 0.6294 - val_accuracy: 0.5111 - lr: 1.2500e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6328 - accuracy: 0.4583\n",
            "Epoch 17: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6328 - accuracy: 0.4583 - val_loss: 0.6293 - val_accuracy: 0.5111 - lr: 1.2500e-05\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6317 - accuracy: 0.4583\n",
            "Epoch 18: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6317 - accuracy: 0.4583 - val_loss: 0.6278 - val_accuracy: 0.5111 - lr: 1.2500e-05\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6329 - accuracy: 0.4361\n",
            "Epoch 19: val_accuracy did not improve from 0.52222\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6329 - accuracy: 0.4361 - val_loss: 0.6283 - val_accuracy: 0.5111 - lr: 1.2500e-05\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6285 - accuracy: 0.4306\n",
            "Epoch 20: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6285 - accuracy: 0.4306 - val_loss: 0.6273 - val_accuracy: 0.5111 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6347 - accuracy: 0.3917\n",
            "Epoch 21: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6347 - accuracy: 0.3917 - val_loss: 0.6283 - val_accuracy: 0.5111 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6324 - accuracy: 0.4056\n",
            "Epoch 22: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6324 - accuracy: 0.4056 - val_loss: 0.6283 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6296 - accuracy: 0.4444\n",
            "Epoch 23: val_accuracy improved from 0.52222 to 0.53333, saving model to  Kmodel8_soft_pre_bi_sgd2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd2.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.6296 - accuracy: 0.4444 - val_loss: 0.6278 - val_accuracy: 0.5333 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6275 - accuracy: 0.4583\n",
            "Epoch 24: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6275 - accuracy: 0.4583 - val_loss: 0.6274 - val_accuracy: 0.5333 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6303 - accuracy: 0.4222\n",
            "Epoch 25: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.6303 - accuracy: 0.4222 - val_loss: 0.6270 - val_accuracy: 0.5333 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6269 - accuracy: 0.4667\n",
            "Epoch 26: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6269 - accuracy: 0.4667 - val_loss: 0.6266 - val_accuracy: 0.5333 - lr: 1.0000e-05\n",
            "Epoch 27/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6316 - accuracy: 0.4056\n",
            "Epoch 27: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6316 - accuracy: 0.4056 - val_loss: 0.6265 - val_accuracy: 0.5333 - lr: 1.0000e-05\n",
            "Epoch 28/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6305 - accuracy: 0.4389\n",
            "Epoch 28: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6305 - accuracy: 0.4389 - val_loss: 0.6259 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 29/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6297 - accuracy: 0.4639\n",
            "Epoch 29: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6297 - accuracy: 0.4639 - val_loss: 0.6264 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 30/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6289 - accuracy: 0.4389\n",
            "Epoch 30: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6289 - accuracy: 0.4389 - val_loss: 0.6267 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 31/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6294 - accuracy: 0.4222\n",
            "Epoch 31: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6294 - accuracy: 0.4222 - val_loss: 0.6266 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 32/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6249 - accuracy: 0.4250\n",
            "Epoch 32: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.6249 - accuracy: 0.4250 - val_loss: 0.6261 - val_accuracy: 0.5333 - lr: 1.0000e-05\n",
            "Epoch 33/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6325 - accuracy: 0.4056\n",
            "Epoch 33: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.6325 - accuracy: 0.4056 - val_loss: 0.6264 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 34/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6227 - accuracy: 0.5139\n",
            "Epoch 34: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6227 - accuracy: 0.5139 - val_loss: 0.6265 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 35/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6314 - accuracy: 0.4361\n",
            "Epoch 35: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6314 - accuracy: 0.4361 - val_loss: 0.6256 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 36/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6252 - accuracy: 0.4722\n",
            "Epoch 36: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6252 - accuracy: 0.4722 - val_loss: 0.6253 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 37/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6304 - accuracy: 0.4194\n",
            "Epoch 37: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6304 - accuracy: 0.4194 - val_loss: 0.6249 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 38/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6290 - accuracy: 0.4306\n",
            "Epoch 38: val_accuracy did not improve from 0.53333\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.6290 - accuracy: 0.4306 - val_loss: 0.6248 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.59      0.29      0.39        34\n",
            "      Normal       0.48      0.89      0.62        27\n",
            "Tuberculosis       0.57      0.45      0.50        29\n",
            "\n",
            "    accuracy                           0.52        90\n",
            "   macro avg       0.54      0.54      0.51        90\n",
            "weighted avg       0.55      0.52      0.50        90\n",
            "\n",
            "Fold #3\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6319 - accuracy: 0.4083\n",
            "Epoch 1: val_accuracy improved from -inf to 0.52222, saving model to  Kmodel8_soft_pre_bi_sgd3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd3.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.6319 - accuracy: 0.4083 - val_loss: 0.6209 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6349 - accuracy: 0.4333\n",
            "Epoch 2: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.6349 - accuracy: 0.4333 - val_loss: 0.6211 - val_accuracy: 0.5111 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6328 - accuracy: 0.4500\n",
            "Epoch 3: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.6328 - accuracy: 0.4500 - val_loss: 0.6200 - val_accuracy: 0.5111 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6304 - accuracy: 0.4472\n",
            "Epoch 4: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 254ms/step - loss: 0.6304 - accuracy: 0.4472 - val_loss: 0.6198 - val_accuracy: 0.5111 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6266 - accuracy: 0.4611\n",
            "Epoch 5: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.6266 - accuracy: 0.4611 - val_loss: 0.6205 - val_accuracy: 0.5111 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6315 - accuracy: 0.4472\n",
            "Epoch 6: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 256ms/step - loss: 0.6315 - accuracy: 0.4472 - val_loss: 0.6203 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6289 - accuracy: 0.4472\n",
            "Epoch 7: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 257ms/step - loss: 0.6289 - accuracy: 0.4472 - val_loss: 0.6195 - val_accuracy: 0.5111 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6186 - accuracy: 0.5111\n",
            "Epoch 8: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6186 - accuracy: 0.5111 - val_loss: 0.6197 - val_accuracy: 0.5111 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6258 - accuracy: 0.4361\n",
            "Epoch 9: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.6258 - accuracy: 0.4361 - val_loss: 0.6200 - val_accuracy: 0.5111 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6262 - accuracy: 0.4611\n",
            "Epoch 10: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.6262 - accuracy: 0.4611 - val_loss: 0.6188 - val_accuracy: 0.5111 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6331 - accuracy: 0.4194\n",
            "Epoch 11: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6331 - accuracy: 0.4194 - val_loss: 0.6186 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6249 - accuracy: 0.4778\n",
            "Epoch 12: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6249 - accuracy: 0.4778 - val_loss: 0.6183 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6301 - accuracy: 0.4722\n",
            "Epoch 13: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6301 - accuracy: 0.4722 - val_loss: 0.6186 - val_accuracy: 0.5111 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6243 - accuracy: 0.4778\n",
            "Epoch 14: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6243 - accuracy: 0.4778 - val_loss: 0.6188 - val_accuracy: 0.5222 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6264 - accuracy: 0.4556\n",
            "Epoch 15: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6264 - accuracy: 0.4556 - val_loss: 0.6188 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6232 - accuracy: 0.4778\n",
            "Epoch 16: val_accuracy did not improve from 0.52222\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.6232 - accuracy: 0.4778 - val_loss: 0.6180 - val_accuracy: 0.5111 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.56      0.33      0.42        27\n",
            "      Normal       0.56      0.82      0.67        33\n",
            "Tuberculosis       0.38      0.33      0.36        30\n",
            "\n",
            "    accuracy                           0.51        90\n",
            "   macro avg       0.50      0.49      0.48        90\n",
            "weighted avg       0.50      0.51      0.49        90\n",
            "\n",
            "Fold #4\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6254 - accuracy: 0.4611\n",
            "Epoch 1: val_accuracy improved from -inf to 0.38889, saving model to  Kmodel8_soft_pre_bi_sgd4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd4.h5 /assets\n",
            "45/45 [==============================] - 47s 1s/step - loss: 0.6254 - accuracy: 0.4611 - val_loss: 0.6385 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6221 - accuracy: 0.4778\n",
            "Epoch 2: val_accuracy did not improve from 0.38889\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6221 - accuracy: 0.4778 - val_loss: 0.6388 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6274 - accuracy: 0.4361\n",
            "Epoch 3: val_accuracy improved from 0.38889 to 0.40000, saving model to  Kmodel8_soft_pre_bi_sgd4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd4.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.6274 - accuracy: 0.4361 - val_loss: 0.6383 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6283 - accuracy: 0.4139\n",
            "Epoch 4: val_accuracy did not improve from 0.40000\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6283 - accuracy: 0.4139 - val_loss: 0.6379 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6242 - accuracy: 0.4500\n",
            "Epoch 5: val_accuracy did not improve from 0.40000\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6242 - accuracy: 0.4500 - val_loss: 0.6379 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6234 - accuracy: 0.4417\n",
            "Epoch 6: val_accuracy did not improve from 0.40000\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.6234 - accuracy: 0.4417 - val_loss: 0.6381 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6243 - accuracy: 0.4583\n",
            "Epoch 7: val_accuracy did not improve from 0.40000\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6243 - accuracy: 0.4583 - val_loss: 0.6382 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6250 - accuracy: 0.4472\n",
            "Epoch 8: val_accuracy did not improve from 0.40000\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6250 - accuracy: 0.4472 - val_loss: 0.6385 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6197 - accuracy: 0.4833\n",
            "Epoch 9: val_accuracy did not improve from 0.40000\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6197 - accuracy: 0.4833 - val_loss: 0.6384 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6283 - accuracy: 0.4389\n",
            "Epoch 10: val_accuracy did not improve from 0.40000\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6283 - accuracy: 0.4389 - val_loss: 0.6375 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6253 - accuracy: 0.4806\n",
            "Epoch 11: val_accuracy did not improve from 0.40000\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6253 - accuracy: 0.4806 - val_loss: 0.6374 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6254 - accuracy: 0.4333\n",
            "Epoch 12: val_accuracy did not improve from 0.40000\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.6254 - accuracy: 0.4333 - val_loss: 0.6373 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6201 - accuracy: 0.4750\n",
            "Epoch 13: val_accuracy did not improve from 0.40000\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.6201 - accuracy: 0.4750 - val_loss: 0.6362 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6234 - accuracy: 0.4500\n",
            "Epoch 14: val_accuracy did not improve from 0.40000\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.6234 - accuracy: 0.4500 - val_loss: 0.6361 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6275 - accuracy: 0.3917\n",
            "Epoch 15: val_accuracy did not improve from 0.40000\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6275 - accuracy: 0.3917 - val_loss: 0.6361 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6240 - accuracy: 0.4611\n",
            "Epoch 16: val_accuracy improved from 0.40000 to 0.41111, saving model to  Kmodel8_soft_pre_bi_sgd4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd4.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.6240 - accuracy: 0.4611 - val_loss: 0.6357 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6183 - accuracy: 0.4639\n",
            "Epoch 17: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6183 - accuracy: 0.4639 - val_loss: 0.6352 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6281 - accuracy: 0.4472\n",
            "Epoch 18: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.6281 - accuracy: 0.4472 - val_loss: 0.6347 - val_accuracy: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6215 - accuracy: 0.4583\n",
            "Epoch 19: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 259ms/step - loss: 0.6215 - accuracy: 0.4583 - val_loss: 0.6350 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6222 - accuracy: 0.4583\n",
            "Epoch 20: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6222 - accuracy: 0.4583 - val_loss: 0.6352 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6239 - accuracy: 0.4611\n",
            "Epoch 21: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.6239 - accuracy: 0.4611 - val_loss: 0.6350 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6168 - accuracy: 0.5028\n",
            "Epoch 22: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.6168 - accuracy: 0.5028 - val_loss: 0.6354 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6211 - accuracy: 0.4611\n",
            "Epoch 23: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.6211 - accuracy: 0.4611 - val_loss: 0.6360 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6197 - accuracy: 0.4778\n",
            "Epoch 24: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.6197 - accuracy: 0.4778 - val_loss: 0.6360 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6191 - accuracy: 0.4722\n",
            "Epoch 25: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.6191 - accuracy: 0.4722 - val_loss: 0.6356 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6232 - accuracy: 0.4417\n",
            "Epoch 26: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6232 - accuracy: 0.4417 - val_loss: 0.6356 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 27/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6179 - accuracy: 0.4944\n",
            "Epoch 27: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.6179 - accuracy: 0.4944 - val_loss: 0.6346 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 28/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6217 - accuracy: 0.4667\n",
            "Epoch 28: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.6217 - accuracy: 0.4667 - val_loss: 0.6342 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 29/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6186 - accuracy: 0.4944\n",
            "Epoch 29: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.6186 - accuracy: 0.4944 - val_loss: 0.6342 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 30/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6189 - accuracy: 0.5028\n",
            "Epoch 30: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.6189 - accuracy: 0.5028 - val_loss: 0.6339 - val_accuracy: 0.3889 - lr: 1.0000e-05\n",
            "Epoch 31/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6251 - accuracy: 0.4306\n",
            "Epoch 31: val_accuracy did not improve from 0.41111\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.6251 - accuracy: 0.4306 - val_loss: 0.6338 - val_accuracy: 0.4000 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.53      0.27      0.36        30\n",
            "      Normal       0.46      0.58      0.51        31\n",
            "Tuberculosis       0.28      0.34      0.31        29\n",
            "\n",
            "    accuracy                           0.40        90\n",
            "   macro avg       0.42      0.40      0.39        90\n",
            "weighted avg       0.43      0.40      0.39        90\n",
            "\n",
            "Fold #5\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6213 - accuracy: 0.4556\n",
            "Epoch 1: val_accuracy improved from -inf to 0.44444, saving model to  Kmodel8_soft_pre_bi_sgd5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd5.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.6213 - accuracy: 0.4556 - val_loss: 0.6210 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6185 - accuracy: 0.4556\n",
            "Epoch 2: val_accuracy did not improve from 0.44444\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.6185 - accuracy: 0.4556 - val_loss: 0.6210 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6244 - accuracy: 0.4583\n",
            "Epoch 3: val_accuracy did not improve from 0.44444\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6244 - accuracy: 0.4583 - val_loss: 0.6209 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6122 - accuracy: 0.5528\n",
            "Epoch 4: val_accuracy did not improve from 0.44444\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.6122 - accuracy: 0.5528 - val_loss: 0.6209 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6133 - accuracy: 0.5250\n",
            "Epoch 5: val_accuracy improved from 0.44444 to 0.45556, saving model to  Kmodel8_soft_pre_bi_sgd5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_bi_sgd5.h5 /assets\n",
            "45/45 [==============================] - 45s 1s/step - loss: 0.6133 - accuracy: 0.5250 - val_loss: 0.6198 - val_accuracy: 0.4556 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6231 - accuracy: 0.4444\n",
            "Epoch 6: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.6231 - accuracy: 0.4444 - val_loss: 0.6204 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6130 - accuracy: 0.4889\n",
            "Epoch 7: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.6130 - accuracy: 0.4889 - val_loss: 0.6205 - val_accuracy: 0.4556 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6257 - accuracy: 0.4528\n",
            "Epoch 8: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6257 - accuracy: 0.4528 - val_loss: 0.6198 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6165 - accuracy: 0.4750\n",
            "Epoch 9: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.6165 - accuracy: 0.4750 - val_loss: 0.6193 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6233 - accuracy: 0.4417\n",
            "Epoch 10: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.6233 - accuracy: 0.4417 - val_loss: 0.6187 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6176 - accuracy: 0.4861\n",
            "Epoch 11: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 260ms/step - loss: 0.6176 - accuracy: 0.4861 - val_loss: 0.6192 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6169 - accuracy: 0.5000\n",
            "Epoch 12: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 258ms/step - loss: 0.6169 - accuracy: 0.5000 - val_loss: 0.6191 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6187 - accuracy: 0.4667\n",
            "Epoch 13: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.6187 - accuracy: 0.4667 - val_loss: 0.6189 - val_accuracy: 0.4333 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6088 - accuracy: 0.5278\n",
            "Epoch 14: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.6088 - accuracy: 0.5278 - val_loss: 0.6182 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6165 - accuracy: 0.4500\n",
            "Epoch 15: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.6165 - accuracy: 0.4500 - val_loss: 0.6184 - val_accuracy: 0.4556 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6212 - accuracy: 0.4556\n",
            "Epoch 16: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.6212 - accuracy: 0.4556 - val_loss: 0.6189 - val_accuracy: 0.4556 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6153 - accuracy: 0.4972\n",
            "Epoch 17: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.6153 - accuracy: 0.4972 - val_loss: 0.6187 - val_accuracy: 0.4556 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6158 - accuracy: 0.4750\n",
            "Epoch 18: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.6158 - accuracy: 0.4750 - val_loss: 0.6179 - val_accuracy: 0.4556 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6192 - accuracy: 0.4750\n",
            "Epoch 19: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.6192 - accuracy: 0.4750 - val_loss: 0.6177 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.6118 - accuracy: 0.5444\n",
            "Epoch 20: val_accuracy did not improve from 0.45556\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.6118 - accuracy: 0.5444 - val_loss: 0.6176 - val_accuracy: 0.4444 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.61      0.35      0.45        31\n",
            "      Normal       0.44      0.79      0.56        28\n",
            "Tuberculosis       0.32      0.23      0.26        31\n",
            "\n",
            "    accuracy                           0.44        90\n",
            "   macro avg       0.46      0.46      0.43        90\n",
            "weighted avg       0.46      0.44      0.42        90\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       0.51      0.31      0.39       150\n",
            "      Normal       0.49      0.74      0.59       150\n",
            "Tuberculosis       0.35      0.31      0.33       150\n",
            "\n",
            "    accuracy                           0.45       450\n",
            "   macro avg       0.45      0.45      0.43       450\n",
            "weighted avg       0.45      0.45      0.43       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8 soft pre cate \n"
      ],
      "metadata": {
        "id": "gIezSP7KHxA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 8\n",
        "filepath = \"Kmodel8_soft_pre_cate.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "6af5c167-6393-47b9-a4ca-3407a512b810",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7LqShb-HxA5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:05<00:00, 87.44it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel8_soft_pre_cate{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "zInSrqiRHxA-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9090cb40-36bc-4443-e2c0-8f11f422d634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold #1\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7615 - accuracy: 0.6528\n",
            "Epoch 1: val_accuracy improved from -inf to 0.60000, saving model to  Kmodel8_soft_pre_cate1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate1.h5 /assets\n",
            "45/45 [==============================] - 59s 1s/step - loss: 0.7615 - accuracy: 0.6528 - val_loss: 0.8505 - val_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.5673 - accuracy: 0.7750\n",
            "Epoch 2: val_accuracy improved from 0.60000 to 0.71111, saving model to  Kmodel8_soft_pre_cate1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate1.h5 /assets\n",
            "45/45 [==============================] - 47s 1s/step - loss: 0.5673 - accuracy: 0.7750 - val_loss: 0.7341 - val_accuracy: 0.7111 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.5094 - accuracy: 0.8000\n",
            "Epoch 3: val_accuracy did not improve from 0.71111\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.5094 - accuracy: 0.8000 - val_loss: 1.2492 - val_accuracy: 0.6222 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.3652 - accuracy: 0.8583\n",
            "Epoch 4: val_accuracy improved from 0.71111 to 0.77778, saving model to  Kmodel8_soft_pre_cate1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate1.h5 /assets\n",
            "45/45 [==============================] - 47s 1s/step - loss: 0.3652 - accuracy: 0.8583 - val_loss: 0.5917 - val_accuracy: 0.7778 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2976 - accuracy: 0.8944\n",
            "Epoch 5: val_accuracy did not improve from 0.77778\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.2976 - accuracy: 0.8944 - val_loss: 1.0703 - val_accuracy: 0.6889 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2514 - accuracy: 0.9056\n",
            "Epoch 6: val_accuracy improved from 0.77778 to 0.78889, saving model to  Kmodel8_soft_pre_cate1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate1.h5 /assets\n",
            "45/45 [==============================] - 47s 1s/step - loss: 0.2514 - accuracy: 0.9056 - val_loss: 0.7613 - val_accuracy: 0.7889 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2582 - accuracy: 0.9000\n",
            "Epoch 7: val_accuracy did not improve from 0.78889\n",
            "45/45 [==============================] - 12s 273ms/step - loss: 0.2582 - accuracy: 0.9000 - val_loss: 2.4470 - val_accuracy: 0.6556 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2248 - accuracy: 0.9056\n",
            "Epoch 8: val_accuracy did not improve from 0.78889\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.2248 - accuracy: 0.9056 - val_loss: 1.5605 - val_accuracy: 0.7111 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1829 - accuracy: 0.9278\n",
            "Epoch 9: val_accuracy did not improve from 0.78889\n",
            "45/45 [==============================] - 12s 270ms/step - loss: 0.1829 - accuracy: 0.9278 - val_loss: 0.9775 - val_accuracy: 0.7556 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1219 - accuracy: 0.9583\n",
            "Epoch 10: val_accuracy did not improve from 0.78889\n",
            "45/45 [==============================] - 12s 270ms/step - loss: 0.1219 - accuracy: 0.9583 - val_loss: 2.0539 - val_accuracy: 0.7111 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2220 - accuracy: 0.9278\n",
            "Epoch 11: val_accuracy did not improve from 0.78889\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.2220 - accuracy: 0.9278 - val_loss: 0.9083 - val_accuracy: 0.7444 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1024 - accuracy: 0.9639\n",
            "Epoch 12: val_accuracy improved from 0.78889 to 0.83333, saving model to  Kmodel8_soft_pre_cate1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate1.h5 /assets\n",
            "45/45 [==============================] - 47s 1s/step - loss: 0.1024 - accuracy: 0.9639 - val_loss: 0.6529 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1252 - accuracy: 0.9611\n",
            "Epoch 13: val_accuracy did not improve from 0.83333\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.1252 - accuracy: 0.9611 - val_loss: 1.0029 - val_accuracy: 0.8111 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1025 - accuracy: 0.9694\n",
            "Epoch 14: val_accuracy improved from 0.83333 to 0.85556, saving model to  Kmodel8_soft_pre_cate1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate1.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.1025 - accuracy: 0.9694 - val_loss: 0.8471 - val_accuracy: 0.8556 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1467 - accuracy: 0.9528\n",
            "Epoch 15: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.1467 - accuracy: 0.9528 - val_loss: 3.2847 - val_accuracy: 0.5444 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1153 - accuracy: 0.9500\n",
            "Epoch 16: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.1153 - accuracy: 0.9500 - val_loss: 1.6126 - val_accuracy: 0.7556 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0988 - accuracy: 0.9667\n",
            "Epoch 17: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0988 - accuracy: 0.9667 - val_loss: 0.6817 - val_accuracy: 0.8222 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1100 - accuracy: 0.9583\n",
            "Epoch 18: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.1100 - accuracy: 0.9583 - val_loss: 1.8598 - val_accuracy: 0.7444 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1012 - accuracy: 0.9556\n",
            "Epoch 19: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.1012 - accuracy: 0.9556 - val_loss: 2.2946 - val_accuracy: 0.6889 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1059 - accuracy: 0.9639\n",
            "Epoch 20: val_accuracy did not improve from 0.85556\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.1059 - accuracy: 0.9639 - val_loss: 1.0209 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.9750\n",
            "Epoch 21: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0609 - accuracy: 0.9750 - val_loss: 1.0149 - val_accuracy: 0.7778 - lr: 5.0000e-05\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9861\n",
            "Epoch 22: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0370 - accuracy: 0.9861 - val_loss: 2.4755 - val_accuracy: 0.7111 - lr: 5.0000e-05\n",
            "Epoch 23/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.9861\n",
            "Epoch 23: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0458 - accuracy: 0.9861 - val_loss: 0.7551 - val_accuracy: 0.8444 - lr: 5.0000e-05\n",
            "Epoch 24/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9861\n",
            "Epoch 24: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.0330 - accuracy: 0.9861 - val_loss: 1.0272 - val_accuracy: 0.8000 - lr: 5.0000e-05\n",
            "Epoch 25/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9972\n",
            "Epoch 25: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0187 - accuracy: 0.9972 - val_loss: 1.5656 - val_accuracy: 0.7778 - lr: 5.0000e-05\n",
            "Epoch 26/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.9861\n",
            "Epoch 26: val_accuracy did not improve from 0.85556\n",
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0296 - accuracy: 0.9861 - val_loss: 1.9463 - val_accuracy: 0.7778 - lr: 5.0000e-05\n",
            "Epoch 27/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0806 - accuracy: 0.9750\n",
            "Epoch 27: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0806 - accuracy: 0.9750 - val_loss: 1.2162 - val_accuracy: 0.8111 - lr: 2.5000e-05\n",
            "Epoch 28/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9944\n",
            "Epoch 28: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0232 - accuracy: 0.9944 - val_loss: 1.3735 - val_accuracy: 0.8111 - lr: 2.5000e-05\n",
            "Epoch 29/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9833\n",
            "Epoch 29: val_accuracy did not improve from 0.85556\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0554 - accuracy: 0.9833 - val_loss: 1.5852 - val_accuracy: 0.7778 - lr: 2.5000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.43      0.60        28\n",
            "      Normal       0.97      0.90      0.93        31\n",
            "Tuberculosis       0.61      0.97      0.75        31\n",
            "\n",
            "    accuracy                           0.78        90\n",
            "   macro avg       0.86      0.77      0.76        90\n",
            "weighted avg       0.85      0.78      0.77        90\n",
            "\n",
            "Fold #2\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.2068 - accuracy: 0.9417\n",
            "Epoch 1: val_accuracy improved from -inf to 1.00000, saving model to  Kmodel8_soft_pre_cate2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate2.h5 /assets\n",
            "45/45 [==============================] - 47s 1s/step - loss: 0.2068 - accuracy: 0.9417 - val_loss: 0.0048 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.1723 - accuracy: 0.9556\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.1723 - accuracy: 0.9556 - val_loss: 0.0066 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0691 - accuracy: 0.9833\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0691 - accuracy: 0.9833 - val_loss: 0.0184 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0559 - accuracy: 0.9861\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0559 - accuracy: 0.9861 - val_loss: 0.0066 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0732 - accuracy: 0.9750\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0732 - accuracy: 0.9750 - val_loss: 0.0299 - val_accuracy: 0.9889 - lr: 2.5000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.9806\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0795 - accuracy: 0.9806 - val_loss: 0.0040 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 0.9889\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0242 - accuracy: 0.9889 - val_loss: 0.0022 - val_accuracy: 1.0000 - lr: 1.2500e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9889\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.0248 - accuracy: 0.9889 - val_loss: 0.0035 - val_accuracy: 1.0000 - lr: 1.2500e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0558 - accuracy: 0.9833\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.0558 - accuracy: 0.9833 - val_loss: 0.0089 - val_accuracy: 1.0000 - lr: 1.2500e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9889\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.0352 - accuracy: 0.9889 - val_loss: 0.0092 - val_accuracy: 1.0000 - lr: 1.2500e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9944\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 271ms/step - loss: 0.0197 - accuracy: 0.9944 - val_loss: 0.0052 - val_accuracy: 1.0000 - lr: 1.2500e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9889\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0397 - accuracy: 0.9889 - val_loss: 0.0123 - val_accuracy: 1.0000 - lr: 1.2500e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9833\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0272 - accuracy: 0.9833 - val_loss: 0.0489 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9944\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 270ms/step - loss: 0.0203 - accuracy: 0.9944 - val_loss: 0.0771 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9944\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0159 - accuracy: 0.9944 - val_loss: 0.1632 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.79      0.89        34\n",
            "      Normal       1.00      1.00      1.00        27\n",
            "Tuberculosis       0.81      1.00      0.89        29\n",
            "\n",
            "    accuracy                           0.92        90\n",
            "   macro avg       0.94      0.93      0.93        90\n",
            "weighted avg       0.94      0.92      0.92        90\n",
            "\n",
            "Fold #3\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9972\n",
            "Epoch 1: val_accuracy improved from -inf to 0.96667, saving model to  Kmodel8_soft_pre_cate3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate3.h5 /assets\n",
            "45/45 [==============================] - 47s 1s/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.0678 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9944\n",
            "Epoch 2: val_accuracy improved from 0.96667 to 0.98889, saving model to  Kmodel8_soft_pre_cate3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate3.h5 /assets\n",
            "45/45 [==============================] - 47s 1s/step - loss: 0.0202 - accuracy: 0.9944 - val_loss: 0.0351 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9917\n",
            "Epoch 3: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0185 - accuracy: 0.9917 - val_loss: 0.0308 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0412 - accuracy: 0.9917\n",
            "Epoch 4: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0412 - accuracy: 0.9917 - val_loss: 0.0296 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9861\n",
            "Epoch 5: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0269 - accuracy: 0.9861 - val_loss: 0.0486 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9917\n",
            "Epoch 7: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0222 - accuracy: 0.9917 - val_loss: 0.0296 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9944\n",
            "Epoch 10: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0348 - accuracy: 0.9944 - val_loss: 0.0332 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9917\n",
            "Epoch 12: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 0.0478 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 270ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9972\n",
            "Epoch 14: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 269ms/step - loss: 0.0066 - accuracy: 0.9972 - val_loss: 0.0260 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9944\n",
            "Epoch 15: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 270ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.0383 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 268ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9972\n",
            "Epoch 17: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.0185 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.96      0.98        27\n",
            "      Normal       1.00      1.00      1.00        33\n",
            "Tuberculosis       0.97      1.00      0.98        30\n",
            "\n",
            "    accuracy                           0.99        90\n",
            "   macro avg       0.99      0.99      0.99        90\n",
            "weighted avg       0.99      0.99      0.99        90\n",
            "\n",
            "Fold #4\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 1: val_accuracy improved from -inf to 0.97778, saving model to  Kmodel8_soft_pre_cate4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate4.h5 /assets\n",
            "45/45 [==============================] - 47s 1s/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.9833\n",
            "Epoch 2: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.0659 - accuracy: 0.9833 - val_loss: 0.0804 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9889\n",
            "Epoch 3: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0269 - accuracy: 0.9889 - val_loss: 0.0716 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 4: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 12s 275ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0826 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9944\n",
            "Epoch 5: val_accuracy improved from 0.97778 to 0.98889, saving model to  Kmodel8_soft_pre_cate4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate4.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.0151 - accuracy: 0.9944 - val_loss: 0.0483 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9972\n",
            "Epoch 9: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 0.1204 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9972\n",
            "Epoch 10: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0063 - accuracy: 0.9972 - val_loss: 0.1011 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9972\n",
            "Epoch 11: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0066 - accuracy: 0.9972 - val_loss: 0.0960 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9944\n",
            "Epoch 14: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 261ms/step - loss: 0.0144 - accuracy: 0.9944 - val_loss: 0.0606 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0628 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9944\n",
            "Epoch 17: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0138 - accuracy: 0.9944 - val_loss: 0.1102 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9944\n",
            "Epoch 18: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0072 - accuracy: 0.9944 - val_loss: 0.0931 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9972\n",
            "Epoch 19: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0072 - accuracy: 0.9972 - val_loss: 0.0838 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9917\n",
            "Epoch 20: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0138 - accuracy: 0.9917 - val_loss: 0.0684 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.93      0.97        30\n",
            "      Normal       1.00      1.00      1.00        31\n",
            "Tuberculosis       0.94      1.00      0.97        29\n",
            "\n",
            "    accuracy                           0.98        90\n",
            "   macro avg       0.98      0.98      0.98        90\n",
            "weighted avg       0.98      0.98      0.98        90\n",
            "\n",
            "Fold #5\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 1: val_accuracy improved from -inf to 0.97778, saving model to  Kmodel8_soft_pre_cate5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate5.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 2: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 3: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9972\n",
            "Epoch 4: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0823 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 5: val_accuracy did not improve from 0.97778\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9944\n",
            "Epoch 6: val_accuracy improved from 0.97778 to 0.98889, saving model to  Kmodel8_soft_pre_cate5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate5.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 0.0290 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 0.98889\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0292 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy improved from 0.98889 to 1.00000, saving model to  Kmodel8_soft_pre_cate5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate5.h5 /assets\n",
            "45/45 [==============================] - 46s 1s/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9972\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0047 - accuracy: 0.9972 - val_loss: 0.0146 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9944\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0140 - accuracy: 0.9944 - val_loss: 0.0377 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9944\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 262ms/step - loss: 0.0111 - accuracy: 0.9944 - val_loss: 0.0647 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0327 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9972\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0036 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 263ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9944\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0118 - accuracy: 0.9944 - val_loss: 0.0140 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9972\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 267ms/step - loss: 0.0073 - accuracy: 0.9972 - val_loss: 0.0199 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 266ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9972\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 264ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.0274 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9972\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0060 - accuracy: 0.9972 - val_loss: 0.0354 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9972\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0047 - accuracy: 0.9972 - val_loss: 0.0458 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "45/45 [==============================] - 12s 265ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.94      0.97        31\n",
            "      Normal       1.00      1.00      1.00        28\n",
            "Tuberculosis       0.94      1.00      0.97        31\n",
            "\n",
            "    accuracy                           0.98        90\n",
            "   macro avg       0.98      0.98      0.98        90\n",
            "weighted avg       0.98      0.98      0.98        90\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.81      0.90       150\n",
            "      Normal       0.99      0.98      0.99       150\n",
            "Tuberculosis       0.83      0.99      0.90       150\n",
            "\n",
            "    accuracy                           0.93       450\n",
            "   macro avg       0.94      0.93      0.93       450\n",
            "weighted avg       0.94      0.93      0.93       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8 soft pre cate adam\n"
      ],
      "metadata": {
        "id": "nbfA8plqHxBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 8\n",
        "filepath = \"Kmodel8_soft_pre_cate_adam.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "95a53f9d-8f4b-4b3d-d67f-a1c4255339dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOXzS-frHxBA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [02:37<00:00,  2.86it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel8_soft_pre_cate_adam{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "8TXqdL-wHxBA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "674f7c85-0eb4-4e9d-b6cc-2678dee7cd31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "87924736/87910968 [==============================] - 1s 0us/step\n",
            "Fold #1\n",
            "Epoch 1/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7665 - accuracy: 0.6139\n",
            "Epoch 1: val_accuracy improved from -inf to 0.56667, saving model to  Kmodel8_soft_pre_cate_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_adam1.h5 /assets\n",
            "45/45 [==============================] - 240s 5s/step - loss: 0.7665 - accuracy: 0.6139 - val_loss: 1.0940 - val_accuracy: 0.5667 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.5185 - accuracy: 0.8056\n",
            "Epoch 2: val_accuracy improved from 0.56667 to 0.78889, saving model to  Kmodel8_soft_pre_cate_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel8_soft_pre_cate_adam1.h5 /assets\n",
            "45/45 [==============================] - 222s 5s/step - loss: 0.5185 - accuracy: 0.8056 - val_loss: 0.5704 - val_accuracy: 0.7889 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "42/45 [===========================>..] - ETA: 11s - loss: 0.4034 - accuracy: 0.8452"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8 soft pre cate sgd\n"
      ],
      "metadata": {
        "id": "W_E0EHBiQlIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 8\n",
        "filepath = \"Kmodel8_soft_pre_cate_sgd.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "id": "ZHY8s-kPQlIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel8_soft_pre_cate_sgd{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "xEFeEAyBQlIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 16\n"
      ],
      "metadata": {
        "id": "AdgXpLcnREHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 16  soft pre bi\n"
      ],
      "metadata": {
        "id": "NZUvi2SEREHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 16\n",
        "filepath = \"Kmodel16_soft_pre_bi.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "id": "L5EfGRXwREHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f33b3a67-92fd-4145-b7a1-144ead7f4e7f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [03:49<00:00,  1.96it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel16_soft_pre_bi{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "wzmw0gyPREHo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9ebfe1d-d63f-4f05-a8ee-e4f38cdb48c0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "87924736/87910968 [==============================] - 1s 0us/step\n",
            "Fold #1\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.4811 - accuracy: 0.6628\n",
            "Epoch 1: val_accuracy improved from -inf to 0.34444, saving model to  Kmodel16_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi1.h5 /assets\n",
            "22/22 [==============================] - 227s 10s/step - loss: 0.4811 - accuracy: 0.6628 - val_loss: 1.0341 - val_accuracy: 0.3444 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.3386 - accuracy: 0.8081\n",
            "Epoch 2: val_accuracy improved from 0.34444 to 0.47778, saving model to  Kmodel16_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi1.h5 /assets\n",
            "22/22 [==============================] - 216s 10s/step - loss: 0.3386 - accuracy: 0.8081 - val_loss: 0.9141 - val_accuracy: 0.4778 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.2409 - accuracy: 0.8488\n",
            "Epoch 3: val_accuracy improved from 0.47778 to 0.53333, saving model to  Kmodel16_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi1.h5 /assets\n",
            "22/22 [==============================] - 217s 10s/step - loss: 0.2409 - accuracy: 0.8488 - val_loss: 0.8740 - val_accuracy: 0.5333 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1648 - accuracy: 0.8953\n",
            "Epoch 4: val_accuracy improved from 0.53333 to 0.62222, saving model to  Kmodel16_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi1.h5 /assets\n",
            "22/22 [==============================] - 216s 10s/step - loss: 0.1648 - accuracy: 0.8953 - val_loss: 0.8616 - val_accuracy: 0.6222 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1802 - accuracy: 0.9070\n",
            "Epoch 5: val_accuracy did not improve from 0.62222\n",
            "22/22 [==============================] - 182s 8s/step - loss: 0.1802 - accuracy: 0.9070 - val_loss: 1.0653 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1243 - accuracy: 0.9244\n",
            "Epoch 6: val_accuracy improved from 0.62222 to 0.71111, saving model to  Kmodel16_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi1.h5 /assets\n",
            "22/22 [==============================] - 211s 10s/step - loss: 0.1243 - accuracy: 0.9244 - val_loss: 0.7703 - val_accuracy: 0.7111 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1157 - accuracy: 0.9419\n",
            "Epoch 7: val_accuracy improved from 0.71111 to 0.76667, saving model to  Kmodel16_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi1.h5 /assets\n",
            "22/22 [==============================] - 206s 9s/step - loss: 0.1157 - accuracy: 0.9419 - val_loss: 0.7463 - val_accuracy: 0.7667 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1382 - accuracy: 0.9244\n",
            "Epoch 8: val_accuracy did not improve from 0.76667\n",
            "22/22 [==============================] - 178s 8s/step - loss: 0.1382 - accuracy: 0.9244 - val_loss: 0.7506 - val_accuracy: 0.7111 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.9651\n",
            "Epoch 9: val_accuracy did not improve from 0.76667\n",
            "22/22 [==============================] - 176s 8s/step - loss: 0.0633 - accuracy: 0.9651 - val_loss: 1.0351 - val_accuracy: 0.7444 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 0.9535\n",
            "Epoch 10: val_accuracy did not improve from 0.76667\n",
            "22/22 [==============================] - 175s 8s/step - loss: 0.0983 - accuracy: 0.9535 - val_loss: 0.8169 - val_accuracy: 0.7444 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9564\n",
            "Epoch 11: val_accuracy improved from 0.76667 to 0.77778, saving model to  Kmodel16_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi1.h5 /assets\n",
            "22/22 [==============================] - 206s 9s/step - loss: 0.0680 - accuracy: 0.9564 - val_loss: 0.7305 - val_accuracy: 0.7778 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0579 - accuracy: 0.9767\n",
            "Epoch 12: val_accuracy did not improve from 0.77778\n",
            "22/22 [==============================] - 177s 8s/step - loss: 0.0579 - accuracy: 0.9767 - val_loss: 0.9532 - val_accuracy: 0.7111 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9826\n",
            "Epoch 13: val_accuracy improved from 0.77778 to 0.83333, saving model to  Kmodel16_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi1.h5 /assets\n",
            "22/22 [==============================] - 209s 10s/step - loss: 0.0351 - accuracy: 0.9826 - val_loss: 0.5902 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.9709\n",
            "Epoch 14: val_accuracy did not improve from 0.83333\n",
            "22/22 [==============================] - 176s 8s/step - loss: 0.0454 - accuracy: 0.9709 - val_loss: 0.6669 - val_accuracy: 0.7556 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9709\n",
            "Epoch 15: val_accuracy improved from 0.83333 to 0.85556, saving model to  Kmodel16_soft_pre_bi1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi1.h5 /assets\n",
            "22/22 [==============================] - 206s 9s/step - loss: 0.0537 - accuracy: 0.9709 - val_loss: 0.4069 - val_accuracy: 0.8556 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9855\n",
            "Epoch 16: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 175s 8s/step - loss: 0.0581 - accuracy: 0.9855 - val_loss: 0.4812 - val_accuracy: 0.8222 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9913\n",
            "Epoch 17: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 176s 8s/step - loss: 0.0292 - accuracy: 0.9913 - val_loss: 0.9138 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.9709\n",
            "Epoch 18: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 177s 8s/step - loss: 0.0601 - accuracy: 0.9709 - val_loss: 1.1632 - val_accuracy: 0.6333 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.9855\n",
            "Epoch 19: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 182s 8s/step - loss: 0.0305 - accuracy: 0.9855 - val_loss: 1.2841 - val_accuracy: 0.6333 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.9535\n",
            "Epoch 20: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 185s 8s/step - loss: 0.0706 - accuracy: 0.9535 - val_loss: 0.3794 - val_accuracy: 0.8111 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.9709\n",
            "Epoch 21: val_accuracy did not improve from 0.85556\n",
            "\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "22/22 [==============================] - 182s 8s/step - loss: 0.0500 - accuracy: 0.9709 - val_loss: 0.8250 - val_accuracy: 0.7222 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0441 - accuracy: 0.9797\n",
            "Epoch 22: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 177s 8s/step - loss: 0.0441 - accuracy: 0.9797 - val_loss: 0.6373 - val_accuracy: 0.7222 - lr: 5.0000e-05\n",
            "Epoch 23/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9884\n",
            "Epoch 23: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 177s 8s/step - loss: 0.0288 - accuracy: 0.9884 - val_loss: 0.5780 - val_accuracy: 0.7778 - lr: 5.0000e-05\n",
            "Epoch 24/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9913\n",
            "Epoch 24: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 176s 8s/step - loss: 0.0187 - accuracy: 0.9913 - val_loss: 0.7870 - val_accuracy: 0.7333 - lr: 5.0000e-05\n",
            "Epoch 25/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9913\n",
            "Epoch 25: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 175s 8s/step - loss: 0.0150 - accuracy: 0.9913 - val_loss: 0.7849 - val_accuracy: 0.7222 - lr: 5.0000e-05\n",
            "Epoch 26/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9972\n",
            "Epoch 26: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 179s 8s/step - loss: 0.0134 - accuracy: 0.9972 - val_loss: 1.2737 - val_accuracy: 0.6778 - lr: 5.0000e-05\n",
            "Epoch 27/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9942\n",
            "Epoch 27: val_accuracy did not improve from 0.85556\n",
            "\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "22/22 [==============================] - 175s 8s/step - loss: 0.0131 - accuracy: 0.9942 - val_loss: 1.5037 - val_accuracy: 0.6333 - lr: 5.0000e-05\n",
            "Epoch 28/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9942\n",
            "Epoch 28: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 175s 8s/step - loss: 0.0221 - accuracy: 0.9942 - val_loss: 1.1743 - val_accuracy: 0.6667 - lr: 2.5000e-05\n",
            "Epoch 29/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9971\n",
            "Epoch 29: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 174s 8s/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 1.0045 - val_accuracy: 0.6889 - lr: 2.5000e-05\n",
            "Epoch 30/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9913\n",
            "Epoch 30: val_accuracy did not improve from 0.85556\n",
            "22/22 [==============================] - 175s 8s/step - loss: 0.0165 - accuracy: 0.9913 - val_loss: 0.8076 - val_accuracy: 0.7111 - lr: 2.5000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.36      0.53        28\n",
            "      Normal       0.83      0.81      0.82        31\n",
            "Tuberculosis       0.58      0.94      0.72        31\n",
            "\n",
            "    accuracy                           0.71        90\n",
            "   macro avg       0.80      0.70      0.69        90\n",
            "weighted avg       0.80      0.71      0.69        90\n",
            "\n",
            "Fold #2\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1146 - accuracy: 0.9535\n",
            "Epoch 1: val_accuracy improved from -inf to 0.98889, saving model to  Kmodel16_soft_pre_bi2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi2.h5 /assets\n",
            "22/22 [==============================] - 203s 9s/step - loss: 0.1146 - accuracy: 0.9535 - val_loss: 0.0100 - val_accuracy: 0.9889 - lr: 2.5000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9738\n",
            "Epoch 2: val_accuracy improved from 0.98889 to 1.00000, saving model to  Kmodel16_soft_pre_bi2.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi2.h5 /assets\n",
            "22/22 [==============================] - 203s 9s/step - loss: 0.0487 - accuracy: 0.9738 - val_loss: 0.0014 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0524 - accuracy: 0.9709\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0524 - accuracy: 0.9709 - val_loss: 3.8147e-04 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9826\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0236 - accuracy: 0.9826 - val_loss: 0.0016 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9886\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 176s 8s/step - loss: 0.0209 - accuracy: 0.9886 - val_loss: 8.1388e-04 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9913\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0235 - accuracy: 0.9913 - val_loss: 0.0078 - val_accuracy: 0.9889 - lr: 2.5000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9889 - lr: 2.5000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9738\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0459 - accuracy: 0.9738 - val_loss: 0.0081 - val_accuracy: 0.9889 - lr: 2.5000e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9884\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0273 - accuracy: 0.9884 - val_loss: 0.0130 - val_accuracy: 0.9889 - lr: 1.2500e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9913\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0222 - accuracy: 0.9913 - val_loss: 0.0138 - val_accuracy: 0.9889 - lr: 1.2500e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 0.9855\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0315 - accuracy: 0.9855 - val_loss: 0.0216 - val_accuracy: 0.9889 - lr: 1.2500e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9971\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0081 - accuracy: 0.9971 - val_loss: 0.0327 - val_accuracy: 0.9889 - lr: 1.2500e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9913\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0153 - accuracy: 0.9913 - val_loss: 0.0377 - val_accuracy: 0.9889 - lr: 1.2500e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9971\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.0401 - val_accuracy: 0.9889 - lr: 1.2500e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9942\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0200 - accuracy: 0.9942 - val_loss: 0.0504 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9971\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0078 - accuracy: 0.9971 - val_loss: 0.0691 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.88      0.94        34\n",
            "      Normal       1.00      1.00      1.00        27\n",
            "Tuberculosis       0.88      1.00      0.94        29\n",
            "\n",
            "    accuracy                           0.96        90\n",
            "   macro avg       0.96      0.96      0.96        90\n",
            "weighted avg       0.96      0.96      0.96        90\n",
            "\n",
            "Fold #3\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9884\n",
            "Epoch 1: val_accuracy improved from -inf to 0.97778, saving model to  Kmodel16_soft_pre_bi3.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi3.h5 /assets\n",
            "22/22 [==============================] - 203s 9s/step - loss: 0.0260 - accuracy: 0.9884 - val_loss: 0.0388 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9942\n",
            "Epoch 2: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0153 - accuracy: 0.9942 - val_loss: 0.0930 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9971\n",
            "Epoch 3: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 174s 8s/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.1105 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000\n",
            "Epoch 4: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9942\n",
            "Epoch 5: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 182s 8s/step - loss: 0.0125 - accuracy: 0.9942 - val_loss: 0.1297 - val_accuracy: 0.9111 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 194s 9s/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9855\n",
            "Epoch 7: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 187s 9s/step - loss: 0.0332 - accuracy: 0.9855 - val_loss: 0.0696 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9942\n",
            "Epoch 8: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 192s 9s/step - loss: 0.0103 - accuracy: 0.9942 - val_loss: 0.0523 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9942\n",
            "Epoch 9: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 187s 9s/step - loss: 0.0086 - accuracy: 0.9942 - val_loss: 0.1190 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9971\n",
            "Epoch 10: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 187s 8s/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.0876 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9913\n",
            "Epoch 11: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 187s 8s/step - loss: 0.0164 - accuracy: 0.9913 - val_loss: 0.1074 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9971\n",
            "Epoch 12: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 185s 8s/step - loss: 0.0055 - accuracy: 0.9971 - val_loss: 0.0755 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9971\n",
            "Epoch 13: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 184s 8s/step - loss: 0.0071 - accuracy: 0.9971 - val_loss: 0.0917 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9971\n",
            "Epoch 14: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 187s 8s/step - loss: 0.0055 - accuracy: 0.9971 - val_loss: 0.1051 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 187s 8s/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0719 - val_accuracy: 0.9556 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9971\n",
            "Epoch 16: val_accuracy did not improve from 0.97778\n",
            "22/22 [==============================] - 182s 8s/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.1134 - val_accuracy: 0.9333 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.81      0.90        27\n",
            "      Normal       1.00      0.97      0.98        33\n",
            "Tuberculosis       0.83      1.00      0.91        30\n",
            "\n",
            "    accuracy                           0.93        90\n",
            "   macro avg       0.94      0.93      0.93        90\n",
            "weighted avg       0.94      0.93      0.93        90\n",
            "\n",
            "Fold #4\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 1: val_accuracy improved from -inf to 1.00000, saving model to  Kmodel16_soft_pre_bi4.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi4.h5 /assets\n",
            "22/22 [==============================] - 203s 9s/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9971\n",
            "Epoch 2: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.0288 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9971\n",
            "Epoch 3: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0050 - accuracy: 0.9971 - val_loss: 0.0412 - val_accuracy: 0.9667 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9972\n",
            "Epoch 4: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 175s 8s/step - loss: 0.0064 - accuracy: 0.9972 - val_loss: 0.0233 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 5: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 6: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 174s 8s/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9971\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 174s 8s/step - loss: 0.0064 - accuracy: 0.9971 - val_loss: 0.0215 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9971\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0066 - accuracy: 0.9971 - val_loss: 0.0447 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9942\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0070 - accuracy: 0.9942 - val_loss: 0.0402 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9943\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 175s 8s/step - loss: 0.0106 - accuracy: 0.9943 - val_loss: 0.0274 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9943\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 175s 8s/step - loss: 0.0109 - accuracy: 0.9943 - val_loss: 0.0255 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9971\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0063 - accuracy: 0.9971 - val_loss: 0.0496 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9971\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0061 - accuracy: 0.9971 - val_loss: 0.0436 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.97      0.98        30\n",
            "      Normal       1.00      0.97      0.98        31\n",
            "Tuberculosis       0.94      1.00      0.97        29\n",
            "\n",
            "    accuracy                           0.98        90\n",
            "   macro avg       0.98      0.98      0.98        90\n",
            "weighted avg       0.98      0.98      0.98        90\n",
            "\n",
            "Fold #5\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 1: val_accuracy improved from -inf to 0.97778, saving model to  Kmodel16_soft_pre_bi5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi5.h5 /assets\n",
            "22/22 [==============================] - 202s 9s/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9778 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9971\n",
            "Epoch 2: val_accuracy improved from 0.97778 to 0.98889, saving model to  Kmodel16_soft_pre_bi5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi5.h5 /assets\n",
            "22/22 [==============================] - 201s 9s/step - loss: 0.0079 - accuracy: 0.9971 - val_loss: 0.0146 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9971\n",
            "Epoch 3: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0049 - accuracy: 0.9971 - val_loss: 0.0164 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9971\n",
            "Epoch 4: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0043 - accuracy: 0.9971 - val_loss: 0.0158 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 5: val_accuracy did not improve from 0.98889\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9971\n",
            "Epoch 6: val_accuracy improved from 0.98889 to 1.00000, saving model to  Kmodel16_soft_pre_bi5.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi5.h5 /assets\n",
            "22/22 [==============================] - 201s 9s/step - loss: 0.0057 - accuracy: 0.9971 - val_loss: 0.0124 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 172s 8s/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9972\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 176s 8s/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0101 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9971\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 173s 8s/step - loss: 0.0044 - accuracy: 0.9971 - val_loss: 0.0043 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 174s 8s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 176s 8s/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 183s 9s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 183s 8s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9971\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 182s 8s/step - loss: 0.0074 - accuracy: 0.9971 - val_loss: 0.0012 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 175s 8s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 178s 8s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 175s 8s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 178s 8s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 174s 8s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "22/22 [==============================] - 180s 8s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      1.00      1.00        31\n",
            "      Normal       1.00      1.00      1.00        28\n",
            "Tuberculosis       1.00      1.00      1.00        31\n",
            "\n",
            "    accuracy                           1.00        90\n",
            "   macro avg       1.00      1.00      1.00        90\n",
            "weighted avg       1.00      1.00      1.00        90\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Lungcancer       1.00      0.81      0.90       150\n",
            "      Normal       0.97      0.95      0.96       150\n",
            "Tuberculosis       0.82      0.99      0.89       150\n",
            "\n",
            "    accuracy                           0.92       450\n",
            "   macro avg       0.93      0.92      0.92       450\n",
            "weighted avg       0.93      0.92      0.92       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 16 soft pre bi adam  \n"
      ],
      "metadata": {
        "id": "2hRe1jTCREHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 16\n",
        "filepath = \"Kmodel16_soft_pre_bi_adam.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\")\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "796594dc-ea89-4413-8cc1-836a107ff68a",
        "id": "UDNgWM_ZREHq"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:05<00:00, 86.34it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel16_soft_pre_bi_adam{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "OoraKn4qREHr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "709a9c8d-53ff-417e-b8a8-ce50bdc03fe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold #1\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.5784 - accuracy: 0.5378\n",
            "Epoch 1: val_accuracy improved from -inf to 0.34444, saving model to  Kmodel16_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_adam1.h5 /assets\n",
            "22/22 [==============================] - 223s 10s/step - loss: 0.5784 - accuracy: 0.5378 - val_loss: 1.1361 - val_accuracy: 0.3444 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.3739 - accuracy: 0.7355\n",
            "Epoch 2: val_accuracy improved from 0.34444 to 0.47778, saving model to  Kmodel16_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_adam1.h5 /assets\n",
            "22/22 [==============================] - 209s 10s/step - loss: 0.3739 - accuracy: 0.7355 - val_loss: 0.9088 - val_accuracy: 0.4778 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.2864 - accuracy: 0.8169\n",
            "Epoch 3: val_accuracy improved from 0.47778 to 0.56667, saving model to  Kmodel16_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_adam1.h5 /assets\n",
            "22/22 [==============================] - 213s 10s/step - loss: 0.2864 - accuracy: 0.8169 - val_loss: 0.7017 - val_accuracy: 0.5667 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1871 - accuracy: 0.8953\n",
            "Epoch 4: val_accuracy improved from 0.56667 to 0.67778, saving model to  Kmodel16_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_adam1.h5 /assets\n",
            "22/22 [==============================] - 221s 10s/step - loss: 0.1871 - accuracy: 0.8953 - val_loss: 0.6026 - val_accuracy: 0.6778 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.2256 - accuracy: 0.8605\n",
            "Epoch 5: val_accuracy improved from 0.67778 to 0.68889, saving model to  Kmodel16_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_adam1.h5 /assets\n",
            "22/22 [==============================] - 213s 10s/step - loss: 0.2256 - accuracy: 0.8605 - val_loss: 0.4609 - val_accuracy: 0.6889 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1155 - accuracy: 0.9360\n",
            "Epoch 6: val_accuracy did not improve from 0.68889\n",
            "22/22 [==============================] - 178s 8s/step - loss: 0.1155 - accuracy: 0.9360 - val_loss: 0.6173 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.9622\n",
            "Epoch 7: val_accuracy improved from 0.68889 to 0.75556, saving model to  Kmodel16_soft_pre_bi_adam1.h5 \n",
            "INFO:tensorflow:Assets written to:  Kmodel16_soft_pre_bi_adam1.h5 /assets\n",
            "22/22 [==============================] - 213s 10s/step - loss: 0.0777 - accuracy: 0.9622 - val_loss: 0.4842 - val_accuracy: 0.7556 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "17/22 [======================>.......] - ETA: 37s - loss: 0.0913 - accuracy: 0.9394"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 16 soft pre bi sgd  \n"
      ],
      "metadata": {
        "id": "oiU4sPwaREHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 16\n",
        "filepath = \"Kmodel16_soft_pre_bi_sgd.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b03506-eddb-4c17-f5fe-976c247895dd",
        "id": "Wd75Y7DjREHr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:06<00:00, 66.43it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel16_soft_pre_bi_sgd{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "vc536jz1REHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 16 soft pre cate \n"
      ],
      "metadata": {
        "id": "2nwMmcCSREHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 16\n",
        "filepath = \"Kmodel16_soft_pre_cate.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "8f62ba84-295e-4d23-a2f7-57bc97196ed3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hMfVEfpREHt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:10<00:00, 41.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel16_soft_pre_cate{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "re6ML_NsREHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####16 soft pre cate adam\n"
      ],
      "metadata": {
        "id": "V1-B4YN5REHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 16                                                       ##\n",
        "filepath = \"Kmodel16_soft_pre_cate_adam.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "4ade8ad3-0a08-4391-b9cc-b535897670e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkxTvAKFREHu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:04<00:00, 92.81it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel16_soft_pre_cate_adam{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "bRGqY3paREHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 16 soft pre cate sgd\n"
      ],
      "metadata": {
        "id": "b3TXk6OsREHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 16                                                       ##\n",
        "filepath = \"Kmodel16_soft_pre_cate_sgd.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "4ade8ad3-0a08-4391-b9cc-b535897670e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFF_2ASxREHv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:04<00:00, 92.81it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel16_soft_pre_cate_sgd{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "elc3h1RWREHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 32"
      ],
      "metadata": {
        "id": "TDetFQwMSKk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 32  soft pre bi\n"
      ],
      "metadata": {
        "id": "tUqsoIt5SKk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 32\n",
        "filepath = \"Kmodel32_soft_pre_bi.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "id": "dGYBzI9tSKk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel32_soft_pre_bi{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "shIE2WLlSKk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 32 soft pre bi adam  \n"
      ],
      "metadata": {
        "id": "17rbmbkJSKk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 32\n",
        "filepath = \"Kmodel32_soft_pre_bi_adam.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b03506-eddb-4c17-f5fe-976c247895dd",
        "id": "0Rc1AYwDSKk6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:06<00:00, 66.43it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel32_soft_pre_bi_adam{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "Z1tVkD0KSKk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 32 soft pre bi sgd  \n"
      ],
      "metadata": {
        "id": "52QbOgEXSKk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 32\n",
        "filepath = \"Kmodel32_soft_pre_bi_sgd.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b03506-eddb-4c17-f5fe-976c247895dd",
        "id": "p3cQUFuaSKk7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:06<00:00, 66.43it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel32_soft_pre_bi_sgd{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "IQLrE14OSKk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 32 soft pre cate \n"
      ],
      "metadata": {
        "id": "YmWai2hhSKk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 32\n",
        "filepath = \"Kmodel32_soft_pre_cate.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "8f62ba84-295e-4d23-a2f7-57bc97196ed3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9iMBwwkSKk9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:10<00:00, 41.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel32_soft_pre_cate{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "OU3Vt4nBSKk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 32 soft pre cate adam\n"
      ],
      "metadata": {
        "id": "Zrg0ZciqSKk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 32\n",
        "filepath = \"Kmodel32_soft_pre_cate_adam.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "4ade8ad3-0a08-4391-b9cc-b535897670e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6IwQDaZSKk-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:04<00:00, 92.81it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel32_soft_pre_cate_adam{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "SNUh7FzdSKk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 32 soft pre cate sgd\n"
      ],
      "metadata": {
        "id": "PInBxnIXSKk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 32\n",
        "filepath = \"Kmodel32_soft_pre_cate_sgd.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "4ade8ad3-0a08-4391-b9cc-b535897670e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zakBZsBzSKk_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:04<00:00, 92.81it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel32_soft_pre_cate_sgd{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "H9ZZNa8dSKk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 \n"
      ],
      "metadata": {
        "id": "GEk-rt9_StVQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1  soft pre bi\n"
      ],
      "metadata": {
        "id": "QDaLgRIyStVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 1\n",
        "filepath = \"Kmodel1_soft_pre_bi.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "id": "GGUJhDI9StVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel1_soft_pre_bi{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "6Vd84ZFgStVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1 soft pre bi adam  \n"
      ],
      "metadata": {
        "id": "OlSZVkmtStVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 1\n",
        "filepath = \"Kmodel1_soft_pre_bi_adam.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b03506-eddb-4c17-f5fe-976c247895dd",
        "id": "g1Xl88J7StVT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:06<00:00, 66.43it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel1_soft_pre_bi_adam{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "eRLREz42StVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1 soft pre bi sgd  \n"
      ],
      "metadata": {
        "id": "VUeDos-7StVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 1\n",
        "filepath = \"Kmodel1_soft_pre_bi_sgd.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b03506-eddb-4c17-f5fe-976c247895dd",
        "id": "RL_Q1Si5StVU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:06<00:00, 66.43it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel1_soft_pre_bi_sgd{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "4mZ0oZ-MStVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1 soft pre cate \n"
      ],
      "metadata": {
        "id": "fc3oQRkOStVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 1\n",
        "filepath = \"Kmodel1_soft_pre_cate.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "8f62ba84-295e-4d23-a2f7-57bc97196ed3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoTbrNJKStVU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:10<00:00, 41.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel1_soft_pre_cate{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "7_-gdbBGStVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1 soft pre cate adam\n"
      ],
      "metadata": {
        "id": "6ptGRCe5StVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 1\n",
        "filepath = \"Kmodel1_soft_pre_cate_adam.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "4ade8ad3-0a08-4391-b9cc-b535897670e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1s9MzgGStVV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:04<00:00, 92.81it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel1_soft_pre_cate_adam{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "55Vty_AUStVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1 soft pre cate sgd\n"
      ],
      "metadata": {
        "id": "DKND6UpAStVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 1\n",
        "filepath = \"Kmodel1_soft_pre_cate_sgd.h5\"                  ##\n",
        "\n",
        "train_img_Incep = []\n",
        "for ImageName in tqdm(data_train3['ImageName']):              \n",
        "    image_path = All_3class_dir +'/' + ImageName                  \n",
        "    img = cv2.imread(image_path)                                          \n",
        "    img = cv2.resize(img, (299, 299))                                      \n",
        "    train_img_Incep.append(img)\n",
        "data_Incep = np.array(train_img_Incep, dtype=\"float32\") / 255.0\n",
        "\n",
        "labels_Incep = np.array(data_train3[['NameType']] )        \n",
        "labels_Incep.shape = (len(labels_Incep),) \n",
        "le_Incep = LabelEncoder()                                                                     \n",
        "labels_Incep = le_Incep.fit_transform(labels_Incep)                                         \n",
        "labels_Incep = to_categorical(labels_Incep, num_classes=3)                   \n",
        "\n",
        "aug = ImageDataGenerator( rotation_range=15,\twidth_shift_range=0.1, \theight_shift_range=0.1,\n",
        "\t\tshear_range=0.15, \thorizontal_flip=True, \tfill_mode=\"nearest\")\n",
        "                                                                                                           ## \n",
        "callback = EarlyStopping( monitor= \"val_accuracy\",    patience=15,       mode=\"max\" , baseline=1.0)\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "                                                                                                            ##\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,   patience=6,     verbose=1, mode='max', min_lr=0.00001)"
      ],
      "metadata": {
        "outputId": "4ade8ad3-0a08-4391-b9cc-b535897670e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6PaOOyHStVW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 450/450 [00:04<00:00, 92.81it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_Incep = tf.keras.applications.InceptionV3(input_shape=(299, 299, 3), include_top=False, weights=\"imagenet\")\n",
        "len(base_model_Incep.layers)\n",
        "\n",
        "base_model_Incep.trainable = True\n",
        "for layer in base_model_Incep.layers[:100]:    #fix w & bias in layer 0-100\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "#Add custom head\n",
        "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model_Incep.output)\n",
        "prediction_layer = tf.keras.layers.Dense(units=3, activation=\"softmax\")(average_pooling_layer)   # unit 3\n",
        "model_Incep = tf.keras.models.Model(inputs=base_model_Incep.input, outputs=prediction_layer)\n",
        "\n",
        "model_Incep.compile(optimizer=SGD(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "### K-fold\n",
        "kf_Incep = KFold(5, shuffle=True, random_state=40) \n",
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "fold = 0\n",
        "\n",
        "for train, test in kf_Incep.split(data_Incep):\n",
        "    fold+=1   \n",
        "    print(f\"Fold #{fold}\")\n",
        "\n",
        "    filename = f\" Kmodel1_soft_pre_cate_sgd{fold}.h5 \"\n",
        "    checkpoint = ModelCheckpoint(filename, monitor='val_accuracy', verbose=1,   save_best_only=True, mode='max')\n",
        "        \n",
        "    x_train_Incep = data_Incep[train]\n",
        "    y_train_Incep = labels_Incep[train]\n",
        "    x_test_Incep = data_Incep[test]\n",
        "    y_test_Incep = labels_Incep[test]\n",
        "\n",
        "    H_Incep = model_Incep.fit( x=aug.flow(x_train_Incep, y_train_Incep, batch_size=BS),\n",
        "\t                                            validation_data=(x_test_Incep, y_test_Incep),\n",
        "\t                                            steps_per_epoch=len(x_train_Incep) // BS,\n",
        "\t                                            epochs=100,  callbacks = [callback,checkpoint,reduce_lr])\n",
        "\n",
        "    pred_Incep = model_Incep.predict(x_test_Incep)\n",
        "    \n",
        "    oos_y.append(y_test_Incep)\n",
        "    oos_pred.append(pred_Incep)  \n",
        "    print(classification_report(y_test_Incep.argmax(axis=1),\t                #แสดง report ค่า acc, recall, ...\n",
        "                                        pred_Incep.argmax(axis=1),  \n",
        "                                        target_names=le_Incep.classes_))\n",
        "    \n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "print(classification_report(oos_y.argmax(axis=1), oos_pred.argmax(axis=1),  target_names=le_Incep.classes_))"
      ],
      "metadata": {
        "id": "6HcHnNkAStVW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}